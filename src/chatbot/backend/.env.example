# ===========================================
# RAG Chatbot Environment Variables
# ===========================================
# Copy this file to .env and fill in your API keys

# ============ AI Models ============
# Cohere API (for embeddings: embed-multilingual-v3.0)
# Get from: https://dashboard.cohere.com/api-keys
# Used by ingestion pipeline to generate book content embeddings
COHERE_API_KEY=your-cohere-api-key-here

# OpenRouter API (for RAG answer generation via OpenAI SDK)
# Get from: https://openrouter.ai/keys
# Used by agent.py to generate grounded answers using GPT-3.5-turbo or Claude
OPENROUTER_API_KEY=your-openrouter-api-key-here
OPENROUTER_MODEL=openai/gpt-3.5-turbo

# Google Gemini API (for text generation)
# Get from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=AIzaSyDJ-p-DzSGud0lDyb53KWG09pjKBjzDIHo

# OpenAI API (for embeddings: text-embedding-3-small)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=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

# ============ Vector Database ============
# Qdrant Cloud (vector search for RAG)
# Sign up: https://cloud.qdrant.io (free tier: 1GB, 100k vectors)
# Create cluster â†’ Copy URL + API key
QDRANT_URL=https://5dc5847f-f6ee-4736-b2b1-fe6b4927889e.europe-west3-0.gcp.cloud.qdrant.io
QDRANT_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.UPDra4_Y7koQWQsaPcZiSWkrXbBZQ4aRqZtj-hkYba8

# ============ Database (Optional - Phase 2) ============
# Neon Serverless Postgres (for persistent chat history)
# Sign up: https://neon.tech (free tier: 3GB)
# Enables persistent storage for production (Phase 1 uses in-memory storage)
NEON_DB_URL=postgresql://user:pass@host.neon.tech/db?sslmode=require

# ============ Ingestion Pipeline Configuration ============
# Textbook URL to ingest content from
TEXTBOOK_BASE_URL=https://shumailaaijaz.github.io/physical-ai-textbook/

# Chunking parameters (for tiktoken-based text splitting)
# CHUNK_SIZE: Target chunk size in tokens (max 512 for Cohere embed-multilingual-v3.0)
# CHUNK_OVERLAP: Overlap between chunks in tokens (25% overlap recommended)
CHUNK_SIZE=512
CHUNK_OVERLAP=128

# Cohere API batch size (max 96 texts per embed call)
BATCH_SIZE=96

# ============ Server Configuration ============
PORT=8000
LOG_LEVEL=INFO
ENVIRONMENT=development

# ============ CORS (for local development) ============
# Add your Docusaurus local dev server URL
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000

# ===========================================
# IMPORTANT: Never commit .env to git!
# ===========================================
# Add .env to your .gitignore file
