"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[7101],{8453:(n,e,s)=>{s.d(e,{R:()=>t,x:()=>o});var i=s(6540);const r={},l=i.createContext(r);function t(n){const e=i.useContext(l);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:t(n.components),i.createElement(l.Provider,{value:e},n.children)}},9050:(n,e,s)=>{s.r(e),s.d(e,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"CHAPTER_OUTLINES","title":"Chapter Outlines: Physical AI & Humanoid Robotics Textbook","description":"Status: Draft outlines for Chapters 2-13 (awaiting approval)","source":"@site/docs/CHAPTER_OUTLINES.md","sourceDirName":".","slug":"/CHAPTER_OUTLINES","permalink":"/physical-ai-textbook/docs/CHAPTER_OUTLINES","draft":false,"unlisted":false,"editUrl":"https://github.com/Shumailaaijaz/physical-ai-textbook/tree/main/docs/CHAPTER_OUTLINES.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Example Diagrams","permalink":"/physical-ai-textbook/docs/example-diagrams"}}');var r=s(4848),l=s(8453);const t={},o="Chapter Outlines: Physical AI & Humanoid Robotics Textbook",c={},d=[{value:"Module 1: The Robotic Nervous System (ROS 2)",id:"module-1-the-robotic-nervous-system-ros-2",level:2},{value:"Chapter 2: ROS 2 Fundamentals",id:"chapter-2-ros-2-fundamentals",level:3},{value:"Learning Objectives",id:"learning-objectives",level:4},{value:"Section Outline",id:"section-outline",level:4},{value:"Exercises",id:"exercises",level:4},{value:"Citations (15 total)",id:"citations-15-total",level:4},{value:"Hardware Requirements",id:"hardware-requirements",level:4},{value:"Lab",id:"lab",level:4},{value:"Chapter 3: URDF &amp; Robot Modeling",id:"chapter-3-urdf--robot-modeling",level:3},{value:"Learning Objectives",id:"learning-objectives-1",level:4},{value:"Section Outline",id:"section-outline-1",level:4},{value:"Exercises",id:"exercises-1",level:4},{value:"Citations (12 total)",id:"citations-12-total",level:4},{value:"Hardware Requirements",id:"hardware-requirements-1",level:4},{value:"Lab",id:"lab-1",level:4},{value:"Module 2: The Digital Twin (Gazebo &amp; Unity)",id:"module-2-the-digital-twin-gazebo--unity",level:2},{value:"Chapter 4: Gazebo Simulation",id:"chapter-4-gazebo-simulation",level:3},{value:"Learning Objectives",id:"learning-objectives-2",level:4},{value:"Section Outline",id:"section-outline-2",level:4},{value:"Exercises",id:"exercises-2",level:4},{value:"Citations (10 total)",id:"citations-10-total",level:4},{value:"Hardware Requirements",id:"hardware-requirements-2",level:4},{value:"Labs",id:"labs",level:4},{value:"Chapter 5: Unity Robotics Hub",id:"chapter-5-unity-robotics-hub",level:3},{value:"Learning Objectives",id:"learning-objectives-3",level:4},{value:"Section Outline",id:"section-outline-3",level:4},{value:"Exercises",id:"exercises-3",level:4},{value:"Citations (8 total)",id:"citations-8-total",level:4},{value:"Hardware Requirements",id:"hardware-requirements-3",level:4},{value:"Lab",id:"lab-2",level:4},{value:"Module 3: The AI-Robot Brain (NVIDIA Isaac)",id:"module-3-the-ai-robot-brain-nvidia-isaac",level:2},{value:"Chapter 6: NVIDIA Isaac Sim Basics",id:"chapter-6-nvidia-isaac-sim-basics",level:3},{value:"Learning Objectives",id:"learning-objectives-4",level:4},{value:"Section Outline",id:"section-outline-4",level:4},{value:"Exercises",id:"exercises-4",level:4},{value:"Citations (12 total)",id:"citations-12-total-1",level:4},{value:"Hardware Requirements",id:"hardware-requirements-4",level:4},{value:"Labs",id:"labs-1",level:4},{value:"Chapter 7: Isaac ROS Integration",id:"chapter-7-isaac-ros-integration",level:3},{value:"Learning Objectives",id:"learning-objectives-5",level:4},{value:"Section Outline",id:"section-outline-5",level:4},{value:"Exercises",id:"exercises-5",level:4},{value:"Citations (15 total)",id:"citations-15-total-1",level:4},{value:"Hardware Requirements",id:"hardware-requirements-5",level:4},{value:"Lab",id:"lab-3",level:4},{value:"Module 4: Vision-Language-Action (VLA) &amp; Humanoid Development",id:"module-4-vision-language-action-vla--humanoid-development",level:2},{value:"Chapter 8: Legged Locomotion",id:"chapter-8-legged-locomotion",level:3},{value:"Learning Objectives",id:"learning-objectives-6",level:4},{value:"Section Outline",id:"section-outline-6",level:4},{value:"Exercises",id:"exercises-6",level:4},{value:"Citations (18 total)",id:"citations-18-total",level:4},{value:"Hardware Requirements",id:"hardware-requirements-6",level:4},{value:"Lab",id:"lab-4",level:4},{value:"Chapter 9: Manipulation &amp; Grasping",id:"chapter-9-manipulation--grasping",level:3},{value:"Learning Objectives",id:"learning-objectives-7",level:4},{value:"Section Outline",id:"section-outline-7",level:4},{value:"Exercises",id:"exercises-7",level:4},{value:"Citations (12 total)",id:"citations-12-total-2",level:4},{value:"Hardware Requirements",id:"hardware-requirements-7",level:4},{value:"Lab",id:"lab-5",level:4},{value:"Chapter 10: Vision-Language-Action (VLA) Models",id:"chapter-10-vision-language-action-vla-models",level:3},{value:"Learning Objectives",id:"learning-objectives-8",level:4},{value:"Section Outline",id:"section-outline-8",level:4},{value:"Exercises",id:"exercises-8",level:4},{value:"Citations (20 total)",id:"citations-20-total",level:4},{value:"Hardware Requirements",id:"hardware-requirements-8",level:4},{value:"Lab",id:"lab-6",level:4},{value:"Chapter 11: Capstone Project",id:"chapter-11-capstone-project",level:3},{value:"Learning Objectives",id:"learning-objectives-9",level:4},{value:"Project Specification",id:"project-specification",level:4},{value:"Deliverables",id:"deliverables",level:4},{value:"Grading Rubric (100 points)",id:"grading-rubric-100-points",level:4},{value:"Starter Code",id:"starter-code",level:4},{value:"Timeline",id:"timeline",level:4},{value:"Example Projects (Inspiration)",id:"example-projects-inspiration",level:4},{value:"Tips for Success",id:"tips-for-success",level:4},{value:"Part 5: Hardware, Ethics, and Future",id:"part-5-hardware-ethics-and-future",level:2},{value:"Chapter 12: Hardware Guide",id:"chapter-12-hardware-guide",level:3},{value:"Learning Objectives",id:"learning-objectives-10",level:4},{value:"Section Outline",id:"section-outline-9",level:4},{value:"Appendices",id:"appendices",level:4},{value:"Citations (8 total)",id:"citations-8-total-1",level:4},{value:"Chapter 13: Ethics &amp; Future of Physical AI",id:"chapter-13-ethics--future-of-physical-ai",level:3},{value:"Learning Objectives",id:"learning-objectives-11",level:4},{value:"Section Outline",id:"section-outline-10",level:4},{value:"Discussion Questions",id:"discussion-questions",level:4},{value:"Citations (15 total)",id:"citations-15-total-2",level:4}];function a(n){const e={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...n.components},{Details:s}=e;return s||function(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"chapter-outlines-physical-ai--humanoid-robotics-textbook",children:"Chapter Outlines: Physical AI & Humanoid Robotics Textbook"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Status"}),": Draft outlines for Chapters 2-13 (awaiting approval)\r\n",(0,r.jsx)(e.strong,{children:"Created"}),": 2025-12-05\r\n",(0,r.jsx)(e.strong,{children:"Author"}),": Based on course syllabus provided by instructor"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"module-1-the-robotic-nervous-system-ros-2",children:"Module 1: The Robotic Nervous System (ROS 2)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Weeks"}),": 3-5 | ",(0,r.jsx)(e.strong,{children:"Chapters"}),": 2-3"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-2-ros-2-fundamentals",children:"Chapter 2: ROS 2 Fundamentals"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 3-4 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 8,000 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Beginner-Intermediate"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Explain ROS 2 architecture (nodes, topics, services, actions)"}),"\n",(0,r.jsxs)(e.li,{children:["Build ROS 2 packages using Python (",(0,r.jsx)(e.code,{children:"rclpy"}),")"]}),"\n",(0,r.jsx)(e.li,{children:"Implement publisher/subscriber communication patterns"}),"\n",(0,r.jsx)(e.li,{children:"Use ROS 2 command-line tools for debugging"}),"\n",(0,r.jsx)(e.li,{children:"Launch multi-node systems with launch files"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.1 Introduction: Why ROS 2?"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Evolution from ROS 1 to ROS 2 (DDS middleware, real-time support)"}),"\n",(0,r.jsx)(e.li,{children:"Industry adoption (Waymo, Amazon Robotics, NASA)"}),"\n",(0,r.jsx)(e.li,{children:"Key improvements: Security, multi-robot systems, Windows support"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Citation"}),": ROS 2 Design Document (Open Robotics, 2022)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.2 ROS 2 Architecture"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Nodes"}),": Independent processes (analogy: apps on a phone)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Topics"}),": Publish/subscribe messaging (1-to-N communication)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Services"}),": Request/response calls (1-to-1 synchronous)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Actions"}),": Long-running tasks with feedback/cancel (e.g., navigate_to_pose)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Parameters"}),": Runtime configuration (node settings)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Diagram"}),": ROS 2 computation graph (nodes connected via topics/services)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.3 Setting Up ROS 2 on Windows"})}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Windows 10/11 + Docker Setup"}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-powershell",children:"# Pull ROS 2 Humble Docker image\r\ndocker pull osrf/ros:humble-desktop\r\n\r\n# Run container with GUI forwarding\r\ndocker run -it --name ros2_dev osrf/ros:humble-desktop\r\n\r\n# Inside container:\r\nros2 --version\r\n# Expected: ros2 cli version: 0.18.5\n"})})]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Alternative: WSL2 native installation (for advanced users)"}),"\n",(0,r.jsx)(e.li,{children:"Alternative: GitHub Codespaces (one-click setup)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Time estimate"}),": 15 minutes"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.4 Your First ROS 2 Node (Talker/Listener)"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": Publisher (Talker)"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# talker.py - Publishes messages to /chatter topic\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\n\r\nclass TalkerNode(Node):\r\n    def __init__(self):\r\n        super().__init__('talker')\r\n        self.publisher_ = self.create_publisher(String, 'chatter', 10)\r\n        self.timer = self.create_timer(1.0, self.timer_callback)\r\n        self.count = 0\r\n\r\n    def timer_callback(self):\r\n        msg = String()\r\n        msg.data = f'Hello from ROS 2: {self.count}'\r\n        self.publisher_.publish(msg)\r\n        self.get_logger().info(f'Published: \"{msg.data}\"')\r\n        self.count += 1\r\n\r\ndef main():\r\n    rclpy.init()\r\n    node = TalkerNode()\r\n    rclpy.spin(node)\r\n    node.destroy_node()\r\n    rclpy.shutdown()\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": Subscriber (Listener)"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# listener.py - Subscribes to /chatter topic\r\n# (Full code provided)\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Running"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Terminal 1:\r\nros2 run my_package talker\r\n\r\n# Terminal 2:\r\nros2 run my_package listener\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Expected Output"}),": Listener prints messages from Talker"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.5 Building ROS 2 Packages"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["Package structure: ",(0,r.jsx)(e.code,{children:"package.xml"}),", ",(0,r.jsx)(e.code,{children:"setup.py"}),", ",(0,r.jsx)(e.code,{children:"CMakeLists.txt"})," (C++)"]}),"\n",(0,r.jsxs)(e.li,{children:["Creating a Python package with ",(0,r.jsx)(e.code,{children:"ros2 pkg create"})]}),"\n",(0,r.jsx)(e.li,{children:"Dependencies and build system (ament_python vs ament_cmake)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 3"}),": Complete package structure for ",(0,r.jsx)(e.code,{children:"my_robot_controller"})]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.6 ROS 2 Topics Deep Dive"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["Message types: ",(0,r.jsx)(e.code,{children:"std_msgs"}),", ",(0,r.jsx)(e.code,{children:"geometry_msgs"}),", ",(0,r.jsx)(e.code,{children:"sensor_msgs"})]}),"\n",(0,r.jsx)(e.li,{children:"Quality of Service (QoS): Reliability, durability, history depth"}),"\n",(0,r.jsxs)(e.li,{children:["Introspection tools:","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"ros2 topic list"})," - Show all active topics"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"ros2 topic echo /chatter"})," - Monitor topic data"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"ros2 topic hz /chatter"})," - Measure publish rate"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"ros2 topic info /chatter"})," - Show publishers/subscribers"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 4"}),": Velocity controller for simulated robot"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Control robot with cmd_vel topic (geometry_msgs/Twist)\r\n# Forward: linear.x = 0.5, angular.z = 0.0\r\n# Turn left: linear.x = 0.0, angular.z = 0.5\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.7 ROS 2 Services"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Synchronous request/response pattern"}),"\n",(0,r.jsx)(e.li,{children:"Use cases: Trigger actions (e.g., /reset_simulation), query state (e.g., /get_robot_pose)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 5"}),": Service client to add two integers"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 6"}),": Service server for robot pose"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.8 ROS 2 Actions"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Asynchronous tasks with feedback"}),"\n",(0,r.jsx)(e.li,{children:"Use case: Navigation (send goal \u2192 get feedback on progress \u2192 receive result)"}),"\n",(0,r.jsx)(e.li,{children:"Action states: ACCEPTED \u2192 EXECUTING \u2192 SUCCEEDED/ABORTED/CANCELED"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 7"}),": Fibonacci action server (tutorial)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 8"}),": Navigation action client (send waypoint, monitor progress)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.9 Launch Files"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Starting multiple nodes with one command"}),"\n",(0,r.jsx)(e.li,{children:"XML vs Python vs YAML launch files"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 9"}),": Launch talker + listener simultaneously"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# talker_listener_launch.py\r\nfrom launch import LaunchDescription\r\nfrom launch_ros.actions import Node\r\n\r\ndef generate_launch_description():\r\n    return LaunchDescription([\r\n        Node(package='my_package', executable='talker'),\r\n        Node(package='my_package', executable='listener'),\r\n    ])\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.10 Parameters and Configuration"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Runtime configuration without recompiling"}),"\n",(0,r.jsx)(e.li,{children:"Declaring parameters in nodes"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 10"}),": Configurable timer frequency for talker"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.11 Debugging Tools"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"ros2 node list"})," - Show running nodes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"ros2 node info /talker"})," - Inspect node connections"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"rqt_graph"})," - Visualize computation graph (GUI)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"ros2 doctor"})," - Check ROS 2 installation health"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2.12 Best Practices"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"One node = one responsibility (e.g., camera_driver, object_detector, path_planner)"}),"\n",(0,r.jsx)(e.li,{children:"Use namespaces for multi-robot systems"}),"\n",(0,r.jsx)(e.li,{children:"Document node interfaces (topics, services, parameters)"}),"\n",(0,r.jsx)(e.li,{children:"Error handling and logging"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"exercises",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 2.1"}),": Build a custom publisher that sends robot odometry (position, velocity)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 2.2"}),": Create a service that calculates inverse kinematics for a 2-DOF arm"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 2.3"}),": Implement an action server for battery charging (feedback: % charged)"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-15-total",children:"Citations (15 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["Macenski, S., et al. (2022). ",(0,r.jsx)(e.em,{children:"Robot Operating System 2: Design, architecture, and uses in the wild."})," Science Robotics."]}),"\n",(0,r.jsxs)(e.li,{children:["Open Robotics. (2023). ",(0,r.jsx)(e.em,{children:"ROS 2 Design Document."})," ",(0,r.jsx)(e.a,{href:"https://design.ros2.org/",children:"https://design.ros2.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Quigley, M., et al. (2009). ",(0,r.jsx)(e.em,{children:"ROS: an open-source Robot Operating System."})," ICRA Workshop."]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Minimum"}),": Any computer (cloud/Codespaces works)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Recommended"}),": Windows 10/11 + Docker Desktop"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"No GPU required"})," for this chapter"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"lab",children:"Lab"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-02-1-ros2-hello-world"}),": Talker/listener in Docker container, launch file example"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-3-urdf--robot-modeling",children:"Chapter 3: URDF & Robot Modeling"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 5 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 7,000 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Intermediate"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-1",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Describe robot geometry using URDF (Unified Robot Description Format)"}),"\n",(0,r.jsx)(e.li,{children:"Define kinematic chains (links, joints) for humanoid robots"}),"\n",(0,r.jsx)(e.li,{children:"Use Xacro for modular URDF design"}),"\n",(0,r.jsx)(e.li,{children:"Visualize robots in RViz"}),"\n",(0,r.jsxs)(e.li,{children:["Publish robot state with ",(0,r.jsx)(e.code,{children:"robot_state_publisher"})]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-1",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.1 Introduction: Describing Robot Geometry"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Why URDF? (Standard format for ROS, supported by all simulators)"}),"\n",(0,r.jsx)(e.li,{children:"URDF vs SDF (Simulation Description Format for Gazebo)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Example"}),": TurtleBot3, Unitree Go2, Unitree G1 URDF files"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.2 URDF Structure"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Links"}),": Rigid bodies (visual, collision, inertial properties)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Joints"}),": Connections between links (revolute, prismatic, fixed, continuous)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"XML syntax"}),": ",(0,r.jsx)(e.code,{children:"<robot>"}),", ",(0,r.jsx)(e.code,{children:"<link>"}),", ",(0,r.jsx)(e.code,{children:"<joint>"}),", ",(0,r.jsx)(e.code,{children:"<material>"})]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": Simple 2-link arm"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<robot name="simple_arm">\r\n  \x3c!-- Base link (fixed to world) --\x3e\r\n  <link name="base_link">\r\n    <visual>\r\n      <geometry><box size="0.1 0.1 0.1"/></geometry>\r\n      <material name="blue"><color rgba="0 0 1 1"/></material>\r\n    </visual>\r\n  </link>\r\n\r\n  \x3c!-- First link (upper arm) --\x3e\r\n  <link name="link1">\r\n    <visual>\r\n      <geometry><cylinder radius="0.05" length="0.5"/></geometry>\r\n      <material name="red"><color rgba="1 0 0 1"/></material>\r\n    </visual>\r\n  </link>\r\n\r\n  \x3c!-- Joint connecting base to link1 --\x3e\r\n  <joint name="joint1" type="revolute">\r\n    <parent link="base_link"/>\r\n    <child link="link1"/>\r\n    <axis xyz="0 0 1"/>\r\n    <limit lower="-1.57" upper="1.57" effort="10" velocity="1.0"/>\r\n  </joint>\r\n</robot>\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.3 Link Properties"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Visual"}),": Appearance (mesh files, STL, DAE, or primitives)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Collision"}),": Simplified geometry for physics (often boxes/cylinders)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Inertial"}),": Mass, center of mass, inertia tensor (required for dynamics)"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": Link with inertial properties"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<link name="link1">\r\n  <inertial>\r\n    <mass value="2.5"/>\r\n    <inertia ixx="0.1" ixy="0.0" ixz="0.0" iyy="0.1" iyz="0.0" izz="0.1"/>\r\n  </inertial>\r\n  \x3c!-- visual and collision here --\x3e\r\n</link>\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.4 Joint Types"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Revolute"}),": Rotational (e.g., elbow, knee) with limits"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Continuous"}),": Rotational without limits (e.g., wheel)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Prismatic"}),": Linear (e.g., elevator, telescope arm)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Fixed"}),": Rigidly attached (e.g., camera mount)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Planar"}),", ",(0,r.jsx)(e.strong,{children:"Floating"}),": Rarely used (2D motion, free-floating base)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.5 Humanoid Kinematic Chain"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Torso (base link) \u2192 Legs (6 DOF per leg: hip roll/pitch/yaw, knee, ankle pitch/roll) \u2192 Arms (7 DOF per arm) \u2192 Head (2 DOF: pan/tilt)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Total DOF"}),": Typical humanoid = 30-40 joints"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Diagram"}),": Unitree G1 kinematic tree"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 3"}),": Simplified humanoid leg (6 DOF)"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'\x3c!-- Hip roll, hip pitch, hip yaw, knee, ankle pitch, ankle roll --\x3e\r\n<joint name="left_hip_roll" type="revolute">...</joint>\r\n<joint name="left_hip_pitch" type="revolute">...</joint>\r\n\x3c!-- etc. --\x3e\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.6 Xacro: Macros for URDF"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Problem: URDF is verbose and repetitive (copy-paste for left/right legs)"}),"\n",(0,r.jsx)(e.li,{children:"Solution: Xacro (XML Macros) - parameterized URDF generation"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Features"}),": Variables, math expressions, macros, includes"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 4"}),": Xacro macro for robot leg"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<xacro:macro name="leg" params="prefix reflect">\r\n  \x3c!-- prefix = "left" or "right", reflect = 1 or -1 for mirroring --\x3e\r\n  <joint name="${prefix}_hip_roll" type="revolute">\r\n    <axis xyz="${reflect} 0 0"/>\r\n    \x3c!-- etc. --\x3e\r\n  </joint>\r\n</xacro:macro>\r\n\r\n\x3c!-- Instantiate left and right legs --\x3e\r\n<xacro:leg prefix="left" reflect="1"/>\r\n<xacro:leg prefix="right" reflect="-1"/>\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.7 Meshes and Visual Fidelity"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Using STL/DAE/OBJ files for realistic appearance"}),"\n",(0,r.jsx)(e.li,{children:"Tools: Blender, Fusion 360, SolidWorks"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Example"}),": Download Unitree Go2 meshes, integrate into URDF"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.8 Visualizing in RViz"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"RViz: 3D visualization tool for ROS"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"robot_state_publisher"}),": Publishes TF transforms from URDF"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"joint_state_publisher"}),": GUI to control joint angles"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Setup"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Inside WSL2 terminal or Docker:\r\nros2 launch urdf_tutorial display.launch.py model:=my_robot.urdf\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Expected"}),": RViz opens, robot model visible, GUI sliders control joints"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.9 Transform Frames (TF2)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Every link has a coordinate frame"}),"\n",(0,r.jsx)(e.li,{children:"TF tree: Parent-child relationships (base_link \u2192 left_hip \u2192 left_knee \u2192 left_ankle)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Tools"}),":","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"ros2 run tf2_tools view_frames"})," - Generate TF tree PDF"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.code,{children:"ros2 run tf2_ros tf2_echo base_link left_foot"})," - Print transform"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.10 Collision and Physics Preparation"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Collision geometry (simple shapes for fast computation)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Best practice"}),": Visual = high-poly mesh, Collision = low-poly boxes/cylinders"]}),"\n",(0,r.jsx)(e.li,{children:"Self-collision filtering (e.g., thigh can't collide with torso)"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.11 Exporting from CAD"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Fusion 360 URDF Exporter plugin"}),"\n",(0,r.jsx)(e.li,{children:"SolidWorks to URDF plugin"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Workflow"}),": Design in CAD \u2192 Export meshes + URDF \u2192 Import into ROS"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3.12 URDF for Unitree G1 Humanoid"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Case study"}),": Analyzing Unitree G1 official URDF"]}),"\n",(0,r.jsx)(e.li,{children:"Link names, joint limits, mass distribution"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 5"}),": Load Unitree G1 URDF, visualize in RViz"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"exercises-1",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 3.1"}),": Create URDF for a 4-legged table (4 legs + 1 tabletop, all fixed joints)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 3.2"}),": Model a 3-DOF robot arm (shoulder pan/tilt, elbow), visualize in RViz"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 3.3"}),": Add collision geometry to your arm, verify in RViz (enable collision view)"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-12-total",children:"Citations (12 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["ROS.org. (2023). ",(0,r.jsx)(e.em,{children:"URDF XML Specification."})," ",(0,r.jsx)(e.a,{href:"http://wiki.ros.org/urdf/XML",children:"http://wiki.ros.org/urdf/XML"})]}),"\n",(0,r.jsxs)(e.li,{children:["Unitree Robotics. (2024). ",(0,r.jsx)(e.em,{children:"G1 Humanoid URDF Repository."})," ",(0,r.jsx)(e.a,{href:"https://github.com/unitreerobotics/unitree_ros",children:"https://github.com/unitreerobotics/unitree_ros"})]}),"\n",(0,r.jsxs)(e.li,{children:["Kam, H. R., et al. (2015). ",(0,r.jsx)(e.em,{children:"RViz: A Toolkit for Real Domain Data Visualization."})," Telecommunications Systems."]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"hardware-requirements-1",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Minimum"}),": Any computer (RViz works in Docker with X11 forwarding)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Recommended"}),": Windows 10/11 + VcXsrv for GUI"]}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"No GPU required"})}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"lab-1",children:"Lab"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-03-1-urdf-robot"}),": Build quadruped URDF, visualize in RViz with joint sliders"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"module-2-the-digital-twin-gazebo--unity",children:"Module 2: The Digital Twin (Gazebo & Unity)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Weeks"}),": 6-7 | ",(0,r.jsx)(e.strong,{children:"Chapters"}),": 4-5"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-4-gazebo-simulation",children:"Chapter 4: Gazebo Simulation"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 6 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 7,500 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Intermediate"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-2",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Set up Gazebo simulation environments"}),"\n",(0,r.jsx)(e.li,{children:"Spawn robots from URDF into Gazebo worlds"}),"\n",(0,r.jsx)(e.li,{children:"Simulate sensors (LIDAR, cameras, IMU, contact sensors)"}),"\n",(0,r.jsx)(e.li,{children:"Apply forces, model physics (gravity, friction, collisions)"}),"\n",(0,r.jsx)(e.li,{children:"Integrate Gazebo with ROS 2"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-2",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.1 Introduction: Why Simulate?"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Benefits: Safe testing, rapid iteration, synthetic data generation, zero hardware cost"}),"\n",(0,r.jsx)(e.li,{children:"Gazebo vs other simulators (Isaac Sim, MuJoCo, PyBullet)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Industry use"}),": Waymo simulates 20 billion miles/year"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.2 Gazebo Architecture"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Client-server"}),": ",(0,r.jsx)(e.code,{children:"gzserver"})," (physics engine) + ",(0,r.jsx)(e.code,{children:"gzclient"})," (GUI)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Physics engines"}),": ODE (default), Bullet, Simbody, DART"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Plugins"}),": Custom sensors, controllers, world logic"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.3 Installing Gazebo on Windows"})}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Windows 10/11 + Docker Setup"}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-powershell",children:"# Pull Gazebo + ROS 2 image\r\ndocker pull osrf/ros:humble-desktop-full\r\n\r\n# Run with GUI forwarding (requires VcXsrv)\r\ndocker run -it -e DISPLAY=host.docker.internal:0 osrf/ros:humble-desktop-full\r\n\r\n# Inside container:\r\ngazebo --version\r\n# Expected: Gazebo multi-robot simulator, version 11.10.2\n"})})]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.4 World Files (SDF Format)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"SDF (Simulation Description Format): XML for worlds, models, plugins"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": Empty world with ground plane"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sdf version="1.6">\r\n  <world name="my_world">\r\n    <include><uri>model://sun</uri></include>\r\n    <include><uri>model://ground_plane</uri></include>\r\n  </world>\r\n</sdf>\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.5 Spawning Robots"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["Convert URDF \u2192 SDF (automatic via ",(0,r.jsx)(e.code,{children:"spawn_entity.py"}),")"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": Spawn robot from URDF"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"ros2 run gazebo_ros spawn_entity.py -entity my_robot -file my_robot.urdf -x 0 -y 0 -z 0.5\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.6 Physics Simulation"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Gravity"}),": Default 9.81 m/s\xb2 (configurable)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Friction"}),": Static, kinetic, rolling resistance"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Collisions"}),": Bounding boxes, convex hulls, mesh-based"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Contact forces"}),": Normal force, tangential force (for grasping)"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 3"}),": Custom friction for robot wheels"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:"<surface>\r\n  <friction>\r\n    <ode>\r\n      <mu>0.8</mu>   \x3c!-- Coefficient of friction --\x3e\r\n      <mu2>0.8</mu2>\r\n    </ode>\r\n  </friction>\r\n</surface>\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.7 Simulated Sensors"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.7.1 Camera Plugin"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="camera" type="camera">\r\n  <update_rate>30</update_rate>\r\n  <camera>\r\n    <horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees --\x3e\r\n    <image>\r\n      <width>640</width>\r\n      <height>480</height>\r\n    </image>\r\n  </camera>\r\n  <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\r\n    <ros>\r\n      <namespace>/robot</namespace>\r\n      <remapping>image_raw:=camera/image_raw</remapping>\r\n    </ros>\r\n  </plugin>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.7.2 LIDAR Plugin"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="lidar" type="ray">\r\n  <ray>\r\n    <scan>\r\n      <horizontal>\r\n        <samples>360</samples>\r\n        <resolution>1</resolution>\r\n        <min_angle>-3.14159</min_angle>\r\n        <max_angle>3.14159</max_angle>\r\n      </horizontal>\r\n    </scan>\r\n    <range><min>0.1</min><max>10.0</max></range>\r\n  </ray>\r\n  <plugin name="lidar_controller" filename="libgazebo_ros_ray_sensor.so">\r\n    <ros>\r\n      <remapping>~/out:=scan</remapping>\r\n    </ros>\r\n  </plugin>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.7.3 IMU Plugin"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="imu" type="imu">\r\n  <imu>\r\n    <angular_velocity>\r\n      <x><noise type="gaussian"><stddev>0.01</stddev></noise></x>\r\n    </angular_velocity>\r\n  </imu>\r\n  <plugin name="imu_plugin" filename="libgazebo_ros_imu_sensor.so"/>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.8 Robot Control in Gazebo"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Differential drive"}),": Control via ",(0,r.jsx)(e.code,{children:"/cmd_vel"})," (Twist messages)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Joint controllers"}),": Position, velocity, effort (torque) control"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 4"}),": Velocity controller plugin"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<plugin name="diff_drive" filename="libgazebo_ros_diff_drive.so">\r\n  <left_joint>left_wheel_joint</left_joint>\r\n  <right_joint>right_wheel_joint</right_joint>\r\n  <wheel_separation>0.4</wheel_separation>\r\n  <wheel_diameter>0.2</wheel_diameter>\r\n  <command_topic>/cmd_vel</command_topic>\r\n</plugin>\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.9 Building Custom Worlds"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Model library: Pre-made objects (tables, chairs, walls)"}),"\n",(0,r.jsx)(e.li,{children:"Building editor: GUI for creating structures"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 5"}),": World with obstacles (maze for navigation testing)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.10 Domain Randomization"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Randomize object poses, textures, lighting"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Purpose"}),": Sim-to-real transfer (train robust policies)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 6"}),": Python script to randomize world parameters"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.11 Performance Optimization"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Real-time factor (RTF): Simulation speed / real-time speed (target: 1.0)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Tips"}),":","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use simple collision geometry (boxes > meshes)"}),"\n",(0,r.jsx)(e.li,{children:"Reduce sensor update rates (10 Hz vs 100 Hz)"}),"\n",(0,r.jsxs)(e.li,{children:["Disable GUI (",(0,r.jsx)(e.code,{children:"gzserver"})," only) for faster batch simulations"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"4.12 Gazebo + ROS 2 Integration"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Launch file combining ROS 2 nodes + Gazebo"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 7"}),": Complete launch file (spawn robot, start teleoperation)"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"exercises-2",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 4.1"}),": Create a world with 10 random boxes, spawn a robot, write a node to avoid collisions"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 4.2"}),": Add a camera sensor to a robot, subscribe to ",(0,r.jsx)(e.code,{children:"/camera/image_raw"}),", display using OpenCV"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 4.3"}),": Measure simulation accuracy (drop a ball from 1m height, measure impact time, compare to physics formula)"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-10-total",children:"Citations (10 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["Koenig, N., & Howard, A. (2004). ",(0,r.jsx)(e.em,{children:"Design and use paradigms for Gazebo, an open-source multi-robot simulator."})," IROS 2004."]}),"\n",(0,r.jsxs)(e.li,{children:["Open Robotics. (2023). ",(0,r.jsx)(e.em,{children:"Gazebo Simulation Documentation."})," ",(0,r.jsx)(e.a,{href:"https://gazebosim.org/",children:"https://gazebosim.org/"})]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"hardware-requirements-2",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Minimum"}),": 4 GB RAM, integrated GPU (RTF ~0.5)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Recommended"}),": 8 GB RAM, dedicated GPU (RTF ~1.0)"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"labs",children:"Labs"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-04-1-gazebo-world"}),": Custom world with obstacles, camera/LIDAR sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-04-2-gazebo-control"}),": Teleoperation, waypoint navigation"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-5-unity-robotics-hub",children:"Chapter 5: Unity Robotics Hub"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 7 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 6,500 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Intermediate"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-3",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Set up Unity for robotics simulation"}),"\n",(0,r.jsx)(e.li,{children:"Connect Unity to ROS 2 via TCP endpoint"}),"\n",(0,r.jsx)(e.li,{children:"Import robot models (URDF) into Unity"}),"\n",(0,r.jsx)(e.li,{children:"Create high-fidelity environments for human-robot interaction"}),"\n",(0,r.jsx)(e.li,{children:"Generate synthetic training data (images, depth, segmentation)"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-3",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.1 Introduction: Why Unity?"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Gazebo"}),": Great physics, poor graphics"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Unity"}),": Photorealistic rendering, human-scale environments, VR/AR support"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Use case"}),": Training vision models with synthetic data, HRI testing"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.2 Unity Robotics Hub Overview"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ROS-TCP-Connector"}),": Bidirectional communication (Unity \u2194 ROS 2)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"URDF Importer"}),": Load robot models into Unity"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Articulation Body"}),": Unity's physics engine for robots"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.3 Installing Unity on Windows (Native!)"})}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Windows 10/11 Setup (No WSL2 Needed)"}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-powershell",children:"# Download Unity Hub\r\n# https://unity.com/download\r\n\r\n# Install Unity 2022.3 LTS (recommended for robotics)\r\n# Add modules: Linux Build Support, Windows Build Support\r\n\r\n# Install ROS-TCP-Connector package\r\n# (Via Unity Package Manager \u2192 Add from git URL)\n"})})]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Note"}),": Unity runs ",(0,r.jsx)(e.strong,{children:"natively on Windows"}),"\u2014one of the few robotics tools that does!"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.4 ROS-TCP-Connector Setup"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Server"}),": ROS 2 node listens on TCP port (default: 10000)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Client"}),": Unity connects, sends/receives ROS messages"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": Launch ROS-TCP-Endpoint"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Inside WSL2 terminal:\r\nros2 run ros_tcp_endpoint default_server_endpoint --ros-args -p ROS_IP:=0.0.0.0\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": Unity C# script to publish ",(0,r.jsx)(e.code,{children:"/cmd_vel"})]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using Unity.Robotics.ROSTCPConnector;\r\nusing RosMessageTypes.Geometry;\r\n\r\npublic class VelocityPublisher : MonoBehaviour {\r\n    ROSConnection ros;\r\n\r\n    void Start() {\r\n        ros = ROSConnection.GetOrCreateInstance();\r\n        ros.RegisterPublisher<TwistMsg>("/cmd_vel");\r\n    }\r\n\r\n    void Update() {\r\n        TwistMsg twist = new TwistMsg {\r\n            linear = new Vector3Msg { x = 0.5, y = 0, z = 0 },\r\n            angular = new Vector3Msg { x = 0, y = 0, z = 0.1 }\r\n        };\r\n        ros.Publish("/cmd_vel", twist);\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.5 Importing URDF into Unity"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"URDF Importer"})," package (Unity Robotics Hub)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Workflow"}),": URDF \u2192 Unity Asset \u2192 Scene"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 3"}),": Import Unitree Go2 URDF"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.6 Articulation Body (Physics)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Unity's physics engine for multi-body robots"}),"\n",(0,r.jsx)(e.li,{children:"Joint types: Revolute, Prismatic, Fixed, Spherical"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 4"}),": Configure articulation for robot arm"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.7 Simulating Sensors in Unity"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Camera"}),": RGB, depth, segmentation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Perception Package"}),": Ground truth labels for ML training"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 5"}),": Capture RGB-D images, publish to ROS"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.8 High-Fidelity Environments"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Asset Store: Pre-made environments (offices, homes, warehouses)"}),"\n",(0,r.jsx)(e.li,{children:"ProBuilder: Build custom environments in Unity Editor"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Example"}),": Create kitchen scene for manipulation tasks"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.9 Human-Robot Interaction"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Animated human models (Mixamo, Asset Store)"}),"\n",(0,r.jsx)(e.li,{children:"Social navigation scenarios (robot navigating around humans)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 6"}),": Human waypoint navigation (NPC movement)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.10 Synthetic Data Generation"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Use case"}),": Train object detectors without real-world data"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Perception Package"}),": Randomize object poses, lighting, textures"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Dataset"}),": 10,000 labeled images in 1 hour"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 7"}),": Domain randomization script"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.11 Unity ML-Agents (Preview)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Train robot policies with reinforcement learning"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Example"}),": Train quadruped to walk using PPO"]}),"\n",(0,r.jsx)(e.li,{children:"Integration with ROS 2 (actions \u2192 observations \u2192 rewards)"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"5.12 Unity vs Gazebo: When to Use Which?"})}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"Feature"})}),(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"Gazebo"})}),(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"Unity"})})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Physics accuracy"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50\u2b50\u2b50\u2b50 (ODE, Bullet)"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50\u2b50\u2b50 (PhysX)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Visual fidelity"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50 (Basic rendering)"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50\u2b50\u2b50\u2b50 (Photorealistic)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"ROS integration"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50\u2b50\u2b50\u2b50 (Native)"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50\u2b50 (TCP bridge)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Ease of use"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50\u2b50 (SDF/URDF)"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50\u2b50\u2b50 (GUI editor)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Performance"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50\u2b50 (CPU-heavy)"}),(0,r.jsx)(e.td,{children:"\u2b50\u2b50\u2b50\u2b50 (GPU-accelerated)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Cost"}),(0,r.jsx)(e.td,{children:"Free (open-source)"}),(0,r.jsx)(e.td,{children:"Free (Personal), Paid (Pro)"})]})]})]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Recommendation"}),": Use ",(0,r.jsx)(e.strong,{children:"Gazebo"})," for navigation/manipulation testing. Use ",(0,r.jsx)(e.strong,{children:"Unity"})," for vision training and HRI."]}),"\n",(0,r.jsx)(e.h4,{id:"exercises-3",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 5.1"}),": Import a robot URDF into Unity, control joints via ROS"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 5.2"}),": Create a kitchen scene, place objects, capture 100 RGB-D images"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 5.3"}),": Implement social navigation (robot avoids moving humans)"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-8-total",children:"Citations (8 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["Unity Technologies. (2023). ",(0,r.jsx)(e.em,{children:"Unity Robotics Hub Documentation."})," ",(0,r.jsx)(e.a,{href:"https://github.com/Unity-Technologies/Unity-Robotics-Hub",children:"https://github.com/Unity-Technologies/Unity-Robotics-Hub"})]}),"\n",(0,r.jsxs)(e.li,{children:["Juliani, A., et al. (2018). ",(0,r.jsx)(e.em,{children:"Unity: A general platform for intelligent agents."})," arXiv preprint."]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"hardware-requirements-3",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Minimum"}),": NVIDIA GTX 1060 (for rendering)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Recommended"}),": NVIDIA RTX 3060 (for real-time ray tracing)"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"lab-2",children:"Lab"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-05-1-unity-tcp-connector"}),": Unity scene + ROS bridge, teleoperation, synthetic image capture"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"module-3-the-ai-robot-brain-nvidia-isaac",children:"Module 3: The AI-Robot Brain (NVIDIA Isaac)"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Weeks"}),": 8-10 | ",(0,r.jsx)(e.strong,{children:"Chapters"}),": 6-7"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-6-nvidia-isaac-sim-basics",children:"Chapter 6: NVIDIA Isaac Sim Basics"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 8-9 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 8,000 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Advanced"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-4",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Install and configure NVIDIA Isaac Sim (Windows native)"}),"\n",(0,r.jsx)(e.li,{children:"Create USD (Universal Scene Description) scenes"}),"\n",(0,r.jsx)(e.li,{children:"Generate synthetic training data (images, annotations, depth)"}),"\n",(0,r.jsx)(e.li,{children:"Simulate humanoid robots with accurate physics"}),"\n",(0,r.jsx)(e.li,{children:"Use Isaac Sim Python API for automation"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-4",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.1 Introduction: The Isaac Platform"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac Sim"}),": Omniverse-based photorealistic simulator"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac ROS"}),": Hardware-accelerated perception (Chapter 7)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac Gym"}),": RL training (massively parallel GPU simulation)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Why Isaac?"})," RTX ray tracing, synthetic data, NVIDIA AI integration"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.2 Installing Isaac Sim on Windows (Native!)"})}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Windows 10/11 Setup (No WSL2/Docker Needed)"}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-powershell",children:'# 1. Download NVIDIA Omniverse Launcher\r\n# https://www.nvidia.com/en-us/omniverse/download/\r\n\r\n# 2. Install Omniverse Launcher (runs natively on Windows)\r\n\r\n# 3. Inside Launcher: Library \u2192 Install "Isaac Sim"\r\n\r\n# 4. Launch Isaac Sim\r\n# Expected: USD scene opens in viewport\r\n\r\n# System Requirements:\r\n# - NVIDIA RTX GPU (2060 or higher)\r\n# - Windows 10/11 (64-bit)\r\n# - 32 GB RAM (recommended)\n'})})]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Important"}),": Isaac Sim has ",(0,r.jsx)(e.strong,{children:"full Windows support"})," (unlike many Linux-only robotics tools)."]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.3 USD (Universal Scene Description)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Pixar's scene format (used in film VFX)"}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Hierarchy"}),": Stage \u2192 Prims (objects) \u2192 Properties (transforms, materials)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": Create simple USD scene via Python"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from pxr import Usd, UsdGeom\r\n\r\nstage = Usd.Stage.CreateNew("my_scene.usd")\r\nxform = UsdGeom.Xform.Define(stage, "/World")\r\nsphere = UsdGeom.Sphere.Define(stage, "/World/Sphere")\r\nsphere.GetRadiusAttr().Set(0.5)\r\n\r\nstage.Save()\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.4 Isaac Sim GUI Tour"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Viewport"}),": 3D view (real-time ray tracing)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Stage"}),": Hierarchy of objects (similar to Unity/Unreal)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Property Panel"}),": Modify object attributes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Content Browser"}),": Asset library (robots, environments)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.5 Importing Robots"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"URDF Import"}),": File \u2192 Import \u2192 URDF"]}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Fixes joint axes, generates USD representation"})}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": Import Unitree G1 URDF"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import omni.isaac.urdf\r\nurdf_interface = omni.isaac.urdf.get_interface()\r\nurdf_interface.parse_urdf("/path/to/unitree_g1.urdf", "/World/G1")\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.6 Physics Simulation (PhysX 5)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Rigid body dynamics"}),": Mass, inertia, damping"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Articulations"}),": Multi-body robots (optimized solver)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Contacts"}),": Friction, restitution, contact offset"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 3"}),": Configure joint drive (PD controller)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.7 Creating Environments"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Asset Library"}),": Pre-made warehouses, offices, outdoor scenes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Materials"}),": PBR (Physically-Based Rendering) for realism"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Lighting"}),": HDR skydomes, point lights, spotlights"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 4"}),": Build kitchen environment programmatically"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.8 Cameras and Sensors"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RGB Camera"}),": Photorealistic rendering"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Depth Camera"}),": Ray-traced depth"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Segmentation"}),": Instance/semantic masks"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"LIDAR"}),": Ray-traced laser scanning"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 5"}),": Capture annotated images for training"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import omni.replicator.core as rep\r\n\r\ncamera = rep.create.camera(position=(2, 2, 2), look_at=(0, 0, 0))\r\nrender_product = rep.create.render_product(camera, (640, 480))\r\n\r\nwriter = rep.WriterRegistry.get("BasicWriter")\r\nwriter.initialize(output_dir="./output", rgb=True, semantic_segmentation=True)\r\nwriter.attach([render_product])\r\n\r\nrep.orchestrator.run()\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.9 Synthetic Data Generation"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Domain Randomization"}),": Randomize textures, lighting, poses"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Replicator"}),": Isaac's data generation framework"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Use case"}),": Generate 100,000 images for training object detectors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 6"}),": Randomize object positions/colors"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.10 ROS 2 Bridge"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"OmniGraph"}),": Visual scripting for ROS topics"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Publish"}),": Joint states, camera images, LIDAR scans"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Subscribe"}),": Velocity commands, joint commands"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 7"}),": Publish camera feed to ",(0,r.jsx)(e.code,{children:"/camera/image_raw"})]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.11 Python Scripting (Standalone)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Standalone mode"}),": Run Isaac Sim headless (no GUI)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Automation"}),": Batch data generation, CI/CD testing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 8"}),": Spawn 100 robots in parallel scenes"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from omni.isaac.kit import SimulationApp\r\nsimulation_app = SimulationApp({"headless": True})\r\n\r\nfrom omni.isaac.core import World\r\nworld = World()\r\n\r\n# Spawn robots, run simulation\r\nfor i in range(100):\r\n    world.scene.add(robot_factory.create(f"/World/Robot_{i}"))\r\n\r\nwhile True:\r\n    world.step(render=False)\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"6.12 Performance Optimization"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RTX GPUs"}),": 10x faster ray tracing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Multi-GPU"}),": Distribute scenes across GPUs"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"LOD (Level of Detail)"}),": Simplify meshes at distance"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Culling"}),": Don't render off-camera objects"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"exercises-4",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 6.1"}),": Create a USD scene with 50 random objects, capture 1,000 annotated images"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 6.2"}),": Import Unitree G1, make it walk using joint position commands"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 6.3"}),": Measure rendering FPS with different quality settings (RTX on/off, resolution)"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-12-total-1",children:"Citations (12 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["NVIDIA. (2024). ",(0,r.jsx)(e.em,{children:"Isaac Sim Documentation."})," ",(0,r.jsx)(e.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/",children:"https://docs.omniverse.nvidia.com/isaacsim/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Liang, J., et al. (2023). ",(0,r.jsx)(e.em,{children:"Code as Policies: Language Model Programs for Embodied Control."})," ICRA 2023."]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"hardware-requirements-4",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Minimum"}),": NVIDIA RTX 2060, 16 GB RAM (low quality, 20 FPS)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Recommended"}),": NVIDIA RTX 4070, 32 GB RAM (high quality, 60 FPS)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Ideal"}),": NVIDIA RTX 4090, 64 GB RAM (ultra quality, real-time ray tracing)"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"labs-1",children:"Labs"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-06-1-isaac-first-scene"}),": Create kitchen scene, spawn objects, capture RGB-D images"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-06-2-isaac-robot-control"}),": Import humanoid, control joints via ROS 2"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-7-isaac-ros-integration",children:"Chapter 7: Isaac ROS Integration"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 10 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 7,500 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Advanced"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-5",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Install Isaac ROS packages on NVIDIA Jetson"}),"\n",(0,r.jsx)(e.li,{children:"Implement Visual SLAM (VSLAM) with hardware acceleration"}),"\n",(0,r.jsx)(e.li,{children:"Use Isaac ROS for object detection (DOPE, FoundationPose)"}),"\n",(0,r.jsx)(e.li,{children:"Integrate Nav2 for autonomous navigation"}),"\n",(0,r.jsx)(e.li,{children:"Deploy sim-trained policies to real robots"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-5",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.1 Introduction: Why Isaac ROS?"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Problem"}),": ROS perception is CPU-bound (SLAM at 10 Hz, object detection at 2 FPS)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Solution"}),": Isaac ROS uses NVIDIA GPUs (SLAM at 100 Hz, detection at 30 FPS)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Hardware"}),": NVIDIA Jetson Orin (40-275 TOPS AI performance)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.2 Isaac ROS Architecture"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"GXF (Graph Execution Framework)"}),": NVIDIA's dataflow framework"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"NITROS (NVIDIA Isaac Transport for ROS)"}),": Zero-copy message passing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"DNN Inference"}),": TensorRT-optimized models"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.3 Setting Up Jetson Orin"})}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Windows + Jetson Workflow"}),(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"On Windows 10/11"}),":"]}),(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Flash Jetson Orin with JetPack SDK (via NVIDIA SDK Manager)"}),"\n",(0,r.jsxs)(e.li,{children:["Connect via SSH: ",(0,r.jsx)(e.code,{children:"ssh nvidia@<jetson-ip>"})]}),"\n"]}),(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"On Jetson (Linux)"}),":"]}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Install Isaac ROS\r\nsudo apt install ros-humble-isaac-ros-visual-slam\r\n\r\n# Connect RealSense camera\r\nlsusb  # Verify D435i detected\r\n\r\n# Run VSLAM\r\nros2 launch isaac_ros_visual_slam isaac_ros_visual_slam.launch.py\n"})})]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.4 Visual SLAM (VSLAM)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Purpose"}),": Build 3D map while tracking camera pose"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Input"}),": Stereo cameras (left/right images) OR RGB-D camera"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Output"}),": ",(0,r.jsx)(e.code,{children:"/visual_slam/tracking/odometry"})," (robot pose), point cloud"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Performance"}),": 100 Hz on Jetson Orin (vs 10 Hz CPU)"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": Launch VSLAM with RealSense"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"ros2 launch isaac_ros_visual_slam realsense_vslam.launch.py\n"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": Visualize map in RViz"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"ros2 run rviz2 rviz2 -d $(ros2 pkg prefix isaac_ros_visual_slam)/share/isaac_ros_visual_slam/rviz/default.rviz\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.5 Object Detection (DOPE)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"DOPE"}),": Deep Object Pose Estimation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Purpose"}),": Detect objects, estimate 6D pose (position + rotation)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Use case"}),": Grasping (know exact pose of cup for manipulation)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 3"}),": Detect soup cans from camera feed"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.6 FoundationPose (Zero-Shot Detection)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"New approach"}),": No training per object (uses 3D model only)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Input"}),": RGB-D image + CAD model"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Output"}),": 6D pose"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 4"}),": Detect novel objects (e.g., custom tools)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.7 Stereo Depth Estimation"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac ROS ESS (Efficient Stereo Segmentation)"}),": DNN-based depth"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Performance"}),": 30 FPS on Jetson (vs 10 FPS CPU)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 5"}),": Publish depth map to ",(0,r.jsx)(e.code,{children:"/depth/image_raw"})]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.8 Nav2 Integration"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Nav2"}),": ROS 2 navigation stack (path planning, obstacle avoidance)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Costmap"}),": Occupancy grid (free space, obstacles)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Planners"}),": A*, Dijkstra, Theta*, Smac Planner"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Controllers"}),": DWA (Dynamic Window Approach), TEB, MPPI"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Code Example 6"}),": Launch Nav2 with Isaac VSLAM"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"ros2 launch nav2_bringup navigation_launch.py \\\r\n  use_sim_time:=False \\\r\n  slam:=True \\\r\n  slam_params_file:=isaac_vslam_params.yaml\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.9 Bipedal Navigation (Humanoid-Specific)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Challenge"}),": Humanoids have different dynamics than wheeled robots"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Footstep planning"}),": Discrete footstep poses vs continuous paths"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Balance constraints"}),": Center of mass must stay within support polygon"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 7"}),": Footstep planner for Unitree G1"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.10 Sim-to-Real Transfer"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Train in Isaac Sim"})," (infinite data, safe)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Deploy to Jetson"})," (real hardware)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Domain randomization"}),": Bridge sim-real gap"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 8"}),": Load TensorRT model trained in Isaac Sim"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.11 Performance Benchmarks"})}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"Task"})}),(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"CPU (x86)"})}),(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"GPU (Jetson Orin)"})}),(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"Speedup"})})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"VSLAM"}),(0,r.jsx)(e.td,{children:"10 Hz"}),(0,r.jsx)(e.td,{children:"100 Hz"}),(0,r.jsx)(e.td,{children:"10x"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Object Detection"}),(0,r.jsx)(e.td,{children:"2 FPS"}),(0,r.jsx)(e.td,{children:"30 FPS"}),(0,r.jsx)(e.td,{children:"15x"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Depth Estimation"}),(0,r.jsx)(e.td,{children:"5 FPS"}),(0,r.jsx)(e.td,{children:"30 FPS"}),(0,r.jsx)(e.td,{children:"6x"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Segmentation"}),(0,r.jsx)(e.td,{children:"1 FPS"}),(0,r.jsx)(e.td,{children:"20 FPS"}),(0,r.jsx)(e.td,{children:"20x"})]})]})]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"7.12 Debugging Isaac ROS"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"GXF logs"}),": Check ",(0,r.jsx)(e.code,{children:"/tmp/gxf_logs/"})]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"NITROS topics"}),": ",(0,r.jsx)(e.code,{children:"ros2 topic list | grep nitros"})]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Latency profiling"}),": ",(0,r.jsx)(e.code,{children:"ros2 run isaac_ros_common isaac_ros_profiler"})]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"exercises-5",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 7.1"}),": Run VSLAM with RealSense, map your room, save PCD file"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 7.2"}),": Train DOPE on custom object (YCB dataset), deploy to Jetson"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 7.3"}),": Implement Nav2 waypoint navigation, measure success rate over 100 runs"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-15-total-1",children:"Citations (15 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["Tremblay, J., et al. (2018). ",(0,r.jsx)(e.em,{children:"Deep Object Pose Estimation for Semantic Robotic Grasping."})," CoRL 2018."]}),"\n",(0,r.jsxs)(e.li,{children:["NVIDIA. (2024). ",(0,r.jsx)(e.em,{children:"Isaac ROS Documentation."})," ",(0,r.jsx)(e.a,{href:"https://nvidia-isaac-ros.github.io/",children:"https://nvidia-isaac-ros.github.io/"})]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"hardware-requirements-5",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Required"}),": NVIDIA Jetson Orin Nano ($249) OR Orin NX ($399)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Required"}),": Intel RealSense D435i ($349)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Optional"}),": RPLIDAR A1 ($99) for 2D SLAM comparison"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"lab-3",children:"Lab"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-07-1-isaac-ros-vslam"}),": VSLAM with RealSense, map building, localization"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"module-4-vision-language-action-vla--humanoid-development",children:"Module 4: Vision-Language-Action (VLA) & Humanoid Development"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Weeks"}),": 11-13 | ",(0,r.jsx)(e.strong,{children:"Chapters"}),": 8-11"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-8-legged-locomotion",children:"Chapter 8: Legged Locomotion"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 11 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 7,000 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Advanced"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-6",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Understand bipedal kinematics and dynamics"}),"\n",(0,r.jsx)(e.li,{children:"Implement Zero Moment Point (ZMP) balance control"}),"\n",(0,r.jsx)(e.li,{children:"Generate walking gaits using preview control"}),"\n",(0,r.jsx)(e.li,{children:"Train locomotion policies with reinforcement learning"}),"\n",(0,r.jsx)(e.li,{children:"Deploy to Unitree G1 humanoid"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-6",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.1 Introduction: Walking is Hard"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Challenges"}),": 40 DOF, underactuated (no direct control of torso position), contact switching (foot on/off ground)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Comparison"}),": Quadrupeds (statically stable), Bipeds (dynamically stable)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Example"}),": Boston Dynamics Atlas parkour, Unitree G1 stair climbing"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.2 Kinematics"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Forward kinematics"}),": Joint angles \u2192 foot position"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Inverse kinematics"}),": Desired foot position \u2192 joint angles"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Jacobian"}),": Velocity mapping (joint velocities \u2192 end-effector velocity)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": IK for 6-DOF leg (hip, knee, ankle)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.3 Dynamics"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Equations of motion"}),": Lagrangian mechanics, M(q)q\u0308 + C(q,q\u0307) + G(q) = \u03c4"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Centroidal dynamics"}),": Simplified model (whole-body COM + angular momentum)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": Simulate dynamics in PyBullet"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.4 Zero Moment Point (ZMP)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Definition"}),": Point where net moment from gravity and inertia is zero"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Stability criterion"}),": ZMP must be inside support polygon (foot contact area)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 3"}),": Calculate ZMP from COM trajectory"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.5 Gait Generation"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Walking pattern"}),": Swing phase (foot in air) + Stance phase (foot on ground)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Preview control"}),": Plan COM trajectory to keep ZMP stable"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 4"}),": Generate walking trajectory (Kajita et al. 2003 method)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.6 Whole-Body Control"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Hierarchical QP"}),": Optimize joint torques subject to constraints (balance, joint limits, contact forces)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 5"}),": Whole-body controller in Pinocchio library"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.7 Reinforcement Learning for Locomotion"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Training in Isaac Gym"}),": 4,096 parallel environments, 10M steps in 1 hour"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Reward function"}),": Forward velocity, upright posture, low energy"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 6"}),": Train PPO policy for flat-ground walking"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.8 Terrain Adaptation"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Rough terrain"}),": Stepping stones, stairs, slopes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Perception"}),": Height map from stereo camera"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 7"}),": Terrain-aware footstep planner"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.9 Push Recovery"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"External disturbances"}),": Sudden pushes, slippery surfaces"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Strategies"}),": Step, ankle torque, hip torque"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 8"}),": Detect fall, trigger recovery step"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"8.10 Sim-to-Real (Unitree G1)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Domain randomization"}),": Mass, friction, motor delays"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"System identification"}),": Measure real robot parameters"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 9"}),": Deploy policy to G1, measure success rate"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"exercises-6",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 8.1"}),": Implement IK for humanoid leg, verify with visualization"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 8.2"}),": Generate 10-step walking trajectory, plot ZMP and COM"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 8.3"}),": Train RL policy for stair climbing, evaluate in simulation"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-18-total",children:"Citations (18 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["Kajita, S., et al. (2003). ",(0,r.jsx)(e.em,{children:"Biped walking pattern generation by using preview control of zero-moment point."})," ICRA 2003."]}),"\n",(0,r.jsxs)(e.li,{children:["Vukobratovi\u0107, M., & Borovac, B. (2004). ",(0,r.jsx)(e.em,{children:"Zero-moment point\u2014thirty five years of its life."})," International Journal of Humanoid Robotics."]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"hardware-requirements-6",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Simulation"}),": Any PC with GPU (Isaac Gym: RTX 3060+)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Real robot"}),": Unitree G1 ($16,000) - optional, shared lab resource"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"lab-4",children:"Lab"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-08-1-zmp-walking"}),": Generate walking gait, visualize ZMP stability"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-08-2-rl-locomotion"}),": Train PPO policy in Isaac Gym, deploy to simulation"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-9-manipulation--grasping",children:"Chapter 9: Manipulation & Grasping"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 12 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 6,800 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Advanced"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-7",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Solve inverse kinematics for robot arms"}),"\n",(0,r.jsx)(e.li,{children:"Plan collision-free trajectories with MoveIt 2"}),"\n",(0,r.jsx)(e.li,{children:"Implement grasp planning algorithms"}),"\n",(0,r.jsx)(e.li,{children:"Use force control for compliant manipulation"}),"\n",(0,r.jsx)(e.li,{children:"Integrate vision (object detection) + manipulation"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-7",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"9.1 Introduction: Manipulation Challenges"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Kinematics"}),": 7-DOF arm (redundant), IK has infinite solutions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Grasp stability"}),": Force closure, contact points"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Deformable objects"}),": Cloth, food, soft materials"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"9.2 Forward/Inverse Kinematics"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"DH parameters"}),": Denavit-Hartenberg convention"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Numerical IK"}),": Jacobian pseudoinverse, damped least squares"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": IK for 7-DOF arm (PyKDL library)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"9.3 MoveIt 2"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Motion planning"}),": RRT, RRT*, OMPL library"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Collision checking"}),": FCL (Flexible Collision Library)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": Plan trajectory from current pose to goal pose"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import moveit_commander\r\n\r\narm = moveit_commander.MoveGroupCommander("manipulator")\r\narm.set_pose_target([0.5, 0.2, 0.3, 0, 0, 0, 1])  # x,y,z, quat\r\nplan = arm.plan()\r\narm.execute(plan)\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"9.4 Grasp Planning"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Parallel-jaw gripper"}),": Approach direction, grasp width"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Antipodal grasps"}),": Force closure condition"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 3"}),": Sample grasp poses for cylinder (GPD library)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"9.5 GraspNet / Contact-GraspNet"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Learning-based"}),": DNN predicts grasp poses from point cloud"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Training data"}),": Synthetic grasps in Isaac Sim"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 4"}),": Infer grasps from RealSense depth image"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"9.6 Force Control"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Admittance control"}),": Respond to contact forces"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Use case"}),": Inserting peg in hole, wiping table"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 5"}),": Implement admittance controller"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"9.7 Visual Servoing"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Eye-in-hand"}),": Camera on end-effector"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"PBVS (Position-Based)"}),": Estimate object pose \u2192 move to goal"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 6"}),": Visual servoing to grasp detected object"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"9.8 Dual-Arm Manipulation"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Coordination"}),": Both arms work together"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Use case"}),": Carry large box, open jar (one hand holds, one unscrews)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 7"}),": Coordinate two MoveIt groups"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"9.9 Whole-Body Manipulation"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Mobile manipulator"}),": Use base + arms (redundancy)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 8"}),": Reach high shelf (stand on toes + extend arm)"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"exercises-7",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 9.1"}),": Implement IK, compare 5 IK solvers (speed, success rate)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 9.2"}),": Use MoveIt to stack 3 blocks, measure success rate"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 9.3"}),": Train GraspNet on YCB dataset, test on 10 novel objects"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-12-total-2",children:"Citations (12 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["Salisbury, J. K., & Roth, B. (1983). ",(0,r.jsx)(e.em,{children:"Kinematic and force analysis of articulated mechanical hands."})," Journal of Mechanisms."]}),"\n",(0,r.jsxs)(e.li,{children:["Chitta, S., et al. (2012). ",(0,r.jsx)(e.em,{children:"MoveIt! [ROS Topics]."})," IEEE RAM."]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"hardware-requirements-7",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Simulation"}),": Any PC (MoveIt works in Gazebo/RViz)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Real robot"}),": Franka Emika Panda ($25k) OR Unitree Z1 arm ($3k)"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"lab-5",children:"Lab"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-09-1-moveit-planning"}),": Pick-and-place with MoveIt 2"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-09-2-grasp-planning"}),": GraspNet inference, execute grasps in sim"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-10-vision-language-action-vla-models",children:"Chapter 10: Vision-Language-Action (VLA) Models"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 13 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 8,500 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Advanced"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-8",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Understand Vision-Language-Action model architecture"}),"\n",(0,r.jsx)(e.li,{children:"Implement voice interfaces with OpenAI Whisper"}),"\n",(0,r.jsx)(e.li,{children:"Use LLMs to plan robot actions (natural language \u2192 ROS)"}),"\n",(0,r.jsx)(e.li,{children:"Deploy RT-2 / OpenVLA for robotic control"}),"\n",(0,r.jsx)(e.li,{children:"Build end-to-end voice-controlled robot"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-8",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.1 Introduction: From Chatbots to Robots"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"LLMs"}),": GPT-4, Claude excel at text reasoning"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"VLAs"}),": Extend LLMs to control robots (input: image + text, output: actions)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Key papers"}),": RT-1 (Google, 2022), RT-2 (Google, 2023), OpenVLA (2024)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.2 VLA Architecture"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Vision encoder"}),": ViT (Vision Transformer) processes camera images"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Language encoder"}),': LLM processes instructions ("pick up the cup")']}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Action decoder"}),": Predict robot actions (joint positions, gripper open/close)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Diagram"}),": RT-2 architecture"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.3 Voice-to-Text (OpenAI Whisper)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Speech recognition"}),": Audio \u2192 text transcription"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": Record voice, transcribe with Whisper"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import whisper\r\n\r\nmodel = whisper.load_model("base")\r\nresult = model.transcribe("audio.mp3")\r\nprint(result["text"])\r\n# Output: "Robot, pick up the red block"\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.4 Language-to-Action Planning (GPT-4)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Prompt engineering"}),": Give LLM robot capabilities"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": GPT-4 plans action sequence"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import openai\r\n\r\nprompt = """\r\nYou are a robot controller. Available actions:\r\n- navigate_to(location)\r\n- grasp_object(object_name)\r\n- place_object(location)\r\n\r\nUser command: "Bring me a water bottle from the kitchen"\r\nOutput a JSON list of actions.\r\n"""\r\n\r\nresponse = openai.ChatCompletion.create(\r\n    model="gpt-4",\r\n    messages=[{"role": "user", "content": prompt}]\r\n)\r\n\r\nactions = json.loads(response.choices[0].message.content)\r\n# [{"action": "navigate_to", "location": "kitchen"},\r\n#  {"action": "grasp_object", "object": "water bottle"},\r\n#  {"action": "navigate_to", "location": "user"}]\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.5 Executing Actions with ROS 2"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Action bridge"}),": Convert LLM output \u2192 ROS action calls"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 3"}),": Execute action sequence via Nav2 + MoveIt"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.6 RT-2: Vision-Language-Action Model"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Training data"}),": Web images + robotic demonstrations"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Transfer learning"}),': Use web knowledge (never seen scissors, but knows "cutting tool")']}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 4"}),": Run RT-2 inference (requires TPU/GPU cluster)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.7 OpenVLA (Open-Source Alternative)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Model"}),": 7B parameters, trained on Open X-Embodiment dataset"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Deployment"}),": Runs on NVIDIA Jetson Orin"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 5"}),": Deploy OpenVLA to Unitree G1"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from openvla import OpenVLA\r\n\r\nmodel = OpenVLA.load("openvla-7b")\r\nimage = camera.capture()  # RGB image\r\ninstruction = "pick up the cup"\r\n\r\naction = model.predict(image, instruction)\r\nrobot.execute(action)  # [x, y, z, roll, pitch, yaw, gripper]\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.8 Multi-Modal Interaction"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Speech + Gesture"}),': "Pick up that" (points at object)']}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Vision + Language"}),': "Grasp the red object" (requires object detection)']}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 6"}),": Combine Whisper + YOLO + GPT-4"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.9 Error Recovery"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Failure detection"}),": If grasp fails, LLM replans"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 7"}),": Retry logic with GPT-4 feedback"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"10.10 Safety and Alignment"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Challenges"}),": LLM hallucinates, outputs unsafe actions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Mitigations"}),": Action bounds, human-in-the-loop confirmation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 8"}),": Filter LLM actions through safety checker"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"exercises-8",children:"Exercises"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 10.1"}),": Implement voice interface (Whisper + TTS feedback)"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 10.2"}),": Use GPT-4 to plan multi-step task, execute in Gazebo"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Exercise 10.3"}),": Fine-tune OpenVLA on custom task (10 demonstrations)"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-20-total",children:"Citations (20 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["Brohan, A., et al. (2023). ",(0,r.jsx)(e.em,{children:"RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control."})," CoRL 2023."]}),"\n",(0,r.jsxs)(e.li,{children:["Radford, A., et al. (2023). ",(0,r.jsx)(e.em,{children:"Robust Speech Recognition via Large-Scale Weak Supervision (Whisper)."})," ICML 2023."]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"hardware-requirements-8",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Whisper"}),": Any PC (CPU-only works, slow but functional)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"GPT-4 API"}),": Internet connection, OpenAI API key (~$0.03 per request)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"OpenVLA"}),": NVIDIA Jetson Orin (16GB VRAM) OR RTX 4090"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"lab-6",children:"Lab"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"lab-10-1-voice-control"}),": Whisper \u2192 GPT-4 \u2192 ROS actions (pick-and-place)"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-11-capstone-project",children:"Chapter 11: Capstone Project"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Week"}),": 13 | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 5,000 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": Capstone"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-9",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Integrate all course modules (ROS 2, Gazebo, Isaac, VLA)"}),"\n",(0,r.jsx)(e.li,{children:"Design and implement a complete autonomous system"}),"\n",(0,r.jsx)(e.li,{children:"Evaluate performance with quantitative metrics"}),"\n",(0,r.jsx)(e.li,{children:"Present results professionally"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"project-specification",children:"Project Specification"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Title"}),": Voice-Controlled Autonomous Humanoid"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Scenario"}),": A simulated Unitree G1 humanoid receives a voice command from a human, plans a sequence of actions, navigates to a table, identifies an object using vision, grasps it, and brings it to the user."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"System Components"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Voice Interface"})," (Whisper): Transcribe user command"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Task Planning"})," (GPT-4): Decompose command into ROS actions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Navigation"})," (Nav2 + Isaac VSLAM): Navigate to table"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Perception"})," (YOLO + FoundationPose): Detect and localize object"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Manipulation"})," (MoveIt 2): Grasp object"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Execution"}),": Deliver to user"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Example Commands"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:'"Robot, bring me the red cup from the table"'}),"\n",(0,r.jsx)(e.li,{children:'"Clean the table by moving all objects to the bin"'}),"\n",(0,r.jsx)(e.li,{children:'"Find the remote control and hand it to me"'}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"deliverables",children:"Deliverables"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"1. System Design Document"})," (10 pages)"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Architecture diagram (all nodes, topics, actions)"}),"\n",(0,r.jsx)(e.li,{children:"Failure modes and mitigations"}),"\n",(0,r.jsx)(e.li,{children:"Performance targets (latency, success rate)"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"2. Implementation"})," (Code + Docker)"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"All ROS 2 packages"}),"\n",(0,r.jsx)(e.li,{children:"Launch files for full system"}),"\n",(0,r.jsx)(e.li,{children:"Dockerized for reproducibility"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"3. Evaluation"})," (Quantitative)"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Metrics"}),":","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Success rate (20 trials, varied commands)"}),"\n",(0,r.jsx)(e.li,{children:"Time to completion"}),"\n",(0,r.jsx)(e.li,{children:"Navigation accuracy (< 10cm error)"}),"\n",(0,r.jsx)(e.li,{children:"Grasp success rate"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Report"}),": Tables, graphs, statistical analysis"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"4. Video Demonstration"})," (3-5 minutes)"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Show 3 successful runs (different commands)"}),"\n",(0,r.jsx)(e.li,{children:"Narrate system behavior"}),"\n",(0,r.jsx)(e.li,{children:"Discuss one failure case + proposed fix"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"5. Presentation"})," (10 minutes)"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Slides covering motivation, approach, results, lessons learned"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"grading-rubric-100-points",children:"Grading Rubric (100 points)"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"Category"})}),(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"Points"})}),(0,r.jsx)(e.th,{children:(0,r.jsx)(e.strong,{children:"Criteria"})})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"System Design"}),(0,r.jsx)(e.td,{children:"20"}),(0,r.jsx)(e.td,{children:"Clear architecture, justified design choices"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Implementation Quality"}),(0,r.jsx)(e.td,{children:"25"}),(0,r.jsx)(e.td,{children:"Clean code, ROS best practices, Dockerized"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Functionality"}),(0,r.jsx)(e.td,{children:"30"}),(0,r.jsx)(e.td,{children:"System works (\u226570% success rate on test set)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Evaluation"}),(0,r.jsx)(e.td,{children:"15"}),(0,r.jsx)(e.td,{children:"Rigorous metrics, statistical analysis"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Presentation"}),(0,r.jsx)(e.td,{children:"10"}),(0,r.jsx)(e.td,{children:"Clear communication, polished video"})]})]})]}),"\n",(0,r.jsx)(e.h4,{id:"starter-code",children:"Starter Code"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Provided"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"ROS 2 package template"}),"\n",(0,r.jsx)(e.li,{children:"Gazebo world with table + objects"}),"\n",(0,r.jsx)(e.li,{children:"URDF for Unitree G1"}),"\n",(0,r.jsx)(e.li,{children:"Sample voice commands dataset"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"You Implement"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Voice \u2192 Action planner"}),"\n",(0,r.jsx)(e.li,{children:"Navigation + Obstacle avoidance"}),"\n",(0,r.jsx)(e.li,{children:"Vision \u2192 Grasp pipeline"}),"\n",(0,r.jsx)(e.li,{children:"Full integration"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"timeline",children:"Timeline"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Week 13, Day 1-2"}),": Design document"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Week 13, Day 3-5"}),": Implementation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Week 13, Day 6"}),": Evaluation + Video"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Week 13, Day 7"}),": Presentation"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"example-projects-inspiration",children:"Example Projects (Inspiration)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:'"Coffee Fetch"'}),": Robot navigates kitchen, identifies coffee mug via vision, grasps, delivers to user"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:'"Table Cleanup"'}),": Robot detects scattered objects, plans order to move them to bin, executes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:'"Tool Handover"'}),": User asks for screwdriver, robot searches workshop, identifies tool, hands it over"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"tips-for-success",children:"Tips for Success"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Start simple"}),": Get teleoperation working first, then add autonomy"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Test incrementally"}),": Test each module (Whisper, Nav2, MoveIt) in isolation before integration"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Use simulation"}),": Debug in Gazebo/Isaac before deploying to real robot (if available)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Failure analysis"}),": Every failure teaches you something\u2014document and fix"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"part-5-hardware-ethics-and-future",children:"Part 5: Hardware, Ethics, and Future"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Post-Quarter Reference"})," | ",(0,r.jsx)(e.strong,{children:"Chapters"}),": 12-13"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-12-hardware-guide",children:"Chapter 12: Hardware Guide"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Reference"})," | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 9,000 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": All Levels"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-10",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Choose appropriate hardware for your goals and budget"}),"\n",(0,r.jsx)(e.li,{children:"Build a workstation optimized for robotics simulation"}),"\n",(0,r.jsx)(e.li,{children:"Set up NVIDIA Jetson for edge AI deployment"}),"\n",(0,r.jsx)(e.li,{children:"Configure RealSense cameras, LIDAR, IMUs"}),"\n",(0,r.jsx)(e.li,{children:"Compare cloud vs on-premise infrastructure"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-9",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.1 Introduction: Investment Tiers"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Tier 1"}),": Cloud-Only ($205/quarter + $1,118 one-time)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Tier 2"}),": Budget Workstation + Edge Kit ($3,500 one-time)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Tier 3"}),": Premium Research Lab ($15,000+)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.2 Tier 1: Cloud-Only Setup"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"AWS g5.2xlarge"}),": A10G GPU (24GB VRAM), 8 vCPU, 32 GB RAM"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Workflow"}),": Train in cloud, deploy to local Jetson"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Cost analysis"}),": $1.50/hour \xd7 120 hours = $180/quarter"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 1"}),": Launch EC2 instance, install Isaac Sim"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.3 Tier 2: Budget Workstation Build"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Part list"})," (exact models, prices, vendor links):","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"GPU: NVIDIA RTX 4070 Ti 12GB ($800 - Newegg)"}),"\n",(0,r.jsx)(e.li,{children:"CPU: Intel Core i7-13700K ($400 - Amazon)"}),"\n",(0,r.jsx)(e.li,{children:"RAM: Corsair Vengeance DDR5 32GB ($120 - Amazon)"}),"\n",(0,r.jsx)(e.li,{children:"SSD: Samsung 980 Pro 1TB NVMe ($80 - Amazon)"}),"\n",(0,r.jsx)(e.li,{children:"Motherboard: ASUS TUF Z790 ($220 - Newegg)"}),"\n",(0,r.jsx)(e.li,{children:"PSU: EVGA 850W Gold ($100 - Amazon)"}),"\n",(0,r.jsx)(e.li,{children:"Case: NZXT H510 ($80 - Amazon)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Total"}),": $1,800"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Build guide"}),": Step-by-step assembly photos"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.4 Tier 3: Premium Lab (RTX 4090 + Unitree G1)"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Workstation"}),": RTX 4090 24GB, AMD Ryzen 9 7950X, 64GB RAM ($3,500)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Robot"}),": Unitree G1 Humanoid ($16,000)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensors"}),": RealSense L515 LIDAR ($950), Force/torque sensors ($2,500)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.5 NVIDIA Jetson Ecosystem"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Jetson Orin Nano Super"}),": 8GB, 40 TOPS, $249 (NEW 2024 price drop!)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Jetson Orin NX"}),": 16GB, 100 TOPS, $599"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Jetson AGX Orin"}),": 64GB, 275 TOPS, $1,999"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Comparison table"}),": TOPS, memory, power, use case"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.6 Jetson Setup (Windows \u2192 Jetson Workflow)"})}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Flash JetPack from Windows"}),(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"On Windows 10/11"}),":"]}),(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Download NVIDIA SDK Manager (Windows version)"}),"\n",(0,r.jsx)(e.li,{children:"Connect Jetson via USB-C (force recovery mode)"}),"\n",(0,r.jsx)(e.li,{children:"Flash JetPack 5.1.2 (Ubuntu 20.04 + ROS 2 Humble)"}),"\n",(0,r.jsxs)(e.li,{children:["SSH into Jetson: ",(0,r.jsx)(e.code,{children:"ssh nvidia@192.168.55.1"})]}),"\n"]})]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.7 Intel RealSense D435i"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Specs"}),": Stereo depth (640\xd7480 @ 90fps), RGB (1920\xd71080 @ 30fps), IMU"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Use case"}),": VSLAM, object detection, obstacle avoidance"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Code Example 2"}),": RealSense + Jetson + Isaac ROS VSLAM"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.8 LIDAR Options"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RPLIDAR A1"}),": 2D, 12m range, $99 (budget)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Livox Mid-360"}),": 3D, 70m range, $599 (mid-tier)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Velodyne VLP-16"}),": 3D, 100m range, $4,000 (premium)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.9 IMU Selection"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"MPU6050"}),": $2 (hobby projects)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"BNO055"}),": $20 (sensor fusion built-in)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"VectorNav VN-100"}),": $750 (GPS + IMU, research-grade)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.10 Robot Platforms"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Unitree Go2 Edu"}),": Quadruped, $2,500 (best proxy for humanoid)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Unitree G1"}),": Humanoid, $16,000 (most affordable research humanoid)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"TurtleBot4"}),": Wheeled, $1,200 (ROS 2 education platform)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.11 Power Budget"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Workstation"}),": RTX 4070 Ti (285W) + CPU (125W) = ~450W total"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Jetson Orin Nano"}),": 7-15W (incredibly efficient!)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Robot"}),": Unitree G1 battery (2 hours runtime)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.12 Cloud vs On-Premise: TCO Analysis"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"3-year total cost"})," (simulation workload: 10 hours/week):","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Cloud: $180/quarter \xd7 12 quarters = $2,160"}),"\n",(0,r.jsx)(e.li,{children:"On-premise: $1,800 (workstation) + $50/year (electricity) = $1,950"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Breakeven"}),": ~10 quarters (2.5 years)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"12.13 Recommended Setups by Role"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Undergraduate Student"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Option A"}),": GitHub Codespaces (free 60 hours/month) + Jetson Orin Nano ($249)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Option B"}),": Budget workstation ($1,800) if planning multi-year use"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Graduate Researcher"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Budget workstation"})," ($1,800) + ",(0,r.jsx)(e.strong,{children:"Jetson Orin NX"})," ($599) + ",(0,r.jsx)(e.strong,{children:"RealSense D435i"})," ($349)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Total"}),": $2,748"]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Industry Lab"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Premium workstation"})," ($3,500) + ",(0,r.jsx)(e.strong,{children:"Unitree G1"})," ($16,000) + ",(0,r.jsx)(e.strong,{children:"Full sensor suite"})," ($1,500)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Total"}),": $21,000"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"appendices",children:"Appendices"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Appendix A"}),": Part links (PCPartPicker lists)\r\n",(0,r.jsx)(e.strong,{children:"Appendix B"}),": Troubleshooting (GPU not detected, CUDA errors)\r\n",(0,r.jsx)(e.strong,{children:"Appendix C"}),": Vendor contacts (Unitree, NVIDIA, Intel RealSense)"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-8-total-1",children:"Citations (8 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["NVIDIA. (2024). ",(0,r.jsx)(e.em,{children:"Jetson Orin Modules and Developer Kits."})," ",(0,r.jsx)(e.a,{href:"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/",children:"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Intel. (2023). ",(0,r.jsx)(e.em,{children:"RealSense D400 Series Datasheet."})," ",(0,r.jsx)(e.a,{href:"https://www.intelrealsense.com/",children:"https://www.intelrealsense.com/"})]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"chapter-13-ethics--future-of-physical-ai",children:"Chapter 13: Ethics & Future of Physical AI"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Reference"})," | ",(0,r.jsx)(e.strong,{children:"Word Count"}),": 6,000 | ",(0,r.jsx)(e.strong,{children:"Difficulty"}),": All Levels"]}),"\n",(0,r.jsx)(e.h4,{id:"learning-objectives-11",children:"Learning Objectives"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Identify ethical challenges in embodied AI (safety, bias, job displacement)"}),"\n",(0,r.jsx)(e.li,{children:"Understand AI safety principles for physical systems"}),"\n",(0,r.jsx)(e.li,{children:"Analyze societal impact of humanoid robots"}),"\n",(0,r.jsx)(e.li,{children:"Predict future directions of Physical AI research"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"section-outline-10",children:"Section Outline"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.1 Introduction: When AI Enters the World"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Digital AI"}),": Errors are annoying (wrong answer, offensive output)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Physical AI"}),": Errors are dangerous (robot collision, wrong medication)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Stakes"}),": Human safety, property damage, legal liability"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.2 Safety: The Asimov Problem"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Three Laws of Robotics"})," (Asimov, 1942): Don't harm humans, obey orders (unless harm), self-preservation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Reality"}),": Vague, unenforceable, impossible to formalize"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Modern approach"}),": Robust control, fail-safes, human-in-the-loop"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.3 Physical Safety"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Collision avoidance"}),": Humans are unpredictable, must have safety margins"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Emergency stop"}),": Hardware kill switch (required by ISO 10218)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Force limits"}),": Collaborative robots (cobots) must limit contact force (less than 150N)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Case study"}),": Tesla autopilot crashes, lessons learned"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.4 Bias in Embodied AI"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Training data"}),": If VLA trained on data from wealthy homes, may fail in low-income settings"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Example"}),": Hand soap dispenser that doesn't detect dark skin (optical sensor bias)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Mitigation"}),": Diverse training data, fairness audits"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.5 Privacy & Surveillance"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Robots with cameras"}),": Constant recording in homes, workplaces"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Data ownership"}),": Who owns video of you in a restaurant where a robot works?"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Regulation"}),": GDPR (EU), CCPA (California) implications"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.6 Job Displacement"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Warehouse automation"}),": Amazon replacing pickers with robots"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Food service"}),": Flippy (burger-flipping robot), autonomous delivery"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Prediction"}),": 85 million jobs displaced by 2025 (World Economic Forum)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Counterargument"}),": 97 million new jobs created (robot maintenance, AI training)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.7 Dual-Use Concerns"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Military applications"}),": Boston Dynamics Spot with gun mount (controversy)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Autonomous weapons"}),": Loitering munitions, drone swarms"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Treaties"}),": Campaign to Stop Killer Robots"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.8 Alignment: What Do We Want Robots to Do?"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Value alignment"}),": Whose values? Cultural differences (individualism vs collectivism)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Example"}),": Should a robot lie to protect feelings?"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.9 Regulation & Standards"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ISO 10218"}),": Safety requirements for industrial robots"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"IEEE 7000"}),": Ethical considerations in system design"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"EU AI Act"}),": High-risk AI systems (including robots) require audits"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.10 Future: Next 10 Years"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"2025-2030"}),": Humanoid robots in warehouses, factories (Agility Digit, Figure 01)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"2030-2035"}),": Home assistants (elderly care, cleaning)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"2035+"}),": Human-level dexterity, conversational intelligence"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.11 Research Frontiers"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Soft robotics"}),": Compliant, safe for human interaction"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Morphological computation"}),": Body design as part of intelligence"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Lifelong learning"}),": Robots that continuously improve from experience"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"13.12 Call to Action"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Build responsibly"}),": Prioritize safety, transparency, fairness"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Engage with policy"}),": Researchers should inform regulation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Interdisciplinary work"}),": Collaborate with ethicists, social scientists, lawyers"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"discussion-questions",children:"Discussion Questions"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Should humanoid robots be anthropomorphic (human-like) or clearly robotic? (Trust, uncanny valley)"}),"\n",(0,r.jsx)(e.li,{children:"Who is liable when a robot causes harm? (Manufacturer, operator, robot itself?)"}),"\n",(0,r.jsx)(e.li,{children:"Should there be limits on robot capabilities? (e.g., ban autonomous weapons)"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"citations-15-total-2",children:"Citations (15 total)"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["Asimov, I. (1950). ",(0,r.jsx)(e.em,{children:"I, Robot."})," Gnome Press."]}),"\n",(0,r.jsxs)(e.li,{children:["Calo, R. (2015). ",(0,r.jsx)(e.em,{children:"Robotics and the Lessons of Cyberlaw."})," California Law Review."]}),"\n",(0,r.jsxs)(e.li,{children:["World Economic Forum. (2020). ",(0,r.jsx)(e.em,{children:"The Future of Jobs Report 2020."})," ",(0,r.jsx)(e.a,{href:"https://www.weforum.org/",children:"https://www.weforum.org/"})]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"End of Outlines Document"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Total Word Count"})," (estimated): 90,000 - 95,000 words across 12 chapters"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Next Step"}),": Review these outlines, suggest changes, approve for full chapter creation."]})]})}function h(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(a,{...n})}):a(n)}}}]);