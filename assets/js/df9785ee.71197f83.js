"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[5274],{968:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"08-legged-locomotion","title":"Chapter 8: Legged Locomotion","description":"\\"Walking on two legs is the hardest thing a robot can do\u2014and the most human.\\"","source":"@site/docs/08-legged-locomotion.mdx","sourceDirName":".","slug":"/08-legged-locomotion","permalink":"/physical-ai-textbook/docs/08-legged-locomotion","draft":false,"unlisted":false,"editUrl":"https://github.com/Shumailaaijaz/physical-ai-textbook/tree/main/docs/08-legged-locomotion.mdx","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"id":"08-legged-locomotion","title":"Chapter 8: Legged Locomotion","sidebar_position":8,"part":4,"week":11,"difficulty_levels":["advanced"],"hardware_tracks":["simulation_only","research_grade"],"citation_count":18,"word_count":7000,"urdu_completeness":0},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 7: Isaac ROS Integration","permalink":"/physical-ai-textbook/docs/07-isaac-ros-integration"},"next":{"title":"Chapter 9: Manipulation & Grasping","permalink":"/physical-ai-textbook/docs/09-manipulation-grasping"}}');var t=r(4848),o=r(8453);const s={id:"08-legged-locomotion",title:"Chapter 8: Legged Locomotion",sidebar_position:8,part:4,week:11,difficulty_levels:["advanced"],hardware_tracks:["simulation_only","research_grade"],citation_count:18,word_count:7e3,urdu_completeness:0},a="Chapter 8: Legged Locomotion",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"8.1 Introduction: Walking is Hard",id:"81-introduction-walking-is-hard",level:2},{value:"8.1.1 State of the Art",id:"811-state-of-the-art",level:3},{value:"8.2 Kinematics",id:"82-kinematics",level:2},{value:"8.2.1 Forward Kinematics (FK)",id:"821-forward-kinematics-fk",level:3},{value:"8.2.2 Inverse Kinematics (IK)",id:"822-inverse-kinematics-ik",level:3},{value:"8.2.3 Jacobian",id:"823-jacobian",level:3},{value:"8.3 Dynamics",id:"83-dynamics",level:2},{value:"8.3.1 Equations of Motion",id:"831-equations-of-motion",level:3},{value:"8.3.2 Centroidal Dynamics",id:"832-centroidal-dynamics",level:3},{value:"8.4 Zero Moment Point (ZMP)",id:"84-zero-moment-point-zmp",level:2},{value:"8.4.1 Why ZMP Matters",id:"841-why-zmp-matters",level:3},{value:"8.4.2 Calculating ZMP",id:"842-calculating-zmp",level:3},{value:"8.4.3 ZMP Stability",id:"843-zmp-stability",level:3},{value:"8.5 Gait Generation",id:"85-gait-generation",level:2},{value:"8.5.1 Walking Phases",id:"851-walking-phases",level:3},{value:"8.5.2 Preview Control (Kajita et al. 2003)",id:"852-preview-control-kajita-et-al-2003",level:3},{value:"8.5.3 Footstep Planning",id:"853-footstep-planning",level:3},{value:"8.6 Whole-Body Control",id:"86-whole-body-control",level:2},{value:"8.6.1 Hierarchical Quadratic Programming (QP)",id:"861-hierarchical-quadratic-programming-qp",level:3},{value:"8.7 Reinforcement Learning for Locomotion",id:"87-reinforcement-learning-for-locomotion",level:2},{value:"8.7.1 Training in Isaac Gym",id:"871-training-in-isaac-gym",level:3},{value:"8.7.2 Reward Function",id:"872-reward-function",level:3},{value:"8.7.3 Training Script (Isaac Gym)",id:"873-training-script-isaac-gym",level:3},{value:"8.8 Terrain Adaptation",id:"88-terrain-adaptation",level:2},{value:"8.8.1 Height Map Perception",id:"881-height-map-perception",level:3},{value:"8.8.2 Footstep Planning on Terrain",id:"882-footstep-planning-on-terrain",level:3},{value:"8.9 Push Recovery",id:"89-push-recovery",level:2},{value:"8.9.1 Detecting Disturbances",id:"891-detecting-disturbances",level:3},{value:"8.9.2 Recovery Step",id:"892-recovery-step",level:3},{value:"8.10 Sim-to-Real (Unitree G1)",id:"810-sim-to-real-unitree-g1",level:2},{value:"8.10.1 Domain Randomization",id:"8101-domain-randomization",level:3},{value:"8.10.2 Deployment to G1",id:"8102-deployment-to-g1",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 8.1: Implement IK for Humanoid Leg",id:"exercise-81-implement-ik-for-humanoid-leg",level:3},{value:"Exercise 8.2: Generate Walking Trajectory",id:"exercise-82-generate-walking-trajectory",level:3},{value:"Exercise 8.3: Train RL Policy for Stair Climbing",id:"exercise-83-train-rl-policy-for-stair-climbing",level:3},{value:"Citations",id:"citations",level:2},{value:"Hardware Requirements",id:"hardware-requirements",level:2},{value:"Labs",id:"labs",level:2}];function d(n){const e={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"chapter-8-legged-locomotion",children:"Chapter 8: Legged Locomotion"})}),"\n",(0,t.jsxs)(e.blockquote,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.em,{children:'"Walking on two legs is the hardest thing a robot can do\u2014and the most human."'})}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.strong,{children:"Understand bipedal kinematics and dynamics"})}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Implement Zero Moment Point (ZMP)"})," balance control"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Generate walking gaits"})," using preview control"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Train locomotion policies"})," with reinforcement learning"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Deploy to Unitree G1"})," humanoid (simulation)"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Estimated Time"}),": 10-12 hours (reading + labs)"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"81-introduction-walking-is-hard",children:"8.1 Introduction: Walking is Hard"}),"\n",(0,t.jsxs)(e.p,{children:["A human child takes ",(0,t.jsx)(e.strong,{children:"12 months"})," to learn to walk. A humanoid robot faces the same challenge:"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Challenges"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"High DOF"}),": Unitree G1 has 23 actuated joints (6 per leg, 7 per arm, 3 torso)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Underactuated"}),": Cannot directly control torso position (only joint torques)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Contact switching"}),": Foot contacts change rapidly (swing \u2192 stance \u2192 swing)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Balance"}),": Must maintain center of mass (COM) within support polygon"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Disturbances"}),": External pushes, uneven terrain, slippery surfaces"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Comparison"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Quadrupeds"})," (4 legs): Statically stable (3+ feet always on ground)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Bipeds"})," (2 legs): Dynamically stable (must keep moving to stay upright, like cycling)"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"811-state-of-the-art",children:"8.1.1 State of the Art"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Boston Dynamics Atlas"})," (2023):"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Parkour: Backflips, jumping over obstacles"}),"\n",(0,t.jsx)(e.li,{children:"Recovery: Withstands 20kg push from any direction"}),"\n",(0,t.jsx)(e.li,{children:"Terrain: Walks on ice, mud, stairs, stepping stones"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Unitree G1"})," (2024):"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Walking speed: 2 m/s (7.2 km/h)"}),"\n",(0,t.jsx)(e.li,{children:"Stairs: Up to 20cm step height"}),"\n",(0,t.jsx)(e.li,{children:"Push recovery: 10kg lateral push"}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Price"}),": $16,000 (most affordable research humanoid)"]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"82-kinematics",children:"8.2 Kinematics"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Kinematics"})," describes motion without considering forces."]}),"\n",(0,t.jsx)(e.h3,{id:"821-forward-kinematics-fk",children:"8.2.1 Forward Kinematics (FK)"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Problem"}),": Given joint angles \u03b8\u2081, \u03b8\u2082, ..., \u03b8\u2099, find foot position (x, y, z)."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Example"}),": Humanoid leg (6 DOF):"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"Hip Roll (\u03b8\u2081) \u2192 Hip Pitch (\u03b8\u2082) \u2192 Hip Yaw (\u03b8\u2083) \u2192 Knee (\u03b8\u2084) \u2192 Ankle Pitch (\u03b8\u2085) \u2192 Ankle Roll (\u03b8\u2086)\n"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"FK Equation"})," (simplified for 2D):"]}),"\n",(0,t.jsx)(e.p,{children:"For a 2-link leg:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Link 1 (thigh): length L\u2081 = 0.4m"}),"\n",(0,t.jsx)(e.li,{children:"Link 2 (shin): length L\u2082 = 0.4m"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Foot position:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"x = L\u2081 cos(\u03b8\u2081) + L\u2082 cos(\u03b8\u2081 + \u03b8\u2082)\r\ny = L\u2081 sin(\u03b8\u2081) + L\u2082 sin(\u03b8\u2081 + \u03b8\u2082)\n"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Code Example"}),": FK for 6-DOF leg using Pinocchio library"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import pinocchio as pin\r\nimport numpy as np\r\n\r\n# Load Unitree G1 URDF\r\nmodel = pin.buildModelFromUrdf("unitree_g1.urdf")\r\ndata = model.createData()\r\n\r\n# Set joint angles (radians)\r\nq = np.array([\r\n    0.0,   # Hip roll\r\n    -0.5,  # Hip pitch (leg forward)\r\n    0.0,   # Hip yaw\r\n    1.0,   # Knee (bent)\r\n    -0.5,  # Ankle pitch\r\n    0.0    # Ankle roll\r\n])\r\n\r\n# Compute forward kinematics\r\npin.forwardKinematics(model, data, q)\r\n\r\n# Get foot position (end-effector frame)\r\nfoot_frame_id = model.getFrameId("left_foot")\r\nfoot_pose = data.oMf[foot_frame_id]\r\n\r\nprint(f"Foot position: x={foot_pose.translation[0]:.3f}, y={foot_pose.translation[1]:.3f}, z={foot_pose.translation[2]:.3f}")\r\n# Output: Foot position: x=0.123, y=-0.085, z=-0.780\n'})}),"\n",(0,t.jsx)(e.h3,{id:"822-inverse-kinematics-ik",children:"8.2.2 Inverse Kinematics (IK)"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Problem"}),": Given desired foot position (x, y, z), find joint angles \u03b8\u2081, \u03b8\u2082, ..., \u03b8\u2099."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Why IK?"})," For walking, we plan foot trajectories (where to step), then solve IK to find joint commands."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Analytical IK"})," (for simple 2-link leg):"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import math\r\n\r\ndef ik_2d_leg(x, y, L1, L2):\r\n    """\r\n    Inverse kinematics for 2-DOF planar leg.\r\n\r\n    Args:\r\n        x, y: Desired foot position\r\n        L1: Thigh length\r\n        L2: Shin length\r\n\r\n    Returns:\r\n        (theta1, theta2): Hip and knee angles (radians)\r\n    """\r\n    # Distance from hip to foot\r\n    r = math.sqrt(x**2 + y**2)\r\n\r\n    # Check reachability\r\n    if r > L1 + L2 or r < abs(L1 - L2):\r\n        raise ValueError(f"Target unreachable: r={r}, max reach={L1+L2}")\r\n\r\n    # Law of cosines\r\n    cos_theta2 = (r**2 - L1**2 - L2**2) / (2 * L1 * L2)\r\n    theta2 = math.acos(cos_theta2)\r\n\r\n    # Angle to target\r\n    alpha = math.atan2(y, x)\r\n    beta = math.acos((L1**2 + r**2 - L2**2) / (2 * L1 * r))\r\n    theta1 = alpha - beta\r\n\r\n    return theta1, theta2\r\n\r\n# Example: Foot at (0.3, -0.5)\r\ntheta1, theta2 = ik_2d_leg(x=0.3, y=-0.5, L1=0.4, L2=0.4)\r\nprint(f"Hip angle: {math.degrees(theta1):.1f}\xb0")\r\nprint(f"Knee angle: {math.degrees(theta2):.1f}\xb0")\r\n# Output: Hip angle: 32.5\xb0, Knee angle: 68.2\xb0\n'})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Numerical IK"})," (for complex 6-DOF leg):"]}),"\n",(0,t.jsxs)(e.p,{children:["Use ",(0,t.jsx)(e.strong,{children:"Jacobian pseudoinverse"})," or optimization (Pinocchio, KDL, MoveIt)."]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import pinocchio as pin\r\n\r\ndef ik_6dof_leg(model, data, target_pos, target_ori, max_iter=100):\r\n    """\r\n    Numerical IK using Levenberg-Marquardt.\r\n    """\r\n    q = pin.neutral(model)  # Initial guess\r\n    foot_frame_id = model.getFrameId("left_foot")\r\n\r\n    for i in range(max_iter):\r\n        pin.forwardKinematics(model, data, q)\r\n        pin.computeJointJacobians(model, data, q)\r\n\r\n        # Current foot pose\r\n        current_pose = data.oMf[foot_frame_id]\r\n\r\n        # Error (position + orientation)\r\n        error_pos = target_pos - current_pose.translation\r\n        error_ori = pin.log3(target_ori.rotation @ current_pose.rotation.T)\r\n        error = np.concatenate([error_pos, error_ori])\r\n\r\n        # Jacobian (6x6)\r\n        J = pin.getFrameJacobian(model, data, foot_frame_id, pin.LOCAL_WORLD_ALIGNED)\r\n\r\n        # Update joint angles\r\n        dq = np.linalg.pinv(J) @ error\r\n        q += dq * 0.1  # Step size\r\n\r\n        if np.linalg.norm(error) < 1e-4:\r\n            break\r\n\r\n    return q\n'})}),"\n",(0,t.jsx)(e.h3,{id:"823-jacobian",children:"8.2.3 Jacobian"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Jacobian"})," J relates joint velocities to end-effector velocity:"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"v = J q\u0307\n"})}),"\n",(0,t.jsx)(e.p,{children:"Where:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"v"}),": End-effector velocity (6D: linear + angular)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"q\u0307"}),": Joint velocities (6D for leg)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"J"}),": Jacobian matrix (6\xd76)"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Use cases"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Velocity control"}),": Given desired foot velocity, compute joint velocities"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Singularity detection"}),": det(J) = 0 means leg is fully extended (avoid!)"]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"83-dynamics",children:"8.3 Dynamics"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Dynamics"})," describes motion considering forces and torques."]}),"\n",(0,t.jsx)(e.h3,{id:"831-equations-of-motion",children:"8.3.1 Equations of Motion"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid dynamics:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"M(q) q\u0308 + C(q, q\u0307) + G(q) = \u03c4 + J^T F_ext\n"})}),"\n",(0,t.jsx)(e.p,{children:"Where:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"M(q)"}),": Mass matrix (inertia)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"C(q, q\u0307)"}),": Coriolis and centrifugal forces"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"G(q)"}),": Gravity forces"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"\u03c4"}),": Joint torques (what we control)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"F_ext"}),": External forces (ground reaction, pushes)"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Complexity"}),": For Unitree G1 (23 joints), M is a 23\xd723 matrix."]}),"\n",(0,t.jsx)(e.h3,{id:"832-centroidal-dynamics",children:"8.3.2 Centroidal Dynamics"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Simplification"}),": Model robot as a single rigid body (center of mass + angular momentum)."]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"m \u010b = F_total  (Newton's 2nd law)\r\nL\u0307 = \u03c4_total    (Angular momentum)\n"})}),"\n",(0,t.jsx)(e.p,{children:"Where:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"c"}),": Center of mass (COM) position"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"m"}),": Total mass"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"F_total"}),": Sum of all external forces"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"L"}),": Angular momentum"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Advantage"}),": Reduced from 23D to 6D (position + orientation)."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Code Example"}),": Simulate COM dynamics"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\n# Parameters\r\nm = 65.0  # Robot mass (kg)\r\ng = 9.81  # Gravity (m/s^2)\r\ndt = 0.01  # Time step (s)\r\n\r\n# Initial state\r\nc = np.array([0.0, 0.0, 0.9])  # COM position (x, y, z)\r\nv = np.array([0.0, 0.0, 0.0])  # COM velocity\r\n\r\n# Ground reaction force (simplified)\r\nF_ground = np.array([0.0, 0.0, m * g])  # Exactly balances gravity\r\n\r\n# Simulate\r\ntrajectory = []\r\nfor t in np.arange(0, 5.0, dt):\r\n    # Dynamics\r\n    F_total = F_ground + np.array([0, 0, -m * g])\r\n    a = F_total / m\r\n    v += a * dt\r\n    c += v * dt\r\n\r\n    trajectory.append(c.copy())\r\n\r\n# Plot\r\ntrajectory = np.array(trajectory)\r\nplt.plot(trajectory[:, 2])\r\nplt.xlabel("Time step")\r\nplt.ylabel("COM height (m)")\r\nplt.title("Balanced robot (COM stays at 0.9m)")\r\nplt.show()\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"84-zero-moment-point-zmp",children:"8.4 Zero Moment Point (ZMP)"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"ZMP"})," is the point on the ground where the net moment from gravity and inertia is zero."]}),"\n",(0,t.jsx)(e.h3,{id:"841-why-zmp-matters",children:"8.4.1 Why ZMP Matters"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Stability criterion"}),": If ZMP is inside the ",(0,t.jsx)(e.strong,{children:"support polygon"})," (foot contact area), the robot won't tip over."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Support polygon"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Single support"})," (one foot on ground): Rectangle of foot size (e.g., 10cm \xd7 20cm)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Double support"})," (both feet on ground): Convex hull of both feet (larger area, more stable)"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Example"}),": Human standing on one foot"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"If you lean too far forward, ZMP moves to your toes"}),"\n",(0,t.jsx)(e.li,{children:"If ZMP goes past toe tip, you fall forward"}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Balance strategy"}),": Shift weight back to keep ZMP inside foot"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"842-calculating-zmp",children:"8.4.2 Calculating ZMP"}),"\n",(0,t.jsxs)(e.p,{children:["For a robot with COM at position ",(0,t.jsx)(e.code,{children:"c = (cx, cy, cz)"})," and acceleration ",(0,t.jsx)(e.code,{children:"c\u0308"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"ZMP_x = cx - (cz / g) * c\u0308x\r\nZMP_y = cy - (cz / g) * c\u0308y\n"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Code Example"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def calculate_zmp(com_pos, com_acc, g=9.81):\r\n    """\r\n    Calculate Zero Moment Point.\r\n\r\n    Args:\r\n        com_pos: (x, y, z) center of mass position\r\n        com_acc: (ax, ay, az) center of mass acceleration\r\n        g: gravity constant\r\n\r\n    Returns:\r\n        (zmp_x, zmp_y): ZMP position on ground\r\n    """\r\n    cx, cy, cz = com_pos\r\n    ax, ay, az = com_acc\r\n\r\n    zmp_x = cx - (cz / g) * ax\r\n    zmp_y = cy - (cz / g) * ay\r\n\r\n    return zmp_x, zmp_y\r\n\r\n# Example: COM at (0, 0, 0.9m), accelerating forward at 0.5 m/s^2\r\nzmp = calculate_zmp(com_pos=(0.0, 0.0, 0.9), com_acc=(0.5, 0.0, 0.0))\r\nprint(f"ZMP: x={zmp[0]:.3f}m, y={zmp[1]:.3f}m")\r\n# Output: ZMP: x=-0.046m, y=0.000m (shifted backward due to forward acceleration)\n'})}),"\n",(0,t.jsx)(e.h3,{id:"843-zmp-stability",children:"8.4.3 ZMP Stability"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Check if ZMP is inside support polygon"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def is_stable(zmp, foot_corners):\r\n    """\r\n    Check if ZMP is inside support polygon.\r\n\r\n    Args:\r\n        zmp: (x, y)\r\n        foot_corners: [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]\r\n\r\n    Returns:\r\n        bool: True if stable\r\n    """\r\n    from shapely.geometry import Point, Polygon\r\n\r\n    zmp_point = Point(zmp)\r\n    support_polygon = Polygon(foot_corners)\r\n\r\n    return support_polygon.contains(zmp_point)\r\n\r\n# Left foot corners (10cm \xd7 20cm)\r\nleft_foot = [(-0.05, 0.0), (0.05, 0.0), (0.05, 0.2), (-0.05, 0.2)]\r\nzmp = (-0.046, 0.1)\r\n\r\nstable = is_stable(zmp, left_foot)\r\nprint(f"Stable: {stable}")\r\n# Output: Stable: True\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"85-gait-generation",children:"8.5 Gait Generation"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Gait"}),": Sequence of footsteps (walking pattern)."]}),"\n",(0,t.jsx)(e.h3,{id:"851-walking-phases",children:"8.5.1 Walking Phases"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Single support phase"}),": One foot on ground (50% of cycle)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Left foot on ground \u2192 Right foot swings forward"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Double support phase"}),": Both feet on ground (10% of cycle)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Transition between left and right support"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Swing phase"}),": Foot in air (40% of cycle)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Foot moves from behind to in front"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"852-preview-control-kajita-et-al-2003",children:"8.5.2 Preview Control (Kajita et al. 2003)"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Idea"}),": Plan COM trajectory to keep ZMP stable."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Algorithm"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Define desired ZMP trajectory (stay in center of support polygon)"}),"\n",(0,t.jsx)(e.li,{children:"Solve optimization: Find COM trajectory that produces desired ZMP"}),"\n",(0,t.jsx)(e.li,{children:"Use preview window (look ahead 1-2 seconds)"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Code Example"}),": Simplified preview controller"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\nfrom scipy.optimize import minimize\r\n\r\ndef preview_control(zmp_ref, com_height, T, dt):\r\n    """\r\n    Generate COM trajectory to track ZMP reference.\r\n\r\n    Args:\r\n        zmp_ref: Desired ZMP trajectory (Nx2 array)\r\n        com_height: Constant COM height (m)\r\n        T: Time horizon (s)\r\n        dt: Time step (s)\r\n\r\n    Returns:\r\n        com_traj: COM trajectory (Nx2 array)\r\n    """\r\n    N = int(T / dt)\r\n    g = 9.81\r\n\r\n    # Decision variables: COM positions\r\n    def cost(com_flat):\r\n        com = com_flat.reshape(N, 2)\r\n\r\n        # Calculate ZMP from COM\r\n        zmp = np.zeros((N, 2))\r\n        for i in range(1, N-1):\r\n            com_acc = (com[i+1] - 2*com[i] + com[i-1]) / dt**2\r\n            zmp[i, 0] = com[i, 0] - (com_height / g) * com_acc[0]\r\n            zmp[i, 1] = com[i, 1] - (com_height / g) * com_acc[1]\r\n\r\n        # Minimize ZMP tracking error\r\n        error = np.sum((zmp - zmp_ref)**2)\r\n        return error\r\n\r\n    # Initial guess (straight line)\r\n    com_init = np.linspace(zmp_ref[0], zmp_ref[-1], N)\r\n\r\n    # Optimize\r\n    result = minimize(cost, com_init.flatten(), method=\'BFGS\')\r\n    com_traj = result.x.reshape(N, 2)\r\n\r\n    return com_traj\r\n\r\n# Example: Walk forward 1 meter\r\nzmp_ref = np.array([[0.0, 0.0], [0.5, 0.0], [1.0, 0.0]])  # 3 keyframes\r\ncom_traj = preview_control(zmp_ref, com_height=0.9, T=2.0, dt=0.1)\r\n\r\nprint(f"COM trajectory: {com_traj.shape[0]} waypoints")\r\n# Output: COM trajectory: 20 waypoints\n'})}),"\n",(0,t.jsx)(e.h3,{id:"853-footstep-planning",children:"8.5.3 Footstep Planning"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Problem"}),": Given goal position, generate sequence of footsteps."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Constraints"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Step length: 0.2-0.5m (limited by leg length)"}),"\n",(0,t.jsx)(e.li,{children:"Step width: 0.1-0.2m (for stability)"}),"\n",(0,t.jsx)(e.li,{children:"Step frequency: 0.5-2 Hz"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Code Example"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def plan_footsteps(start, goal, step_length=0.3, step_width=0.15):\r\n    \"\"\"\r\n    Generate footstep sequence from start to goal.\r\n\r\n    Args:\r\n        start: (x, y, theta) initial pose\r\n        goal: (x, y, theta) goal pose\r\n        step_length: forward distance per step\r\n        step_width: lateral distance between feet\r\n\r\n    Returns:\r\n        List of (x, y, theta, foot) tuples\r\n    \"\"\"\r\n    import math\r\n\r\n    footsteps = []\r\n    x, y, theta = start\r\n    gx, gy, gtheta = goal\r\n\r\n    foot = 'left'  # Start with left\r\n\r\n    while True:\r\n        # Distance to goal\r\n        dx = gx - x\r\n        dy = gy - y\r\n        dist = math.sqrt(dx**2 + dy**2)\r\n\r\n        if dist < step_length:\r\n            # Final step\r\n            footsteps.append((gx, gy, gtheta, foot))\r\n            break\r\n\r\n        # Step forward\r\n        step_x = x + step_length * math.cos(theta)\r\n        step_y = y + step_length * math.sin(theta)\r\n\r\n        # Lateral offset (alternate left/right)\r\n        offset = step_width / 2 if foot == 'left' else -step_width / 2\r\n        step_x += offset * math.sin(theta)\r\n        step_y -= offset * math.cos(theta)\r\n\r\n        footsteps.append((step_x, step_y, theta, foot))\r\n\r\n        # Update\r\n        x, y = step_x, step_y\r\n        foot = 'right' if foot == 'left' else 'left'\r\n\r\n    return footsteps\r\n\r\n# Example\r\nsteps = plan_footsteps(start=(0, 0, 0), goal=(2, 0, 0))\r\nfor i, (x, y, theta, foot) in enumerate(steps):\r\n    print(f\"Step {i}: {foot} foot at ({x:.2f}, {y:.2f})\")\n"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"86-whole-body-control",children:"8.6 Whole-Body Control"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Problem"}),": Given desired COM trajectory and footsteps, compute joint torques."]}),"\n",(0,t.jsx)(e.h3,{id:"861-hierarchical-quadratic-programming-qp",children:"8.6.1 Hierarchical Quadratic Programming (QP)"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Formulation"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"Minimize: ||q\u0308 - q\u0308_ref||^2  (track desired accelerations)\r\n\r\nSubject to:\r\n  1. Contact constraints: Feet don't slip (F_friction < \u03bc F_normal)\r\n  2. ZMP constraint: ZMP inside support polygon\r\n  3. Joint limits: \u03c4_min < \u03c4 < \u03c4_max\r\n  4. Balance: COM acceleration matches ZMP plan\n"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Libraries"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Pinocchio"}),": Efficient dynamics computations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"quadprog"}),": QP solver"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Code Example"})," (simplified):"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import pinocchio as pin\r\nimport quadprog\r\n\r\ndef whole_body_control(model, data, q, v, com_ref, contact_forces):\r\n    """\r\n    Compute joint torques to track COM reference.\r\n    """\r\n    # Compute dynamics\r\n    M = pin.crba(model, data, q)  # Mass matrix\r\n    nle = pin.nle(model, data, q, v)  # Nonlinear effects\r\n\r\n    # COM Jacobian\r\n    J_com = pin.jacobianCenterOfMass(model, data, q)\r\n\r\n    # Desired COM acceleration (PD controller)\r\n    com_current = pin.centerOfMass(model, data, q)\r\n    com_error = com_ref - com_current\r\n    ddcom_des = 10.0 * com_error  # Proportional gain\r\n\r\n    # QP: Minimize ||M q\u0308 - \u03c4||^2\r\n    # Subject to: J_com q\u0308 = ddcom_des\r\n\r\n    # (Simplified: use pseudoinverse instead of full QP)\r\n    ddq = np.linalg.pinv(J_com) @ ddcom_des\r\n    tau = M @ ddq + nle\r\n\r\n    return tau\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"87-reinforcement-learning-for-locomotion",children:"8.7 Reinforcement Learning for Locomotion"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Traditional approach"})," (ZMP + Preview): Requires manual tuning, struggles on rough terrain."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"RL approach"}),": Learn walking policy from scratch using trial-and-error."]}),"\n",(0,t.jsx)(e.h3,{id:"871-training-in-isaac-gym",children:"8.7.1 Training in Isaac Gym"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Isaac Gym"})," (NVIDIA) simulates 4,096+ parallel environments on GPU."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Training time"}),": 10 million steps in ",(0,t.jsx)(e.strong,{children:"1 hour"})," (vs 100 hours on CPU)."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Workflow"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Define reward function (encourage forward walking, penalize falling)"}),"\n",(0,t.jsx)(e.li,{children:"Train PPO (Proximal Policy Optimization) agent"}),"\n",(0,t.jsx)(e.li,{children:"Deploy to Unitree G1 (sim-to-real)"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"872-reward-function",children:"8.7.2 Reward Function"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def compute_reward(state, action):\r\n    """\r\n    Reward function for walking.\r\n\r\n    Args:\r\n        state: Robot state (position, velocity, orientation)\r\n        action: Joint torques\r\n\r\n    Returns:\r\n        reward: Scalar reward\r\n    """\r\n    # Unpack state\r\n    pos, vel, ori, ang_vel = state\r\n\r\n    # Rewards\r\n    forward_vel = vel[0]  # X velocity\r\n    upright = ori[2]  # Z-axis should point up\r\n\r\n    # Penalties\r\n    energy = np.sum(action**2)  # Minimize actuator effort\r\n    fallen = 1.0 if pos[2] < 0.5 else 0.0  # Torso below 0.5m = fallen\r\n\r\n    reward = (\r\n        2.0 * forward_vel +      # Move forward\r\n        1.0 * upright -           # Stay upright\r\n        0.01 * energy -           # Minimize energy\r\n        10.0 * fallen             # Don\'t fall\r\n    )\r\n\r\n    return reward\n'})}),"\n",(0,t.jsx)(e.h3,{id:"873-training-script-isaac-gym",children:"8.7.3 Training Script (Isaac Gym)"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from isaacgym import gymapi\r\nimport torch\r\n\r\n# Initialize Isaac Gym\r\ngym = gymapi.acquire_gym()\r\nsim = gym.create_sim(0, 0, gymapi.SIM_PHYSX, gymapi.SimParams())\r\n\r\n# Create 4096 parallel environments\r\nnum_envs = 4096\r\nenvs = []\r\nfor i in range(num_envs):\r\n    env = gym.create_env(sim, gymapi.Vec3(-1, -1, 0), gymapi.Vec3(1, 1, 2), 8)\r\n    envs.append(env)\r\n\r\n# Load Unitree G1 URDF\r\nasset = gym.load_asset(sim, "assets", "unitree_g1.urdf")\r\nactors = [gym.create_actor(env, asset, gymapi.Transform(), f"robot_{i}", i, 0) for i, env in enumerate(envs)]\r\n\r\n# Training loop (simplified)\r\npolicy = torch.nn.Sequential(...)  # Neural network\r\noptimizer = torch.optim.Adam(policy.parameters(), lr=3e-4)\r\n\r\nfor epoch in range(1000):\r\n    # Collect experience\r\n    states, actions, rewards = [], [], []\r\n    for step in range(128):\r\n        gym.simulate(sim)\r\n        state = gym.get_actor_rigid_body_states(...)\r\n        action = policy(state)\r\n        reward = compute_reward(state, action)\r\n\r\n        states.append(state)\r\n        actions.append(action)\r\n        rewards.append(reward)\r\n\r\n    # Update policy (PPO)\r\n    loss = compute_ppo_loss(states, actions, rewards)\r\n    optimizer.zero_grad()\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\n    if epoch % 100 == 0:\r\n        print(f"Epoch {epoch}, Avg Reward: {np.mean(rewards):.2f}")\n'})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Expected output"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"Epoch 0, Avg Reward: -5.23\r\nEpoch 100, Avg Reward: 2.15\r\nEpoch 500, Avg Reward: 8.42\r\nEpoch 1000, Avg Reward: 12.67 (walking successfully!)\n"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"88-terrain-adaptation",children:"8.8 Terrain Adaptation"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Challenge"}),": Real world has stairs, slopes, rocks, grass."]}),"\n",(0,t.jsx)(e.h3,{id:"881-height-map-perception",children:"8.8.1 Height Map Perception"}),"\n",(0,t.jsxs)(e.p,{children:["Use ",(0,t.jsx)(e.strong,{children:"stereo camera"})," (RealSense) to build height map."]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\n\r\ndef build_height_map(depth_image, camera_intrinsics):\r\n    """\r\n    Convert depth image to 2D height map.\r\n\r\n    Returns:\r\n        height_map: NxM array of ground heights\r\n    """\r\n    # Project depth to 3D points\r\n    points_3d = depth_to_pointcloud(depth_image, camera_intrinsics)\r\n\r\n    # Grid the ground plane\r\n    grid_res = 0.05  # 5cm cells\r\n    height_map = np.zeros((100, 100))\r\n\r\n    for p in points_3d:\r\n        x, y, z = p\r\n        i = int(x / grid_res) + 50\r\n        j = int(y / grid_res) + 50\r\n        if 0 <= i < 100 and 0 <= j < 100:\r\n            height_map[i, j] = max(height_map[i, j], z)\r\n\r\n    return height_map\n'})}),"\n",(0,t.jsx)(e.h3,{id:"882-footstep-planning-on-terrain",children:"8.8.2 Footstep Planning on Terrain"}),"\n",(0,t.jsx)(e.p,{children:"Modify footstep planner to avoid obstacles:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def plan_footsteps_terrain(start, goal, height_map, max_step_height=0.15):\r\n    """\r\n    Plan footsteps on uneven terrain.\r\n    """\r\n    # A* search over discrete footstep graph\r\n    # Cost = distance + step_height_penalty\r\n    pass  # (See exercises)\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"89-push-recovery",children:"8.9 Push Recovery"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Scenario"}),": Robot is pushed while walking."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Strategies"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Ankle torque"}),": Apply counter-torque (works for small pushes)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Step"}),": Take a quick step to catch balance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Hip torque"}),": Swing arms (angular momentum transfer)"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"891-detecting-disturbances",children:"8.9.1 Detecting Disturbances"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def detect_push(imu_data, threshold=5.0):\r\n    """\r\n    Detect external push from IMU.\r\n\r\n    Args:\r\n        imu_data: (ax, ay, az, wx, wy, wz)\r\n        threshold: Acceleration threshold (m/s^2)\r\n\r\n    Returns:\r\n        bool: True if pushed\r\n    """\r\n    ax, ay, az, wx, wy, wz = imu_data\r\n    lateral_acc = np.sqrt(ax**2 + ay**2)\r\n\r\n    return lateral_acc > threshold\n'})}),"\n",(0,t.jsx)(e.h3,{id:"892-recovery-step",children:"8.9.2 Recovery Step"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def recovery_step(push_direction):\r\n    """\r\n    Generate recovery footstep.\r\n\r\n    Args:\r\n        push_direction: (x, y) unit vector\r\n\r\n    Returns:\r\n        foot_pose: (x, y, theta, foot)\r\n    """\r\n    # Step in direction of push (capture falling motion)\r\n    step_length = 0.4  # Larger than normal step\r\n    x = push_direction[0] * step_length\r\n    y = push_direction[1] * step_length\r\n\r\n    return (x, y, 0.0, \'left\')  # Simplified\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"810-sim-to-real-unitree-g1",children:"8.10 Sim-to-Real (Unitree G1)"}),"\n",(0,t.jsx)(e.h3,{id:"8101-domain-randomization",children:"8.10.1 Domain Randomization"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Problem"}),": Simulation is perfect; reality has noise, delays, friction variations."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Solution"}),": Train on ",(0,t.jsx)(e.strong,{children:"randomized"})," simulations."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Randomize"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Mass: \xb110% of nominal (simulate carrying payloads)"}),"\n",(0,t.jsx)(e.li,{children:"Friction: 0.5-1.5 (concrete, carpet, tile)"}),"\n",(0,t.jsx)(e.li,{children:"Motor delays: 5-20ms (actuator response time)"}),"\n",(0,t.jsx)(e.li,{children:"Joint torque limits: \xb120%"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Code"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"# In Isaac Gym\r\nfor env in envs:\r\n    # Randomize mass\r\n    mass_scale = np.random.uniform(0.9, 1.1)\r\n    gym.set_actor_rigid_body_properties(env, actor, mass * mass_scale)\r\n\r\n    # Randomize friction\r\n    friction = np.random.uniform(0.5, 1.5)\r\n    gym.set_actor_rigid_shape_properties(env, actor, friction)\n"})}),"\n",(0,t.jsx)(e.h3,{id:"8102-deployment-to-g1",children:"8.10.2 Deployment to G1"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Export policy"})," (PyTorch \u2192 ONNX \u2192 TensorRT):"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"python export_policy.py --checkpoint best_policy.pth --output policy.onnx\r\ntrtexec --onnx=policy.onnx --saveEngine=policy.trt --fp16\n"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Run on Jetson"})," (onboard G1 computer):"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import tensorrt as trt\r\nimport numpy as np\r\n\r\n# Load TensorRT engine\r\nwith open("policy.trt", "rb") as f:\r\n    engine = trt.Runtime(trt.Logger()).deserialize_cuda_engine(f.read())\r\n\r\n# Inference loop\r\nwhile True:\r\n    # Read sensors\r\n    joint_pos = read_joint_positions()\r\n    joint_vel = read_joint_velocities()\r\n    imu = read_imu()\r\n\r\n    # Prepare input\r\n    state = np.concatenate([joint_pos, joint_vel, imu])\r\n\r\n    # Run policy\r\n    action = engine.infer(state)\r\n\r\n    # Send commands\r\n    send_joint_torques(action)\r\n\r\n    time.sleep(0.01)  # 100 Hz control loop\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsx)(e.h3,{id:"exercise-81-implement-ik-for-humanoid-leg",children:"Exercise 8.1: Implement IK for Humanoid Leg"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Goal"}),": Write analytical IK for 3-DOF leg (hip pitch, knee, ankle pitch)."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Requirements"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["Function signature: ",(0,t.jsx)(e.code,{children:"ik_leg_3dof(x, z, L1, L2, L3)"})]}),"\n",(0,t.jsx)(e.li,{children:"Visualize solution in Matplotlib"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Expected"}),": Leg configuration for foot at (0.2, -0.7)."]}),"\n",(0,t.jsx)(e.h3,{id:"exercise-82-generate-walking-trajectory",children:"Exercise 8.2: Generate Walking Trajectory"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Goal"}),": Use preview control to generate 10-step walking trajectory."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Requirements"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Plot COM trajectory, ZMP trajectory, and support polygon"}),"\n",(0,t.jsx)(e.li,{children:"Verify ZMP always inside support"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Expected"}),": Plot showing stable walking (ZMP contained)."]}),"\n",(0,t.jsx)(e.h3,{id:"exercise-83-train-rl-policy-for-stair-climbing",children:"Exercise 8.3: Train RL Policy for Stair Climbing"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Goal"}),": Train PPO agent to climb stairs in Isaac Gym."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Requirements"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Define reward function (height gain, upright posture, energy)"}),"\n",(0,t.jsx)(e.li,{children:"Train for 10M steps"}),"\n",(0,t.jsx)(e.li,{children:"Evaluate success rate on 10cm, 15cm, 20cm stairs"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Expected"}),": >80% success on 15cm stairs."]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"citations",children:"Citations"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Kajita, S., Kanehiro, F., Kaneko, K., Fujiwara, K., Harada, K., Yokoi, K., & Hirukawa, H. (2003). ",(0,t.jsx)(e.em,{children:"Biped walking pattern generation by using preview control of zero-moment point."})," IEEE International Conference on Robotics and Automation (ICRA), 2, 1620-1626."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Vukobratovi\u0107, M., & Borovac, B. (2004). ",(0,t.jsx)(e.em,{children:"Zero-moment point\u2014thirty five years of its life."})," International Journal of Humanoid Robotics, 1(1), 157-173."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Wieber, P. B. (2006). ",(0,t.jsx)(e.em,{children:"Trajectory free linear model predictive control for stable walking in the presence of strong perturbations."})," IEEE-RAS International Conference on Humanoid Robots, 137-142."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Tedrake, R., Zhang, T. W., & Seung, H. S. (2004). ",(0,t.jsx)(e.em,{children:"Stochastic policy gradient reinforcement learning on a simple 3D biped."})," IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 3, 2849-2854."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). ",(0,t.jsx)(e.em,{children:"Proximal policy optimization algorithms."})," arXiv preprint arXiv:1707.06347."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Lee, J., Hwangbo, J., Wellhausen, L., Koltun, V., & Hutter, M. (2020). ",(0,t.jsx)(e.em,{children:"Learning quadrupedal locomotion over challenging terrain."})," Science Robotics, 5(47)."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Kuindersma, S., Deits, R., Fallon, M., Valenzuela, A., Dai, H., Permenter, F., ... & Tedrake, R. (2016). ",(0,t.jsx)(e.em,{children:"Optimization-based locomotion planning, estimation, and control design for the atlas humanoid robot."})," Autonomous Robots, 40(3), 429-455."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Sentis, L., Park, J., & Khatib, O. (2010). ",(0,t.jsx)(e.em,{children:"Compliant control of multicontact and center-of-mass behaviors in humanoid robots."})," IEEE Transactions on Robotics, 26(3), 483-501."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Englsberger, J., Ott, C., & Albu-Sch\xe4ffer, A. (2015). ",(0,t.jsx)(e.em,{children:"Three-dimensional bipedal walking control based on divergent component of motion."})," IEEE Transactions on Robotics, 31(2), 355-368."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Hopkins, M. A., Griffin, R. J., Leonessa, A., & Bobrow, J. E. (2015). ",(0,t.jsx)(e.em,{children:"Compliant locomotion using whole-body control and divergent component of motion tracking."})," IEEE International Conference on Robotics and Automation (ICRA), 5726-5733."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Makoviychuk, V., Wawrzyniak, L., Guo, Y., Lu, M., Storey, K., Macklin, M., ... & State, G. (2021). ",(0,t.jsx)(e.em,{children:"Isaac Gym: High performance GPU-based physics simulation for robot learning."})," arXiv preprint arXiv:2108.10470."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Hwangbo, J., Lee, J., Dosovitskiy, A., Bellicoso, D., Tsounis, V., Koltun, V., & Hutter, M. (2019). ",(0,t.jsx)(e.em,{children:"Learning agile and dynamic motor skills for legged robots."})," Science Robotics, 4(26)."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Peng, X. B., Coumans, E., Zhang, T., Lee, T. W., Tan, J., & Levine, S. (2020). ",(0,t.jsx)(e.em,{children:"Learning agile robotic locomotion skills by imitating animals."})," Robotics: Science and Systems (RSS)."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Unitree Robotics. (2024). ",(0,t.jsx)(e.em,{children:"Unitree G1 Technical Specifications."})," ",(0,t.jsx)(e.a,{href:"https://www.unitree.com/g1",children:"https://www.unitree.com/g1"})]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Boston Dynamics. (2023). ",(0,t.jsx)(e.em,{children:"Atlas: The World's Most Dynamic Humanoid Robot."})," ",(0,t.jsx)(e.a,{href:"https://www.bostondynamics.com/atlas",children:"https://www.bostondynamics.com/atlas"})]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Carpentier, J., Saurel, G., Buondonno, G., Mirabel, J., Lamiraux, F., Stasse, O., & Mansard, N. (2019). ",(0,t.jsx)(e.em,{children:"The Pinocchio C++ library: A fast and flexible implementation of rigid body dynamics algorithms and their analytical derivatives."})," IEEE International Symposium on System Integrations (SII), 614-619."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Gehring, C., Coros, S., Hutter, M., Bloesch, M., Hoepflinger, M. A., & Siegwart, R. (2013). ",(0,t.jsx)(e.em,{children:"Practice makes perfect: An optimization-based approach to controlling agile motions for a quadruped robot."})," IEEE Robotics & Automation Magazine, 20(3), 34-43."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:["Pratt, J., Carff, J., Drakunov, S., & Goswami, A. (2006). ",(0,t.jsx)(e.em,{children:"Capture point: A step toward humanoid push recovery."})," IEEE-RAS International Conference on Humanoid Robots, 200-207."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Simulation Only"})," (recommended for this chapter):"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"GPU"}),": NVIDIA RTX 3060 or higher (for Isaac Gym)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"RAM"}),": 16 GB"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"OS"}),": Ubuntu 20.04 or Windows 11"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Real Hardware"})," (optional, shared lab resource):"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Unitree G1"}),": $16,000 (typically one per research lab)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"RealSense D435i"}),": $349 (for terrain perception)"]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"labs",children:"Labs"}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Lab 8.1: ZMP Walking Simulation"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Repository"}),": ",(0,t.jsx)(e.a,{href:"https://github.com/Shumailaaijaz/physical-ai-labs",children:"github.com/Shumailaaijaz/physical-ai-labs"})]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Lab Path"}),": ",(0,t.jsx)(e.code,{children:"labs/chapter-08-zmp-walking/"})]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"What's Included"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Preview control implementation"}),"\n",(0,t.jsx)(e.li,{children:"PyBullet simulation of humanoid"}),"\n",(0,t.jsx)(e.li,{children:"ZMP visualization"}),"\n",(0,t.jsx)(e.li,{children:"10-step walking demo"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Expected Time"}),": 3 hours"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Lab 8.2: RL Locomotion Training"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Lab Path"}),": ",(0,t.jsx)(e.code,{children:"labs/chapter-08-rl-locomotion/"})]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"What's Included"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Isaac Gym environment setup"}),"\n",(0,t.jsx)(e.li,{children:"PPO training script"}),"\n",(0,t.jsx)(e.li,{children:"Reward function templates"}),"\n",(0,t.jsx)(e.li,{children:"Pre-trained checkpoint (for reference)"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Hardware"}),": NVIDIA RTX 3060+ (or use Google Colab with A100)"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Expected Time"}),": 4 hours (including 1 hour training)"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Next Chapter"}),": ",(0,t.jsx)(e.a,{href:"/physical-ai-textbook/docs/09-manipulation-grasping",children:"Chapter 9: Manipulation & Grasping \u2192"})]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsxs)(e.em,{children:["This textbook is a living document. Found an error? Have a suggestion? Submit an issue or PR at ",(0,t.jsx)(e.a,{href:"https://github.com/Shumailaaijaz/physical-ai-textbook",children:"github.com/Shumailaaijaz/physical-ai-textbook"})]})})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>s,x:()=>a});var i=r(6540);const t={},o=i.createContext(t);function s(n){const e=i.useContext(o);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),i.createElement(o.Provider,{value:e},n.children)}}}]);