"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[9688],{8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>l});var r=s(6540);const i={},o=r.createContext(i);function a(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(o.Provider,{value:n},e.children)}},9113:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>t,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"07-isaac-ros-integration","title":"Chapter 7: Isaac ROS Integration","description":"\\"Hardware acceleration transforms perception from a bottleneck into a superpower.\\"","source":"@site/docs/07-isaac-ros-integration.mdx","sourceDirName":".","slug":"/07-isaac-ros-integration","permalink":"/physical-ai-textbook/docs/07-isaac-ros-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/Shumailaaijaz/physical-ai-textbook/tree/main/docs/07-isaac-ros-integration.mdx","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"id":"07-isaac-ros-integration","title":"Chapter 7: Isaac ROS Integration","sidebar_position":7,"part":3,"week":10,"difficulty_levels":["advanced"],"hardware_tracks":["budget_hardware","research_grade"],"citation_count":15,"word_count":7500,"urdu_completeness":0},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 6: NVIDIA Isaac Sim Basics","permalink":"/physical-ai-textbook/docs/06-isaac-sim-basics"},"next":{"title":"Chapter 8: Legged Locomotion","permalink":"/physical-ai-textbook/docs/08-legged-locomotion"}}');var i=s(4848),o=s(8453);const a={id:"07-isaac-ros-integration",title:"Chapter 7: Isaac ROS Integration",sidebar_position:7,part:3,week:10,difficulty_levels:["advanced"],hardware_tracks:["budget_hardware","research_grade"],citation_count:15,word_count:7500,urdu_completeness:0},l="Chapter 7: Isaac ROS Integration",t={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"7.1 Introduction: Why Isaac ROS?",id:"71-introduction-why-isaac-ros",level:2},{value:"The NVIDIA Solution",id:"the-nvidia-solution",level:3},{value:"Hardware: NVIDIA Jetson Orin",id:"hardware-nvidia-jetson-orin",level:3},{value:"7.2 Isaac ROS Architecture",id:"72-isaac-ros-architecture",level:2},{value:"7.2.1 GXF (Graph Execution Framework)",id:"721-gxf-graph-execution-framework",level:3},{value:"7.2.2 NITROS (Zero-Copy Transport)",id:"722-nitros-zero-copy-transport",level:3},{value:"7.2.3 Isaac ROS Packages",id:"723-isaac-ros-packages",level:3},{value:"7.3 Setting Up Jetson Orin",id:"73-setting-up-jetson-orin",level:2},{value:"7.3.1 Flashing JetPack from Windows",id:"731-flashing-jetpack-from-windows",level:3},{value:"7.3.2 Installing Isaac ROS",id:"732-installing-isaac-ros",level:3},{value:"7.4 Visual SLAM (VSLAM)",id:"74-visual-slam-vslam",level:2},{value:"7.4.1 How VSLAM Works",id:"741-how-vslam-works",level:3},{value:"7.4.2 Hardware: Intel RealSense D435i",id:"742-hardware-intel-realsense-d435i",level:3},{value:"7.4.3 Running VSLAM",id:"743-running-vslam",level:3},{value:"7.4.4 Saving and Loading Maps",id:"744-saving-and-loading-maps",level:3},{value:"7.5 Object Detection (DOPE)",id:"75-object-detection-dope",level:2},{value:"7.5.1 Why 6D Pose?",id:"751-why-6d-pose",level:3},{value:"7.5.2 How DOPE Works",id:"752-how-dope-works",level:3},{value:"7.5.3 Running DOPE",id:"753-running-dope",level:3},{value:"7.5.4 Training DOPE on Custom Objects",id:"754-training-dope-on-custom-objects",level:3},{value:"7.6 FoundationPose (Zero-Shot Detection)",id:"76-foundationpose-zero-shot-detection",level:2},{value:"7.6.1 How FoundationPose Works",id:"761-how-foundationpose-works",level:3},{value:"7.6.2 Running FoundationPose",id:"762-running-foundationpose",level:3},{value:"7.7 Stereo Depth Estimation (ESS)",id:"77-stereo-depth-estimation-ess",level:2},{value:"7.7.1 Why Depth Maps?",id:"771-why-depth-maps",level:3},{value:"7.7.2 Running ESS",id:"772-running-ess",level:3},{value:"7.8 Nav2 Integration",id:"78-nav2-integration",level:2},{value:"7.8.1 Nav2 Architecture",id:"781-nav2-architecture",level:3},{value:"7.8.2 Launching Nav2 with Isaac VSLAM",id:"782-launching-nav2-with-isaac-vslam",level:3},{value:"7.8.3 Sending Navigation Goals",id:"783-sending-navigation-goals",level:3},{value:"7.9 Bipedal Navigation (Humanoid-Specific)",id:"79-bipedal-navigation-humanoid-specific",level:2},{value:"7.9.1 Differences from Wheeled Navigation",id:"791-differences-from-wheeled-navigation",level:3},{value:"7.9.2 Footstep Planning",id:"792-footstep-planning",level:3},{value:"7.10 Sim-to-Real Transfer",id:"710-sim-to-real-transfer",level:2},{value:"7.10.1 Domain Randomization",id:"7101-domain-randomization",level:3},{value:"7.10.2 Loading TensorRT Models",id:"7102-loading-tensorrt-models",level:3},{value:"7.11 Performance Benchmarks",id:"711-performance-benchmarks",level:2},{value:"7.11.1 VSLAM Performance",id:"7111-vslam-performance",level:3},{value:"7.11.2 Object Detection Performance",id:"7112-object-detection-performance",level:3},{value:"7.12 Debugging Isaac ROS",id:"712-debugging-isaac-ros",level:2},{value:"7.12.1 GXF Logs",id:"7121-gxf-logs",level:3},{value:"7.12.2 NITROS Topics",id:"7122-nitros-topics",level:3},{value:"7.12.3 Latency Profiling",id:"7123-latency-profiling",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 7.1: Map Your Room with VSLAM",id:"exercise-71-map-your-room-with-vslam",level:3},{value:"Exercise 7.2: Train DOPE on Custom Object",id:"exercise-72-train-dope-on-custom-object",level:3},{value:"Exercise 7.3: Nav2 Waypoint Navigation",id:"exercise-73-nav2-waypoint-navigation",level:3},{value:"Citations",id:"citations",level:2},{value:"Hardware Requirements",id:"hardware-requirements",level:2},{value:"Lab",id:"lab",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-7-isaac-ros-integration",children:"Chapter 7: Isaac ROS Integration"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:'"Hardware acceleration transforms perception from a bottleneck into a superpower."'})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Install Isaac ROS packages"})," on NVIDIA Jetson"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Implement Visual SLAM (VSLAM)"})," with hardware acceleration"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use Isaac ROS for object detection"})," (DOPE, FoundationPose)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Integrate Nav2"})," for autonomous navigation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deploy sim-trained policies"})," to real robots"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Estimated Time"}),": 8-10 hours (reading + labs)"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"71-introduction-why-isaac-ros",children:"7.1 Introduction: Why Isaac ROS?"}),"\n",(0,i.jsx)(n.p,{children:"Traditional ROS 2 perception runs entirely on the CPU. While this works for simple tasks, modern robots require real-time processing of high-resolution sensor data. Consider a humanoid robot navigating a crowded space:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Visual SLAM"}),": Processes stereo images at 30 FPS to build a 3D map"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Object detection"}),": Identifies 80+ object classes in real-time"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Depth estimation"}),": Generates dense depth maps for obstacle avoidance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Semantic segmentation"}),": Labels every pixel (floor, wall, person, furniture)"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["On a typical x86 CPU, these tasks struggle to maintain even 10 Hz. ",(0,i.jsx)(n.strong,{children:"This is the perception bottleneck."})]}),"\n",(0,i.jsx)(n.h3,{id:"the-nvidia-solution",children:"The NVIDIA Solution"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS"})," is a collection of hardware-accelerated ROS 2 packages that leverage NVIDIA GPUs to achieve ",(0,i.jsx)(n.strong,{children:"10-100x speedups"}),":"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Task"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"CPU (x86)"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"GPU (Jetson Orin)"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Speedup"})})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Visual SLAM"}),(0,i.jsx)(n.td,{children:"10 Hz"}),(0,i.jsx)(n.td,{children:"100 Hz"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"10x"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Object Detection (YOLOv8)"}),(0,i.jsx)(n.td,{children:"2 FPS"}),(0,i.jsx)(n.td,{children:"30 FPS"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"15x"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Stereo Depth"}),(0,i.jsx)(n.td,{children:"5 FPS"}),(0,i.jsx)(n.td,{children:"30 FPS"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"6x"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Semantic Segmentation"}),(0,i.jsx)(n.td,{children:"1 FPS"}),(0,i.jsx)(n.td,{children:"20 FPS"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"20x"})})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key Innovation"}),": Isaac ROS uses ",(0,i.jsx)(n.strong,{children:"NITROS (NVIDIA Isaac Transport for ROS)"}),", a zero-copy message passing system that avoids CPU-GPU data transfers\u2014the primary bottleneck in traditional GPU-accelerated ROS nodes."]}),"\n",(0,i.jsx)(n.h3,{id:"hardware-nvidia-jetson-orin",children:"Hardware: NVIDIA Jetson Orin"}),"\n",(0,i.jsxs)(n.p,{children:["Isaac ROS is optimized for the ",(0,i.jsx)(n.strong,{children:"Jetson Orin"})," family of edge AI devices:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Jetson Orin Nano Super"}),": 8GB, 40 TOPS, ",(0,i.jsx)(n.strong,{children:"$249"})," (NEW 2024 price drop!)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Jetson Orin NX"}),": 16GB, 100 TOPS, $599"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Jetson AGX Orin"}),": 64GB, 275 TOPS, $1,999"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"TOPS"})," (Tera Operations Per Second) measures AI inference performance. For comparison, a laptop CPU delivers ~1 TOPS; Orin Nano delivers 40 TOPS while consuming only 7-15W."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"72-isaac-ros-architecture",children:"7.2 Isaac ROS Architecture"}),"\n",(0,i.jsx)(n.h3,{id:"721-gxf-graph-execution-framework",children:"7.2.1 GXF (Graph Execution Framework)"}),"\n",(0,i.jsxs)(n.p,{children:["Isaac ROS is built on ",(0,i.jsx)(n.strong,{children:"GXF"}),", NVIDIA's dataflow framework for real-time systems. Unlike traditional ROS nodes (one process per node), GXF runs multiple processing stages (codelets) within a single GPU-accelerated process."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Traditional ROS 2 Pipeline"})," (3 nodes, 2 CPU-GPU copies):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"[Camera Node] ---(ROS msg)---\x3e [GPU Inference Node] ---(ROS msg)---\x3e [Visualization Node]\r\n    CPU                             GPU                                    CPU\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Pipeline"})," (1 GXF graph, 0 copies):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"[Camera Codelet] ---(GPU memory)---\x3e [Inference Codelet] ---(GPU memory)---\x3e [Output Codelet]\r\n                    All on GPU, zero-copy\n"})}),"\n",(0,i.jsx)(n.h3,{id:"722-nitros-zero-copy-transport",children:"7.2.2 NITROS (Zero-Copy Transport)"}),"\n",(0,i.jsxs)(n.p,{children:["NITROS extends ROS 2's DDS transport to support ",(0,i.jsx)(n.strong,{children:"GPU memory sharing"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Traditional ROS"}),": Publish image \u2192 Copy GPU to CPU \u2192 Serialize \u2192 Send \u2192 Deserialize \u2192 Copy CPU to GPU"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"NITROS"}),": Publish image \u2192 Share GPU pointer \u2192 Subscriber reads directly from GPU"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Result"}),": Latency drops from ~50ms to ~1ms."]}),"\n",(0,i.jsx)(n.h3,{id:"723-isaac-ros-packages",children:"7.2.3 Isaac ROS Packages"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS provides drop-in replacements for common ROS packages:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Package"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"CPU Equivalent"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Use Case"})})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"isaac_ros_visual_slam"})}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"rtabmap_ros"}),", ",(0,i.jsx)(n.code,{children:"orb_slam3"})]}),(0,i.jsx)(n.td,{children:"Visual SLAM"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"isaac_ros_dnn_inference"})}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"darknet_ros"}),", ",(0,i.jsx)(n.code,{children:"pytorch_ros"})]}),(0,i.jsx)(n.td,{children:"Object detection"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"isaac_ros_ess"})}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"stereo_image_proc"})}),(0,i.jsx)(n.td,{children:"Stereo depth"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"isaac_ros_unet"})}),(0,i.jsx)(n.td,{children:"N/A"}),(0,i.jsx)(n.td,{children:"Semantic segmentation"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"isaac_ros_apriltag"})}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"apriltag_ros"})}),(0,i.jsx)(n.td,{children:"Fiducial markers"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Plug-and-play"}),": Change one launch file line to switch from CPU to GPU."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"73-setting-up-jetson-orin",children:"7.3 Setting Up Jetson Orin"}),"\n",(0,i.jsx)(n.h3,{id:"731-flashing-jetpack-from-windows",children:"7.3.1 Flashing JetPack from Windows"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"On Windows 10/11"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Download NVIDIA SDK Manager"})," (Windows version):"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Visit: ",(0,i.jsx)(n.a,{href:"https://developer.nvidia.com/sdk-manager",children:"https://developer.nvidia.com/sdk-manager"})]}),"\n",(0,i.jsx)(n.li,{children:"Create an NVIDIA Developer account (free)"}),"\n",(0,i.jsx)(n.li,{children:"Download SDK Manager installer"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Connect Jetson Orin"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Put Jetson in ",(0,i.jsx)(n.strong,{children:"Force Recovery Mode"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Power off Jetson"}),"\n",(0,i.jsxs)(n.li,{children:["Hold down ",(0,i.jsx)(n.strong,{children:"RECOVERY"})," button"]}),"\n",(0,i.jsxs)(n.li,{children:["Press ",(0,i.jsx)(n.strong,{children:"POWER"})," button (while still holding RECOVERY)"]}),"\n",(0,i.jsx)(n.li,{children:"Release RECOVERY after 2 seconds"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Connect Jetson to Windows PC via USB-C cable"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Flash JetPack"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Open SDK Manager"}),"\n",(0,i.jsxs)(n.li,{children:["Select ",(0,i.jsx)(n.strong,{children:"Jetson Orin Nano"})," (or your model)"]}),"\n",(0,i.jsxs)(n.li,{children:["Choose ",(0,i.jsx)(n.strong,{children:"JetPack 5.1.2"})," (includes Ubuntu 20.04 + ROS 2 Humble)"]}),"\n",(0,i.jsx)(n.li,{children:'Click "Flash" (takes ~30 minutes)'}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"First Boot"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Disconnect USB-C cable"}),"\n",(0,i.jsx)(n.li,{children:"Connect HDMI monitor, keyboard, mouse"}),"\n",(0,i.jsx)(n.li,{children:"Power on Jetson"}),"\n",(0,i.jsxs)(n.li,{children:["Complete Ubuntu setup wizard (username: ",(0,i.jsx)(n.code,{children:"nvidia"}),", password of your choice)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Alternative: SSH Workflow"})," (recommended for headless operation):"]}),"\n",(0,i.jsx)(n.p,{children:"After initial setup, configure SSH:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# On Jetson (via HDMI):\r\nsudo systemctl enable ssh\r\nsudo systemctl start ssh\r\nip addr show  # Note the IP address (e.g., 192.168.1.100)\r\n\r\n# On Windows (PowerShell):\r\nssh nvidia@192.168.1.100\n"})}),"\n",(0,i.jsx)(n.h3,{id:"732-installing-isaac-ros",children:"7.3.2 Installing Isaac ROS"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"On Jetson"})," (via SSH or terminal):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Update system\r\nsudo apt update && sudo apt upgrade -y\r\n\r\n# Install ROS 2 Humble (if not already installed)\r\nsudo apt install -y ros-humble-desktop\r\n\r\n# Install Isaac ROS packages\r\nsudo apt install -y \\\r\n  ros-humble-isaac-ros-visual-slam \\\r\n  ros-humble-isaac-ros-dnn-inference \\\r\n  ros-humble-isaac-ros-ess \\\r\n  ros-humble-isaac-ros-apriltag\r\n\r\n# Install dependencies\r\nsudo apt install -y \\\r\n  ros-humble-isaac-ros-common \\\r\n  ros-humble-isaac-ros-nitros\r\n\r\n# Verify installation\r\nros2 pkg list | grep isaac_ros\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected output"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"isaac_ros_apriltag\r\nisaac_ros_common\r\nisaac_ros_dnn_inference\r\nisaac_ros_ess\r\nisaac_ros_nitros\r\nisaac_ros_visual_slam\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"74-visual-slam-vslam",children:"7.4 Visual SLAM (VSLAM)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Visual SLAM (Simultaneous Localization and Mapping)"})," solves two problems simultaneously:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Localization"}),": Where am I? (robot pose: x, y, z, roll, pitch, yaw)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mapping"}),": What's around me? (3D point cloud of the environment)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"741-how-vslam-works",children:"7.4.1 How VSLAM Works"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Feature Extraction"}),": Detect keypoints in camera images (FAST, ORB)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Feature Matching"}),": Match keypoints between consecutive frames"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Motion Estimation"}),": Calculate camera movement (visual odometry)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Loop Closure"}),": Recognize previously visited locations, correct drift"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Bundle Adjustment"}),": Optimize camera poses and 3D points globally"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Isaac ROS VSLAM uses ",(0,i.jsx)(n.strong,{children:"cuVSLAM"}),", NVIDIA's CUDA-accelerated SLAM implementation:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"100 Hz tracking"})," (10x faster than CPU SLAM)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stereo or RGB-D"})," camera support"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"IMU fusion"})," for improved accuracy"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"742-hardware-intel-realsense-d435i",children:"7.4.2 Hardware: Intel RealSense D435i"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"RealSense D435i"})," is the standard camera for Isaac ROS VSLAM:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stereo cameras"}),": 848x480 @ 90 FPS (infrared)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"RGB camera"}),": 1920x1080 @ 30 FPS"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"IMU"}),": Accelerometer + Gyroscope (250 Hz)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Depth range"}),": 0.1m to 10m"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Price"}),": $349 (Amazon, B&H Photo)"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Connect to Jetson"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Install RealSense ROS wrapper\r\nsudo apt install -y ros-humble-realsense2-camera\r\n\r\n# Verify camera detected\r\nlsusb | grep Intel\r\n# Expected: "Bus 001 Device 005: ID 8086:0b3a Intel Corp. RealSense D435i"\r\n\r\n# Launch camera node\r\nros2 launch realsense2_camera rs_launch.py\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected output"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"[INFO] [realsense2_camera_node]: RealSense ROS Node Running\r\n[INFO] [realsense2_camera_node]: Device Name: Intel RealSense D435I\r\n[INFO] [realsense2_camera_node]: Device Serial No: 123456789012\n"})}),"\n",(0,i.jsx)(n.h3,{id:"743-running-vslam",children:"7.4.3 Running VSLAM"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Launch VSLAM with RealSense"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_visual_slam isaac_ros_visual_slam_realsense.launch.py\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"What happens"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["RealSense node publishes stereo images to ",(0,i.jsx)(n.code,{children:"/camera/infra1/image_rect_raw"})," and ",(0,i.jsx)(n.code,{children:"/camera/infra2/image_rect_raw"})]}),"\n",(0,i.jsx)(n.li,{children:"VSLAM node subscribes to images, computes camera pose"}),"\n",(0,i.jsxs)(n.li,{children:["VSLAM publishes odometry to ",(0,i.jsx)(n.code,{children:"/visual_slam/tracking/odometry"})]}),"\n",(0,i.jsxs)(n.li,{children:["VSLAM publishes point cloud to ",(0,i.jsx)(n.code,{children:"/visual_slam/tracking/slam_path"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Visualize in RViz"}),":"]}),"\n",(0,i.jsxs)(n.p,{children:["Open a ",(0,i.jsx)(n.strong,{children:"new terminal"})," on Jetson:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run rviz2 rviz2 -d $(ros2 pkg prefix isaac_ros_visual_slam)/share/isaac_ros_visual_slam/rviz/default.rviz\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected view"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Red trajectory"}),": Camera path (estimated robot motion)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"White points"}),": 3D map (detected features)"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Walk around with the camera"})," and watch the map build in real-time."]}),"\n",(0,i.jsx)(n.h3,{id:"744-saving-and-loading-maps",children:"7.4.4 Saving and Loading Maps"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Save map"})," (after exploring an area):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 service call /visual_slam/save_map isaac_ros_visual_slam_interfaces/srv/SaveMap \"{map_url: '/home/nvidia/my_map.db'}\"\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Load map"})," (on next run):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_visual_slam isaac_ros_visual_slam_realsense.launch.py load_map_folder_path:=/home/nvidia load_map_filename:=my_map.db\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use case"}),": Robot navigates a warehouse. Save map once, then use for localization (no re-mapping needed)."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"75-object-detection-dope",children:"7.5 Object Detection (DOPE)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"DOPE (Deep Object Pose Estimation)"})," detects objects and estimates their ",(0,i.jsx)(n.strong,{children:"6D pose"})," (3D position + 3D rotation)."]}),"\n",(0,i.jsx)(n.h3,{id:"751-why-6d-pose",children:"7.5.1 Why 6D Pose?"}),"\n",(0,i.jsx)(n.p,{children:"For manipulation, knowing \"there's a cup\" isn't enough. You need:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Position"}),": x=0.5m, y=0.2m, z=0.8m (center of cup)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Orientation"}),": roll=0\xb0, pitch=5\xb0, yaw=45\xb0 (cup is slightly tilted)"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use case"}),": Robot grasps a cup. Without pose, gripper might collide with the table or grasp empty air."]}),"\n",(0,i.jsx)(n.h3,{id:"752-how-dope-works",children:"7.5.2 How DOPE Works"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Input"}),": RGB image from camera"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"CNN (Belief Maps)"}),": Predict 2D keypoints for object (e.g., 8 corners of a bounding box)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"PnP (Perspective-n-Point)"}),": Solve for 3D pose given 2D keypoints and known 3D model"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Output"}),": 6D pose (x, y, z, qx, qy, qz, qw)"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Pre-trained models"})," available for:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"YCB objects (soup can, mustard bottle, Cheez-It box)"}),"\n",(0,i.jsx)(n.li,{children:"Custom objects (requires training, ~10 minutes on Jetson)"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"753-running-dope",children:"7.5.3 Running DOPE"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Install DOPE"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt install -y ros-humble-isaac-ros-dope\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Download pre-trained model"})," (YCB soup can):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/isaac_ros_ws/src\r\ncd ~/isaac_ros_ws/src\r\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_pose_estimation.git\r\ncd isaac_ros_pose_estimation/isaac_ros_dope\r\n./scripts/download_models.sh\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Launch DOPE"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_dope isaac_ros_dope.launch.py model_name:=Ketchup\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Place a ketchup bottle in front of the camera."})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Check detection"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /dope/pose_array\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected output"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"poses:\r\n  - position:\r\n      x: 0.45\r\n      y: -0.12\r\n      z: 0.68\r\n    orientation:\r\n      x: 0.02\r\n      y: 0.01\r\n      z: 0.71\r\n      w: 0.70\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Visualize in RViz"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Add ",(0,i.jsx)(n.code,{children:"PoseArray"})," display"]}),"\n",(0,i.jsxs)(n.li,{children:["Set topic to ",(0,i.jsx)(n.code,{children:"/dope/pose_array"})]}),"\n",(0,i.jsx)(n.li,{children:"See 3D axes showing object orientation"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"754-training-dope-on-custom-objects",children:"7.5.4 Training DOPE on Custom Objects"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use NVIDIA Isaac Sim"})," to generate synthetic training data:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Import 3D model of your object (CAD file)"}),"\n",(0,i.jsx)(n.li,{children:"Place object in random poses, lighting, backgrounds"}),"\n",(0,i.jsx)(n.li,{children:"Generate 10,000 annotated images (takes ~1 hour)"}),"\n",(0,i.jsx)(n.li,{children:"Train DOPE model (takes ~10 minutes on Jetson)"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Details"}),": See Chapter 6 (Isaac Sim Basics) for synthetic data generation."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"76-foundationpose-zero-shot-detection",children:"7.6 FoundationPose (Zero-Shot Detection)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Limitation of DOPE"}),": Requires per-object training (10+ minutes per object)."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"FoundationPose"})," (2024) detects ",(0,i.jsx)(n.strong,{children:"novel objects"})," without training:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Input"}),": RGB-D image + CAD model (3D mesh)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Output"}),": 6D pose"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No training required"})," (zero-shot)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"761-how-foundationpose-works",children:"7.6.1 How FoundationPose Works"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Render CAD model"})," from multiple viewpoints (100+ poses)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Match rendered views"})," to observed depth image"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Refine pose"})," using iterative closest point (ICP)"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Performance"}),": 30 FPS on Jetson Orin (vs 5 FPS on CPU)."]}),"\n",(0,i.jsx)(n.h3,{id:"762-running-foundationpose",children:"7.6.2 Running FoundationPose"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Install"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt install -y ros-humble-isaac-ros-foundationpose\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Prepare CAD model"})," (STL, OBJ, or DAE file):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Example: Use a coffee mug model\r\nwget https://example.com/models/mug.obj -O ~/mug.obj\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Launch FoundationPose"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_foundationpose foundationpose.launch.py \\\r\n  mesh_file_path:=~/mug.obj\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Place the mug in front of RealSense camera."})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Check pose"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /foundationpose/pose\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Use case"}),": Warehouse robot identifies packages of arbitrary shapes (no pre-training needed)."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"77-stereo-depth-estimation-ess",children:"7.7 Stereo Depth Estimation (ESS)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS ESS (Efficient Stereo Segmentation)"})," generates dense depth maps from stereo cameras."]}),"\n",(0,i.jsx)(n.h3,{id:"771-why-depth-maps",children:"7.7.1 Why Depth Maps?"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Obstacle avoidance"}),": Know distance to every pixel (wall, person, table)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"3D reconstruction"}),": Build detailed 3D models"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Navigation costmaps"}),": Mark occupied/free space"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Traditional stereo matching"})," (CPU): 5-10 FPS\r\n",(0,i.jsx)(n.strong,{children:"Isaac ESS"})," (GPU): 30 FPS"]}),"\n",(0,i.jsx)(n.h3,{id:"772-running-ess",children:"7.7.2 Running ESS"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Launch ESS with RealSense"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_ess ess_realsense.launch.py\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Visualize depth"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run rviz2 rviz2\r\n# Add DepthCloud display\r\n# Set topic to /ess/depth\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected"}),": Colorized point cloud (red=close, blue=far)."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"78-nav2-integration",children:"7.8 Nav2 Integration"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Nav2"})," (Navigation 2) is the ROS 2 navigation stack. It provides:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Path planning"}),": A*, Dijkstra, Smac Planner"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Control"}),": DWA (Dynamic Window Approach), TEB, MPPI"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Costmaps"}),": 2D occupancy grids (free space, obstacles)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Behavior trees"}),": High-level task logic"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"781-nav2-architecture",children:"7.8.1 Nav2 Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"[Sensor Data] --\x3e [SLAM/Localization] --\x3e [Global Planner] --\x3e [Local Planner] --\x3e [Robot Control]\r\n  (LIDAR, Camera)    (VSLAM, AMCL)         (A*, Theta*)         (DWA, TEB)        (cmd_vel)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"782-launching-nav2-with-isaac-vslam",children:"7.8.2 Launching Nav2 with Isaac VSLAM"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Create a launch file"})," (",(0,i.jsx)(n.code,{children:"nav2_isaac_vslam.launch.py"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from launch import LaunchDescription\r\nfrom launch_ros.actions import Node\r\nfrom launch.actions import IncludeLaunchDescription\r\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\r\nfrom ament_index_python.packages import get_package_share_directory\r\nimport os\r\n\r\n\r\ndef generate_launch_description():\r\n    nav2_dir = get_package_share_directory('nav2_bringup')\r\n    isaac_slam_dir = get_package_share_directory('isaac_ros_visual_slam')\r\n\r\n    return LaunchDescription([\r\n        # Launch Isaac VSLAM\r\n        IncludeLaunchDescription(\r\n            PythonLaunchDescriptionSource(\r\n                os.path.join(isaac_slam_dir, 'launch', 'isaac_ros_visual_slam_realsense.launch.py')\r\n            )\r\n        ),\r\n\r\n        # Launch Nav2\r\n        IncludeLaunchDescription(\r\n            PythonLaunchDescriptionSource(\r\n                os.path.join(nav2_dir, 'launch', 'navigation_launch.py')\r\n            ),\r\n            launch_arguments={\r\n                'use_sim_time': 'False',\r\n                'params_file': os.path.join(nav2_dir, 'params', 'nav2_params.yaml')\r\n            }.items()\r\n        ),\r\n    ])\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Launch"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch my_robot_navigation nav2_isaac_vslam.launch.py\n"})}),"\n",(0,i.jsx)(n.h3,{id:"783-sending-navigation-goals",children:"7.8.3 Sending Navigation Goals"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Via command line"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 action send_goal /navigate_to_pose nav2_msgs/action/NavigateToPose \\\r\n  \"{pose: {header: {frame_id: 'map'}, pose: {position: {x: 2.0, y: 1.0, z: 0.0}, orientation: {w: 1.0}}}}\"\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Via Python"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.action import ActionClient\r\nfrom rclpy.node import Node\r\nfrom nav2_msgs.action import NavigateToPose\r\nfrom geometry_msgs.msg import PoseStamped\r\n\r\n\r\nclass NavGoalClient(Node):\r\n    def __init__(self):\r\n        super().__init__('nav_goal_client')\r\n        self.action_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\r\n\r\n    def send_goal(self, x, y, yaw):\r\n        goal_msg = NavigateToPose.Goal()\r\n        goal_msg.pose.header.frame_id = 'map'\r\n        goal_msg.pose.pose.position.x = x\r\n        goal_msg.pose.pose.position.y = y\r\n        goal_msg.pose.pose.orientation.w = 1.0  # Simplified (use quaternion for yaw)\r\n\r\n        self.action_client.wait_for_server()\r\n        self._send_goal_future = self.action_client.send_goal_async(goal_msg)\r\n\r\n\r\ndef main():\r\n    rclpy.init()\r\n    client = NavGoalClient()\r\n    client.send_goal(2.0, 1.0, 0.0)\r\n    rclpy.spin(client)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"79-bipedal-navigation-humanoid-specific",children:"7.9 Bipedal Navigation (Humanoid-Specific)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Challenge"}),": Humanoids walk differently than wheeled robots."]}),"\n",(0,i.jsx)(n.h3,{id:"791-differences-from-wheeled-navigation",children:"7.9.1 Differences from Wheeled Navigation"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Wheeled Robot"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Humanoid"})})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Continuous motion (any direction)"}),(0,i.jsx)(n.td,{children:"Discrete footsteps (forward, left, right, turn)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Costmap: 2D grid (occupied/free)"}),(0,i.jsx)(n.td,{children:"Costmap: 3D (stairs, slopes, stepping stones)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Dynamics: Simple (car-like model)"}),(0,i.jsx)(n.td,{children:"Dynamics: Complex (balance, ZMP)"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"792-footstep-planning",children:"7.9.2 Footstep Planning"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Approach"}),": Discretize walking into footstep poses."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Code Example"}),": Simple footstep planner"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import math\r\n\r\n\r\ndef plan_footsteps(start_pose, goal_pose, step_length=0.3):\r\n    \"\"\"\r\n    Generate a sequence of footsteps from start to goal.\r\n\r\n    Args:\r\n        start_pose: (x, y, theta)\r\n        goal_pose: (x, y, theta)\r\n        step_length: Distance between consecutive steps (meters)\r\n\r\n    Returns:\r\n        List of footstep poses: [(x, y, theta, foot), ...]\r\n        foot: 'left' or 'right'\r\n    \"\"\"\r\n    footsteps = []\r\n    x, y, theta = start_pose\r\n    goal_x, goal_y, goal_theta = goal_pose\r\n    foot = 'left'  # Start with left foot\r\n\r\n    while True:\r\n        # Calculate distance to goal\r\n        dx = goal_x - x\r\n        dy = goal_y - y\r\n        dist = math.sqrt(dx**2 + dy**2)\r\n\r\n        if dist < step_length:\r\n            # Final step\r\n            footsteps.append((goal_x, goal_y, goal_theta, foot))\r\n            break\r\n\r\n        # Take step towards goal\r\n        step_x = x + step_length * math.cos(theta)\r\n        step_y = y + step_length * math.sin(theta)\r\n        footsteps.append((step_x, step_y, theta, foot))\r\n\r\n        # Update pose and switch foot\r\n        x, y = step_x, step_y\r\n        foot = 'right' if foot == 'left' else 'left'\r\n\r\n    return footsteps\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Integration with Nav2"}),": Replace local planner with footstep controller."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"710-sim-to-real-transfer",children:"7.10 Sim-to-Real Transfer"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Policies trained in Isaac Sim must work on real hardware."]}),"\n",(0,i.jsx)(n.h3,{id:"7101-domain-randomization",children:"7.10.1 Domain Randomization"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Idea"}),": Train on diverse simulated environments so the policy generalizes to reality."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Randomize"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Object poses, textures, colors"}),"\n",(0,i.jsx)(n.li,{children:"Lighting (intensity, direction, color temperature)"}),"\n",(0,i.jsx)(n.li,{children:"Camera parameters (focal length, distortion, noise)"}),"\n",(0,i.jsx)(n.li,{children:"Physics (friction, mass, damping)"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Example"})," (in Isaac Sim, Chapter 6):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import omni.replicator.core as rep\r\n\r\nwith rep.trigger.on_frame():\r\n    # Randomize lighting\r\n    rep.modify.pose(lights, position=rep.distribution.uniform((-5, 5), 3))\r\n\r\n    # Randomize object colors\r\n    rep.randomizer.color(objects, colors=rep.distribution.uniform((0, 1), 3))\n"})}),"\n",(0,i.jsx)(n.h3,{id:"7102-loading-tensorrt-models",children:"7.10.2 Loading TensorRT Models"}),"\n",(0,i.jsxs)(n.p,{children:["Isaac ROS uses ",(0,i.jsx)(n.strong,{children:"TensorRT"})," for optimized inference on Jetson."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Convert PyTorch model to TensorRT"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Inside Isaac Sim Docker container:\r\ntrtexec --onnx=model.onnx --saveEngine=model.trt --fp16\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Load in Isaac ROS"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# isaac_ros_dnn_inference node automatically loads .trt files\r\nros2 launch isaac_ros_dnn_inference inference.launch.py model_file_path:=/path/to/model.trt\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"711-performance-benchmarks",children:"7.11 Performance Benchmarks"}),"\n",(0,i.jsx)(n.h3,{id:"7111-vslam-performance",children:"7.11.1 VSLAM Performance"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Test setup"}),": Walk 50m loop in office environment"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Metric"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"CPU (ORB-SLAM3)"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"GPU (Isaac VSLAM)"})})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Tracking rate"})}),(0,i.jsx)(n.td,{children:"10 Hz"}),(0,i.jsx)(n.td,{children:"100 Hz"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Mapping rate"})}),(0,i.jsx)(n.td,{children:"5 Hz"}),(0,i.jsx)(n.td,{children:"50 Hz"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"CPU usage"})}),(0,i.jsx)(n.td,{children:"100% (4 cores)"}),(0,i.jsx)(n.td,{children:"15% (1 core)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"GPU usage"})}),(0,i.jsx)(n.td,{children:"N/A"}),(0,i.jsx)(n.td,{children:"40%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Latency"})}),(0,i.jsx)(n.td,{children:"100ms"}),(0,i.jsx)(n.td,{children:"10ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"Drift"})," (after loop closure)"]}),(0,i.jsx)(n.td,{children:"0.8m"}),(0,i.jsx)(n.td,{children:"0.2m"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"7112-object-detection-performance",children:"7.11.2 Object Detection Performance"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Test setup"}),": Detect 10 YCB objects in cluttered scene"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Metric"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"CPU (Faster R-CNN)"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"GPU (Isaac DOPE)"})})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"FPS"})}),(0,i.jsx)(n.td,{children:"2"}),(0,i.jsx)(n.td,{children:"30"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Latency"})}),(0,i.jsx)(n.td,{children:"500ms"}),(0,i.jsx)(n.td,{children:"33ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Pose error"})}),(0,i.jsx)(n.td,{children:"2.5cm"}),(0,i.jsx)(n.td,{children:"1.2cm"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"712-debugging-isaac-ros",children:"7.12 Debugging Isaac ROS"}),"\n",(0,i.jsx)(n.h3,{id:"7121-gxf-logs",children:"7.12.1 GXF Logs"}),"\n",(0,i.jsxs)(n.p,{children:["GXF logs are written to ",(0,i.jsx)(n.code,{children:"/tmp/gxf_logs/"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cat /tmp/gxf_logs/isaac_ros_visual_slam.log\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Common errors"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"CUDA out of memory"}),": Reduce image resolution or batch size"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"Failed to initialize cuVSLAM"}),": Camera calibration missing"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"7122-nitros-topics",children:"7.12.2 NITROS Topics"}),"\n",(0,i.jsx)(n.p,{children:"Check NITROS topic types:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 topic list | grep nitros\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"/camera/infra1/image_rect_raw_nitros\r\n/visual_slam/tracking/odometry_nitros\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note"}),": Regular ROS tools (e.g., ",(0,i.jsx)(n.code,{children:"ros2 topic echo"}),") won't work on NITROS topics. Use ",(0,i.jsx)(n.code,{children:"ros2 run isaac_ros_common isaac_ros_visualizer"})," instead."]}),"\n",(0,i.jsx)(n.h3,{id:"7123-latency-profiling",children:"7.12.3 Latency Profiling"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run isaac_ros_common isaac_ros_profiler\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Output"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Node: isaac_ros_visual_slam\r\n  Average latency: 9.8ms\r\n  Max latency: 15.2ms\r\n  Missed frames: 0\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsx)(n.h3,{id:"exercise-71-map-your-room-with-vslam",children:"Exercise 7.1: Map Your Room with VSLAM"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Goal"}),": Use Isaac VSLAM to map your workspace and save the map."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Launch Isaac VSLAM with RealSense"}),"\n",(0,i.jsx)(n.li,{children:"Walk around, building a complete map"}),"\n",(0,i.jsxs)(n.li,{children:["Save map to ",(0,i.jsx)(n.code,{children:"/home/nvidia/workspace_map.db"})]}),"\n",(0,i.jsx)(n.li,{children:"Reload map and localize"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected output"}),": Point cloud file (",(0,i.jsx)(n.code,{children:".pcd"}),") with 10,000+ points."]}),"\n",(0,i.jsx)(n.h3,{id:"exercise-72-train-dope-on-custom-object",children:"Exercise 7.2: Train DOPE on Custom Object"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Goal"}),": Detect a custom object (e.g., your phone) using DOPE."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Steps"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Create a 3D model of your object (use smartphone photogrammetry app)"}),"\n",(0,i.jsx)(n.li,{children:"Generate synthetic training data in Isaac Sim (10,000 images)"}),"\n",(0,i.jsx)(n.li,{children:"Train DOPE model on Jetson (~10 minutes)"}),"\n",(0,i.jsx)(n.li,{children:"Test real-time detection"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Success metric"}),": Detection at 20+ FPS with less than 2cm pose error."]}),"\n",(0,i.jsx)(n.h3,{id:"exercise-73-nav2-waypoint-navigation",children:"Exercise 7.3: Nav2 Waypoint Navigation"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Goal"}),": Implement autonomous waypoint navigation with success rate measurement."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Create a map using VSLAM"}),"\n",(0,i.jsx)(n.li,{children:"Define 5 waypoints (x, y coordinates)"}),"\n",(0,i.jsx)(n.li,{children:"Robot autonomously navigates to all 5 waypoints"}),"\n",(0,i.jsx)(n.li,{children:"Measure success rate over 100 runs"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected success rate"}),": >90% in structured environment."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"citations",children:"Citations"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Tremblay, J., To, T., Sundaralingam, B., Xiang, Y., Fox, D., & Birchfield, S. (2018). ",(0,i.jsx)(n.em,{children:"Deep Object Pose Estimation for Semantic Robotic Grasping of Household Objects."})," Conference on Robot Learning (CoRL)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Wen, B., Mitash, C., Soorian, S., Kimmel, A., Sintov, A., & Bekris, K. E. (2024). ",(0,i.jsx)(n.em,{children:"FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects."})," IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["NVIDIA. (2024). ",(0,i.jsx)(n.em,{children:"Isaac ROS Documentation."})," ",(0,i.jsx)(n.a,{href:"https://nvidia-isaac-ros.github.io/",children:"https://nvidia-isaac-ros.github.io/"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["NVIDIA. (2024). ",(0,i.jsx)(n.em,{children:"Jetson Orin Modules and Developer Kits."})," ",(0,i.jsx)(n.a,{href:"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/",children:"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Macenski, S., Mart\xedn, F., White, R., & Gin\xe9s Clavero, J. (2020). ",(0,i.jsx)(n.em,{children:"The Marathon 2: A Navigation System."})," IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Mur-Artal, R., & Tard\xf3s, J. D. (2017). ",(0,i.jsx)(n.em,{children:"ORB-SLAM2: An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras."})," IEEE Transactions on Robotics, 33(5), 1255-1262."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Intel. (2023). ",(0,i.jsx)(n.em,{children:"Intel RealSense D400 Series Product Family Datasheet."})," ",(0,i.jsx)(n.a,{href:"https://www.intelrealsense.com/",children:"https://www.intelrealsense.com/"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). ",(0,i.jsx)(n.em,{children:"You Only Look Once: Unified, Real-Time Object Detection."})," IEEE Conference on Computer Vision and Pattern Recognition (CVPR)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., & Abbeel, P. (2017). ",(0,i.jsx)(n.em,{children:"Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World."})," IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Peng, X., Sun, B., Ali, K., & Saenko, K. (2015). ",(0,i.jsx)(n.em,{children:"Learning Deep Object Detectors from 3D Models."})," IEEE International Conference on Computer Vision (ICCV)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["NVIDIA. (2023). ",(0,i.jsx)(n.em,{children:"TensorRT Developer Guide."})," ",(0,i.jsx)(n.a,{href:"https://docs.nvidia.com/deeplearning/tensorrt/",children:"https://docs.nvidia.com/deeplearning/tensorrt/"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Xiang, Y., Schmidt, T., Narayanan, V., & Fox, D. (2018). ",(0,i.jsx)(n.em,{children:"PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes."})," Robotics: Science and Systems (RSS)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Labb\xe9, M., & Michaud, F. (2019). ",(0,i.jsx)(n.em,{children:"RTAB-Map as an Open-Source Lidar and Visual Simultaneous Localization and Mapping Library for Large-Scale and Long-Term Online Operation."})," Journal of Field Robotics, 36(2), 416-446."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Engel, J., Sch\xf6ps, T., & Cremers, D. (2014). ",(0,i.jsx)(n.em,{children:"LSD-SLAM: Large-Scale Direct Monocular SLAM."})," European Conference on Computer Vision (ECCV)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Campos, C., Elvira, R., Rodr\xedguez, J. J. G., Montiel, J. M., & Tard\xf3s, J. D. (2021). ",(0,i.jsx)(n.em,{children:"ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual\u2013Inertial, and Multimap SLAM."})," IEEE Transactions on Robotics, 37(6), 1874-1890."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Required"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"NVIDIA Jetson Orin Nano Super"}),": 8GB, $249 (minimum)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Purchase: ",(0,i.jsx)(n.a,{href:"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/",children:"NVIDIA Store"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Intel RealSense D435i"}),": $349","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Purchase: ",(0,i.jsx)(n.a,{href:"https://www.amazon.com/Intel-RealSense-Depth-Camera-D435i/dp/B07Y2M3PZN",children:"Amazon"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Recommended"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"NVIDIA Jetson Orin NX"}),": 16GB, $599 (for faster processing)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MicroSD card"}),": 128GB (for JetPack + datasets)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"USB-C cable"}),": For flashing from Windows PC"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Optional"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"RPLIDAR A1"}),": $99 (for 2D LIDAR comparison)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Power supply"}),": 5V/4A USB-C (Jetson Orin Nano)"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"lab",children:"Lab"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Lab 7.1: Isaac ROS VSLAM"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Repository"}),": ",(0,i.jsx)(n.a,{href:"https://github.com/Shumailaaijaz/physical-ai-labs",children:"github.com/Shumailaaijaz/physical-ai-labs"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Lab Path"}),": ",(0,i.jsx)(n.code,{children:"labs/chapter-07-isaac-ros-vslam/"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"What's Included"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Step-by-step Jetson setup guide"}),"\n",(0,i.jsx)(n.li,{children:"VSLAM launch files"}),"\n",(0,i.jsx)(n.li,{children:"Map saving/loading scripts"}),"\n",(0,i.jsx)(n.li,{children:"Expected output videos"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Hardware"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Jetson Orin Nano + RealSense D435i"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected Time"}),": 2 hours"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Next Chapter"}),": ",(0,i.jsx)(n.a,{href:"/physical-ai-textbook/docs/08-legged-locomotion",children:"Chapter 8: Legged Locomotion \u2192"})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsxs)(n.em,{children:["This textbook is a living document. Found an error? Have a suggestion? Submit an issue or PR at ",(0,i.jsx)(n.a,{href:"https://github.com/Shumailaaijaz/physical-ai-textbook",children:"github.com/Shumailaaijaz/physical-ai-textbook"})]})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);