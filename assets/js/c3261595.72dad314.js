"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[8897],{3850:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>a,contentTitle:()=>t,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"13-ethics-future-physical-ai","title":"Chapter 13: Ethics & Future of Physical AI","description":"\\"With great computational power comes great responsibility.\\"","source":"@site/docs/13-ethics-future-physical-ai.mdx","sourceDirName":".","slug":"/13-ethics-future-physical-ai","permalink":"/physical-ai-textbook/docs/13-ethics-future-physical-ai","draft":false,"unlisted":false,"editUrl":"https://github.com/Shumailaaijaz/physical-ai-textbook/tree/main/docs/13-ethics-future-physical-ai.mdx","tags":[],"version":"current","sidebarPosition":13,"frontMatter":{"id":"13-ethics-future-physical-ai","title":"Chapter 13: Ethics & Future of Physical AI","sidebar_position":13,"part":5,"week":"reference","difficulty_levels":["all"],"hardware_tracks":["simulation_only","budget_hardware","research_grade"],"citation_count":15,"word_count":6000,"urdu_completeness":0},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 12: Hardware Guide","permalink":"/physical-ai-textbook/docs/12-hardware-guide"},"next":{"title":"Example Diagrams","permalink":"/physical-ai-textbook/docs/example-diagrams"}}');var r=n(4848),l=n(8453);const o={id:"13-ethics-future-physical-ai",title:"Chapter 13: Ethics & Future of Physical AI",sidebar_position:13,part:5,week:"reference",difficulty_levels:["all"],hardware_tracks:["simulation_only","budget_hardware","research_grade"],citation_count:15,word_count:6e3,urdu_completeness:0},t="Chapter 13: Ethics & Future of Physical AI",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"13.1 Introduction: When AI Enters the Physical World",id:"131-introduction-when-ai-enters-the-physical-world",level:2},{value:"13.2 Safety: The Asimov Problem",id:"132-safety-the-asimov-problem",level:2},{value:"13.2.1 Three Laws of Robotics (Isaac Asimov, 1942)",id:"1321-three-laws-of-robotics-isaac-asimov-1942",level:3},{value:"13.2.2 Modern Safety Principles",id:"1322-modern-safety-principles",level:3},{value:"13.3 Physical Safety",id:"133-physical-safety",level:2},{value:"13.3.1 Collision Avoidance",id:"1331-collision-avoidance",level:3},{value:"13.3.2 Emergency Stop",id:"1332-emergency-stop",level:3},{value:"13.3.3 Force Limits (Cobots)",id:"1333-force-limits-cobots",level:3},{value:"13.3.4 Case Study: Tesla Autopilot Crashes",id:"1334-case-study-tesla-autopilot-crashes",level:3},{value:"13.4 Bias in Embodied AI",id:"134-bias-in-embodied-ai",level:2},{value:"13.4.1 Perception Bias",id:"1341-perception-bias",level:3},{value:"13.4.2 Behavior Bias",id:"1342-behavior-bias",level:3},{value:"13.4.3 Cultural Bias",id:"1343-cultural-bias",level:3},{value:"13.5 Privacy &amp; Surveillance",id:"135-privacy--surveillance",level:2},{value:"13.5.1 Data Collection",id:"1351-data-collection",level:3},{value:"13.5.2 Regulation",id:"1352-regulation",level:3},{value:"13.6 Job Displacement",id:"136-job-displacement",level:2},{value:"13.6.1 At-Risk Jobs",id:"1361-at-risk-jobs",level:3},{value:"13.6.2 Job Creation",id:"1362-job-creation",level:3},{value:"13.6.3 Social Safety Net",id:"1363-social-safety-net",level:3},{value:"13.7 Dual-Use Concerns",id:"137-dual-use-concerns",level:2},{value:"13.7.1 Military Robotics",id:"1371-military-robotics",level:3},{value:"13.7.2 Campaign to Stop Killer Robots",id:"1372-campaign-to-stop-killer-robots",level:3},{value:"13.8 Alignment: What Do We Want Robots to Do?",id:"138-alignment-what-do-we-want-robots-to-do",level:2},{value:"13.8.1 Cultural Differences",id:"1381-cultural-differences",level:3},{value:"13.8.2 Should Robots Lie?",id:"1382-should-robots-lie",level:3},{value:"13.9 Regulation &amp; Standards",id:"139-regulation--standards",level:2},{value:"13.9.1 ISO 10218 (Industrial Robots)",id:"1391-iso-10218-industrial-robots",level:3},{value:"13.9.2 IEEE 7000 (Ethical Design)",id:"1392-ieee-7000-ethical-design",level:3},{value:"13.9.3 EU AI Act (2024)",id:"1393-eu-ai-act-2024",level:3},{value:"13.10 Future: Next 10 Years",id:"1310-future-next-10-years",level:2},{value:"13.10.1 2025-2030: Warehouse &amp; Factory Robots",id:"13101-2025-2030-warehouse--factory-robots",level:3},{value:"13.10.2 2030-2035: Home Assistants",id:"13102-2030-2035-home-assistants",level:3},{value:"13.10.3 2035+: Human-Level Dexterity",id:"13103-2035-human-level-dexterity",level:3},{value:"13.11 Research Frontiers",id:"1311-research-frontiers",level:2},{value:"13.11.1 Soft Robotics",id:"13111-soft-robotics",level:3},{value:"13.11.2 Morphological Computation",id:"13112-morphological-computation",level:3},{value:"13.11.3 Lifelong Learning",id:"13113-lifelong-learning",level:3},{value:"13.12 Call to Action",id:"1312-call-to-action",level:2},{value:"Discussion Questions",id:"discussion-questions",level:2},{value:"Question 1: Anthropomorphism",id:"question-1-anthropomorphism",level:3},{value:"Question 2: Liability",id:"question-2-liability",level:3},{value:"Question 3: Limits on Capability",id:"question-3-limits-on-capability",level:3},{value:"Citations",id:"citations",level:2},{value:"Epilogue: The Path Forward",id:"epilogue-the-path-forward",level:2}];function d(e){const s={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(s.header,{children:(0,r.jsx)(s.h1,{id:"chapter-13-ethics--future-of-physical-ai",children:"Chapter 13: Ethics & Future of Physical AI"})}),"\n",(0,r.jsxs)(s.blockquote,{children:["\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.em,{children:'"With great computational power comes great responsibility."'})}),"\n"]}),"\n",(0,r.jsx)(s.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(s.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Identify ethical challenges"})," in embodied AI (safety, bias, job displacement)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Understand AI safety principles"})," for physical systems"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Analyze societal impact"})," of humanoid robots"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Predict future directions"})," of Physical AI research"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Apply ethical frameworks"})," to robot design decisions"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Estimated Time"}),": 3-4 hours (reading + reflection)"]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"131-introduction-when-ai-enters-the-physical-world",children:"13.1 Introduction: When AI Enters the Physical World"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Digital AI"})," (ChatGPT, image generators) operates in a virtual sandbox:"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Failure mode"}),": Wrong answer, offensive output, hallucination"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Consequence"}),": User dissatisfaction, reputational damage"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Recovery"}),": Regenerate response, fine-tune model"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Physical AI"})," (humanoid robots) operates in the real world:"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Failure mode"}),": Collision, grasp failure, navigation error"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Consequence"}),": Property damage, human injury, legal liability"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Recovery"}),": Emergency stop, physical repair, safety redesign"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"The stakes are higher."})," A self-driving car's perception error can cause a fatal accident. A surgical robot's control glitch can harm a patient. A delivery robot's navigation bug can block a wheelchair ramp."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"132-safety-the-asimov-problem",children:"13.2 Safety: The Asimov Problem"}),"\n",(0,r.jsx)(s.h3,{id:"1321-three-laws-of-robotics-isaac-asimov-1942",children:"13.2.1 Three Laws of Robotics (Isaac Asimov, 1942)"}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"First Law"}),": A robot may not injure a human being or, through inaction, allow a human being to come to harm."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Second Law"}),": A robot must obey orders given by human beings except where such orders would conflict with the First Law."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Third Law"}),": A robot must protect its own existence as long as such protection does not conflict with the First or Second Law."]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Appealing"}),", but ",(0,r.jsx)(s.strong,{children:"impossible to implement"}),":"]}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Problem 1: Ambiguity"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:'What is "harm"? (Physical injury, psychological distress, financial loss?)'}),"\n",(0,r.jsx)(s.li,{children:'What is "inaction"? (Robot sees drowning person but isn\'t programmed to swim\u2014violates First Law?)'}),"\n"]}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Problem 2: Prediction"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["How does a robot predict ",(0,r.jsx)(s.strong,{children:"all"})," consequences of an action?"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Example"}),": Robot moves heavy box. Box falls on person's foot 10 seconds later. Is the robot responsible?"]}),"\n"]}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Problem 3: Conflicting Orders"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Two humans give contradictory orders (both comply with First Law). Which to obey?"}),"\n"]}),"\n",(0,r.jsx)(s.h3,{id:"1322-modern-safety-principles",children:"13.2.2 Modern Safety Principles"}),"\n",(0,r.jsxs)(s.p,{children:["Instead of Asimov's laws, modern robotics uses ",(0,r.jsx)(s.strong,{children:"engineering safety"}),":"]}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Principle 1: Fail-Safe Design"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Hardware kill switch"}),": Red emergency stop button (required by ISO 10218)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Watchdog timer"}),": If robot doesn't receive heartbeat signal \u2192 motors disable"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Force limits"}),": Collaborative robots (cobots) must limit contact force less than 150N (ISO/TS 15066)"]}),"\n"]}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Principle 2: Redundancy"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Dual sensors"}),": If one camera fails, use backup"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Redundant safety circuits"}),": Independent safety PLCs"]}),"\n"]}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Principle 3: Verification & Validation"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"V&V process"}),": Formal methods prove controller satisfies safety properties"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Example"}),": MIT's Drake framework verifies collision avoidance constraints"]}),"\n"]}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Principle 4: Human-in-the-Loop"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Supervised autonomy"}),": Human approves critical decisions (e.g., surgical robot waits for surgeon confirmation before cutting)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Shared control"}),": Human and robot co-pilot (e.g., Tesla Autopilot)"]}),"\n"]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"133-physical-safety",children:"13.3 Physical Safety"}),"\n",(0,r.jsx)(s.h3,{id:"1331-collision-avoidance",children:"13.3.1 Collision Avoidance"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Challenge"}),": Humans are unpredictable (walk into robot's path)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Approaches"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Safety zones"}),": Robots slow down near humans (< 1 m/s within 1.5m)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Predictive models"}),": Forecast human motion (Gaussian processes, neural networks)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Conservative planning"}),": Assume worst-case human trajectory"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Code Example"}),": Safety zone (speed limiting)"]}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'def compute_safe_velocity(robot_pos, human_pos, max_speed=1.0, safety_radius=1.5):\r\n    """\r\n    Limit robot speed near humans.\r\n\r\n    Args:\r\n        robot_pos: (x, y)\r\n        human_pos: (x, y)\r\n        max_speed: Maximum allowed speed (m/s)\r\n        safety_radius: Slow down within this distance (m)\r\n\r\n    Returns:\r\n        safe_speed: Speed limit (m/s)\r\n    """\r\n    distance = np.linalg.norm(np.array(robot_pos) - np.array(human_pos))\r\n\r\n    if distance < safety_radius:\r\n        # Linear scaling: 0 speed at 0 distance, max_speed at safety_radius\r\n        safe_speed = max_speed * (distance / safety_radius)\r\n    else:\r\n        safe_speed = max_speed\r\n\r\n    return safe_speed\n'})}),"\n",(0,r.jsx)(s.h3,{id:"1332-emergency-stop",children:"13.3.2 Emergency Stop"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"ISO 10218 requirement"}),": All industrial robots must have ",(0,r.jsx)(s.strong,{children:"Category 0"})," stop (immediate power cut) or ",(0,r.jsx)(s.strong,{children:"Category 1"})," stop (controlled deceleration)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Hardware"}),": Hardwired safety relay (independent of main controller)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Software failsafe"}),": If robot doesn't receive heartbeat for 100ms \u2192 trigger emergency stop."]}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'import time\r\nimport threading\r\n\r\nclass SafetyMonitor:\r\n    def __init__(self, timeout=0.1):\r\n        self.last_heartbeat = time.time()\r\n        self.timeout = timeout\r\n        self.stop_triggered = False\r\n\r\n        # Start watchdog thread\r\n        self.watchdog_thread = threading.Thread(target=self.watchdog, daemon=True)\r\n        self.watchdog_thread.start()\r\n\r\n    def heartbeat(self):\r\n        """Called by main control loop every cycle."""\r\n        self.last_heartbeat = time.time()\r\n\r\n    def watchdog(self):\r\n        """Runs in background, triggers stop if heartbeat missed."""\r\n        while True:\r\n            time.sleep(0.01)  # Check every 10ms\r\n            if time.time() - self.last_heartbeat > self.timeout:\r\n                if not self.stop_triggered:\r\n                    self.emergency_stop()\r\n                    self.stop_triggered = True\r\n\r\n    def emergency_stop(self):\r\n        """Trigger hardware emergency stop."""\r\n        print("EMERGENCY STOP TRIGGERED!")\r\n        # In real system: Send signal to safety relay\r\n        robot.disable_motors()\n'})}),"\n",(0,r.jsx)(s.h3,{id:"1333-force-limits-cobots",children:"13.3.3 Force Limits (Cobots)"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"ISO/TS 15066"})," specifies maximum allowable force for human-robot contact:"]}),"\n",(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:(0,r.jsx)(s.strong,{children:"Body Part"})}),(0,r.jsx)(s.th,{children:(0,r.jsx)(s.strong,{children:"Max Force (N)"})}),(0,r.jsx)(s.th,{children:(0,r.jsx)(s.strong,{children:"Max Pressure (N/cm\xb2)"})})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Head"}),(0,r.jsx)(s.td,{children:"130"}),(0,r.jsx)(s.td,{children:"110"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Torso"}),(0,r.jsx)(s.td,{children:"140"}),(0,r.jsx)(s.td,{children:"110"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Upper arm"}),(0,r.jsx)(s.td,{children:"150"}),(0,r.jsx)(s.td,{children:"140"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Hand"}),(0,r.jsx)(s.td,{children:"140"}),(0,r.jsx)(s.td,{children:"210"})]})]})]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Implementation"}),": Torque sensors in all joints. If contact detected \u2192 retract."]}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'def contact_detection(joint_torques, torque_threshold=5.0):\r\n    """\r\n    Detect unexpected contact (collision or human touch).\r\n\r\n    Args:\r\n        joint_torques: Measured torques (Nm)\r\n        torque_threshold: Threshold above expected value (Nm)\r\n\r\n    Returns:\r\n        contact_detected: bool\r\n    """\r\n    expected_torques = compute_expected_torques()  # From dynamics model\r\n    residual = np.abs(joint_torques - expected_torques)\r\n\r\n    if np.any(residual > torque_threshold):\r\n        return True\r\n    return False\n'})}),"\n",(0,r.jsx)(s.h3,{id:"1334-case-study-tesla-autopilot-crashes",children:"13.3.4 Case Study: Tesla Autopilot Crashes"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Incident"})," (May 2016, Florida):"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Tesla Model S in Autopilot mode"}),"\n",(0,r.jsx)(s.li,{children:"Tractor-trailer crosses highway (perpendicular)"}),"\n",(0,r.jsx)(s.li,{children:"Autopilot's camera fails to detect white truck against bright sky"}),"\n",(0,r.jsx)(s.li,{children:"No braking \u2192 fatal collision"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Root cause"}),": Over-reliance on vision (no LIDAR redundancy)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Lessons learned"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Sensor fusion"}),": Use multiple sensor modalities (camera + LIDAR + radar)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Graceful degradation"}),": If one sensor fails, others compensate"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Clear user expectations"}),': Autopilot is "driver assistance," not "self-driving"']}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Regulatory response"}),": NHTSA (US) requires transparent reporting of autonomous vehicle crashes."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"134-bias-in-embodied-ai",children:"13.4 Bias in Embodied AI"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Problem"}),": AI systems reflect biases in training data."]}),"\n",(0,r.jsx)(s.h3,{id:"1341-perception-bias",children:"13.4.1 Perception Bias"}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Example 1: Facial Recognition"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["Study (Buolamwini & Gebru, 2018): Commercial facial recognition systems have ",(0,r.jsx)(s.strong,{children:"error rates 34% higher"})," for dark-skinned women than light-skinned men."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Cause"}),": Training datasets (e.g., FaceNet) predominantly white, male faces."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Impact on robotics"}),": Social robots may fail to recognize or respond to certain demographics."]}),"\n"]}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Example 2: Hand Soap Dispenser"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Viral video (2017): Automatic soap dispenser doesn't detect dark skin."}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Cause"}),": Infrared sensor calibrated for lighter skin (higher reflectance)."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Fix"}),": Recalibrate sensor threshold OR use ultrasonic sensor."]}),"\n"]}),"\n",(0,r.jsx)(s.h3,{id:"1342-behavior-bias",children:"13.4.2 Behavior Bias"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Example"}),": Home assistant robots trained on data from wealthy households may fail in low-income environments (different furniture, layouts, objects)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Mitigation"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Diverse training data"}),": Include images/scenarios from all demographics"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Fairness audits"}),": Test model performance across demographic groups"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Participatory design"}),": Involve end-users (especially marginalized groups) in design process"]}),"\n"]}),"\n",(0,r.jsx)(s.h3,{id:"1343-cultural-bias",children:"13.4.3 Cultural Bias"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Example"}),": Social robot gestures"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:'Head nod = "yes" (most cultures)'}),"\n",(0,r.jsx)(s.li,{children:'But in Bulgaria, head nod = "no"'}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Mitigation"}),": Localize robot behavior (cultural adaptation)."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"135-privacy--surveillance",children:"13.5 Privacy & Surveillance"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Problem"}),": Robots with cameras/microphones constantly record environments."]}),"\n",(0,r.jsx)(s.h3,{id:"1351-data-collection",children:"13.5.1 Data Collection"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Scenario"}),": Delivery robot in office building"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Cameras record employees at desks"}),"\n",(0,r.jsx)(s.li,{children:"Microphones record conversations"}),"\n",(0,r.jsx)(s.li,{children:"LIDAR maps office layout"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Questions"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Who owns this data? (Robot company, building owner, individuals?)"}),"\n",(0,r.jsx)(s.li,{children:"Can employees opt out of being recorded?"}),"\n",(0,r.jsx)(s.li,{children:"How long is data stored?"}),"\n"]}),"\n",(0,r.jsx)(s.h3,{id:"1352-regulation",children:"13.5.2 Regulation"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"GDPR (EU)"})," applies to robots:"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Right to be informed"}),": Individuals must know they're being recorded"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Data minimization"}),": Only collect necessary data (e.g., navigation doesn't need face recognition)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Right to erasure"}),": Individuals can request deletion of their data"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"CCPA (California)"})," similar requirements:"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Businesses must disclose data collection practices"}),"\n",(0,r.jsx)(s.li,{children:"Consumers can opt out of data sale"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Best practices"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Visual indicators"}),": LED lights when camera is recording"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Data anonymization"}),": Blur faces in stored footage"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Edge processing"}),": Process data on robot (don't upload to cloud unless necessary)"]}),"\n"]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"136-job-displacement",children:"13.6 Job Displacement"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Prediction (World Economic Forum, 2020)"}),": By 2025, automation will displace ",(0,r.jsx)(s.strong,{children:"85 million jobs"})," but create ",(0,r.jsx)(s.strong,{children:"97 million new jobs"}),"."]}),"\n",(0,r.jsx)(s.h3,{id:"1361-at-risk-jobs",children:"13.6.1 At-Risk Jobs"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"High risk"})," (>70% of tasks automatable):"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Warehouse pickers"}),": Amazon robots (Kiva, now Amazon Robotics)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Food service"}),": Flippy (burger-flipping robot), robotic pizza makers"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Manufacturing"}),": Industrial robots (welding, assembly)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Delivery"}),": Autonomous trucks, drones"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Medium risk"})," (30-70%):"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Retail"}),": Self-checkout, inventory robots"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Healthcare"}),": Robotic surgery assistants (augment, not replace)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Agriculture"}),": Harvesting robots"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Low risk"})," (",(0,r.jsx)(s.code,{children:"<30%"}),"):"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Creative professions"}),": Artists, writers (though AI is challenging this)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Care work"}),": Elderly care (requires human empathy)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Complex problem-solving"}),": Researchers, engineers"]}),"\n"]}),"\n",(0,r.jsx)(s.h3,{id:"1362-job-creation",children:"13.6.2 Job Creation"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"New jobs"})," enabled by robotics:"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Robot technicians"}),": Maintenance, repair (1M+ jobs by 2030, per IFR)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"AI trainers"}),": Labeling data, fine-tuning models"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Robot ethicists"}),": Design safety protocols, audit fairness"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Telepresence operators"}),": Remote-control robots for dangerous tasks"]}),"\n"]}),"\n",(0,r.jsx)(s.h3,{id:"1363-social-safety-net",children:"13.6.3 Social Safety Net"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Policy proposals"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Universal Basic Income (UBI)"}),": Government pays all citizens (e.g., $1,000/month) to offset job losses"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Retraining programs"}),": Teach displaced workers new skills (coding, robotics)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Robot tax"}),": Tax companies for using robots (funds UBI or retraining)"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Debate"}),": Economists disagree on effectiveness."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"137-dual-use-concerns",children:"13.7 Dual-Use Concerns"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Dual-use technology"}),": Can be used for civilian OR military purposes."]}),"\n",(0,r.jsx)(s.h3,{id:"1371-military-robotics",children:"13.7.1 Military Robotics"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Boston Dynamics Spot"})," (2021 controversy):"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["French army mounted ",(0,r.jsx)(s.strong,{children:"gun"})," on Spot robot (autonomous patrol)"]}),"\n",(0,r.jsx)(s.li,{children:"Public outcry \u2192 Boston Dynamics issued statement prohibiting weaponization"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Autonomous weapons"})," (loitering munitions):"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Definition"}),": Weapons that select and engage targets without human intervention"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Example"}),": KARGU-2 (Turkey) reportedly used in Libya (2020) to autonomously attack retreating soldiers"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Concern"}),": Accountability (who is responsible if autonomous weapon kills civilian?)"]}),"\n"]}),"\n",(0,r.jsx)(s.h3,{id:"1372-campaign-to-stop-killer-robots",children:"13.7.2 Campaign to Stop Killer Robots"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Goal"}),": Ban fully autonomous weapons."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Arguments"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Accountability gap"}),": No human in the loop \u2192 no one to blame"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Arms race"}),": Countries race to deploy before regulations exist"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Lowered threshold for war"}),": If no soldiers at risk, wars become easier to start"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Counter-arguments"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Precision"}),": Robots may have better accuracy than humans (fewer civilian casualties)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Defense"}),": Countries need autonomous systems to defend against adversary's autonomous systems"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Status"})," (2024): No international treaty. UN discussions ongoing."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"138-alignment-what-do-we-want-robots-to-do",children:"13.8 Alignment: What Do We Want Robots to Do?"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Value alignment problem"}),": Whose values should robots follow?"]}),"\n",(0,r.jsx)(s.h3,{id:"1381-cultural-differences",children:"13.8.1 Cultural Differences"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Example"}),": Autonomous car's trolley problem"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Scenario: Brake failure. Steer left \u2192 kill 1 pedestrian. Steer right \u2192 kill 5 pedestrians. What to do?"}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Western cultures"}),": Utilitarian (minimize deaths \u2192 kill 1)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Eastern cultures"}),": May prioritize elderly or authority figures"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Implication"}),": Global companies (Tesla, Waymo) must decide whose ethics to encode."]}),"\n",(0,r.jsx)(s.h3,{id:"1382-should-robots-lie",children:"13.8.2 Should Robots Lie?"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Scenario"}),': Elderly care robot. Patient asks, "Do I look sick?"']}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Honest answer"}),': "Yes, you look very ill."']}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Compassionate answer"}),': "You look fine today."']}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Debate"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Pro-honesty"}),": Trust requires honesty"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Pro-compassion"}),": Sometimes kindness > truth (human caregivers do this)"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Current approach"}),": Let designers choose (no consensus)."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"139-regulation--standards",children:"13.9 Regulation & Standards"}),"\n",(0,r.jsx)(s.h3,{id:"1391-iso-10218-industrial-robots",children:"13.9.1 ISO 10218 (Industrial Robots)"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Requirements"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Emergency stop buttons (easily accessible)"}),"\n",(0,r.jsx)(s.li,{children:"Safety-rated monitored stop (if human enters workspace)"}),"\n",(0,r.jsx)(s.li,{children:"Force/speed limits for collaborative robots"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Compliance"}),": Mandatory in EU, voluntary in US (but liability insurance requires it)."]}),"\n",(0,r.jsx)(s.h3,{id:"1392-ieee-7000-ethical-design",children:"13.9.2 IEEE 7000 (Ethical Design)"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Process"}),": 10-step framework for embedding values in system design:"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsx)(s.li,{children:"Identify stakeholders"}),"\n",(0,r.jsx)(s.li,{children:"Elicit values (interviews, surveys)"}),"\n",(0,r.jsx)(s.li,{children:"Prioritize values (stakeholder workshop)"}),"\n",(0,r.jsx)(s.li,{children:'Translate values into requirements (e.g., "Privacy" \u2192 "No cloud upload without consent")'}),"\n",(0,r.jsx)(s.li,{children:"Design system to meet requirements"}),"\n",(0,r.jsx)(s.li,{children:"Verify (testing, audits)"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Adoption"}),": Voluntary, but gaining traction (Uber uses it for self-driving cars)."]}),"\n",(0,r.jsx)(s.h3,{id:"1393-eu-ai-act-2024",children:"13.9.3 EU AI Act (2024)"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Risk-based approach"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Unacceptable risk"}),": Banned (e.g., social credit scoring, subliminal manipulation)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"High risk"}),": Requires conformity assessment (e.g., hiring algorithms, medical devices, autonomous vehicles)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Limited risk"}),": Transparency obligations (e.g., chatbots must disclose they're AI)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Minimal risk"}),": No regulation (e.g., spam filters)"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Humanoid robots"}),': Likely "high risk" (requires CE marking, audit trail, human oversight).']}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Penalties"}),": Up to \u20ac30M or 6% of global revenue."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"1310-future-next-10-years",children:"13.10 Future: Next 10 Years"}),"\n",(0,r.jsx)(s.h3,{id:"13101-2025-2030-warehouse--factory-robots",children:"13.10.1 2025-2030: Warehouse & Factory Robots"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Trend"}),": Humanoid robots replace human workers in structured environments."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Examples"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Agility Robotics Digit"})," (2023): Already deployed in Amazon warehouses (picking, sorting)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Figure 01"})," (2024): Demo at BMW plant (assembling car parts)"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Key enabler"}),": Imitation learning (robots learn from human demonstrations, not hand-coded programs)."]}),"\n",(0,r.jsx)(s.h3,{id:"13102-2030-2035-home-assistants",children:"13.10.2 2030-2035: Home Assistants"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Trend"}),": Robots perform household tasks (cleaning, cooking, laundry)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Technical challenges"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Dexterity"}),": Human hands have 27 DOF. Current grippers: 2-3 DOF."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Generalization"}),": Every home is different (layout, objects)."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Cost"}),": Target price ~$5,000 (compare to Roomba: $300)."]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Candidate robots"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Tesla Optimus"})," (2024): Musk claims $20k by 2027 (skepticism warranted)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"1X NEO Beta"})," (Norway): Humanoid home assistant (prototype)"]}),"\n"]}),"\n",(0,r.jsx)(s.h3,{id:"13103-2035-human-level-dexterity",children:"13.10.3 2035+: Human-Level Dexterity"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Goal"}),": Match human manipulation ability (tie shoelaces, fold fitted sheet, assemble IKEA furniture)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Approaches"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Better hardware"}),": Soft grippers, tactile sensors (GelSight)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Better learning"}),": Foundation models (OpenVLA scaled to 100B+ parameters)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Better data"}),": 1 billion robot demonstrations (Open X-Embodiment at scale)"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Prediction"}),": Human-level dexterity by ",(0,r.jsx)(s.strong,{children:"2040"})," (optimistic) or ",(0,r.jsx)(s.strong,{children:"2050"})," (realistic)."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"1311-research-frontiers",children:"13.11 Research Frontiers"}),"\n",(0,r.jsx)(s.h3,{id:"13111-soft-robotics",children:"13.11.1 Soft Robotics"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Idea"}),": Build robots from compliant materials (rubber, silicone)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Advantages"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Safety"}),": Soft robots can't exert high forces (inherently safe)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Adaptability"}),": Conform to irregular shapes (better grasping)"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Example"}),": Harvard's Octobot (fully soft, pneumatic robot)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Challenge"}),": Control is harder (infinite DOF)."]}),"\n",(0,r.jsx)(s.h3,{id:"13112-morphological-computation",children:"13.11.2 Morphological Computation"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Idea"}),": Body design contributes to intelligence (not just brain/software)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Example"}),": Passive-dynamic walker (Cornell, 2005)"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"No motors, no computer"}),"\n",(0,r.jsx)(s.li,{children:"Walks down slope using only gravity + leg shape"}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Insight"}),": Leg geometry encodes walking gait"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Application"}),": Design robot bodies to simplify control (exploit natural dynamics)."]}),"\n",(0,r.jsx)(s.h3,{id:"13113-lifelong-learning",children:"13.11.3 Lifelong Learning"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Problem"}),": Current robots are trained once, then frozen (no learning from experience)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Goal"}),": Robots that continuously improve:"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Learn new tasks (never-ending learning)"}),"\n",(0,r.jsx)(s.li,{children:"Adapt to new environments (domain shift)"}),"\n",(0,r.jsx)(s.li,{children:"Remember past experiences (episodic memory)"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Approaches"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Continual learning"}),": Train on new data without forgetting old tasks (Elastic Weight Consolidation)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Meta-learning"}),": Learn to learn (MAML algorithm)"]}),"\n"]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"1312-call-to-action",children:"13.12 Call to Action"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"For students"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Build responsibly"}),": Prioritize safety, test failure modes"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Think critically"}),": Question assumptions (whose values are encoded? who benefits?)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Stay informed"}),": Read AI safety research (arXiv, Alignment Forum)"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"For researchers"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Engage with policy"}),": Inform regulation (testify at hearings, write policy briefs)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Publish transparently"}),": Share failure modes, not just successes"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Collaborate broadly"}),": Work with ethicists, social scientists, lawyers"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"For society"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Demand accountability"}),": Companies should disclose robot capabilities/limitations"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Participate in design"}),": Provide feedback on robot behavior (via public pilots)"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Support education"}),": Fund robotics education (STEM programs, community colleges)"]}),"\n"]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"discussion-questions",children:"Discussion Questions"}),"\n",(0,r.jsx)(s.h3,{id:"question-1-anthropomorphism",children:"Question 1: Anthropomorphism"}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Should humanoid robots look human-like or clearly robotic?"})}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Arguments for human-like"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Easier to interact (people naturally read facial expressions)"}),"\n",(0,r.jsx)(s.li,{children:"Less intimidating (cute robots reduce anxiety)"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Arguments against"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Uncanny valley (slightly off looks creepy)"}),"\n",(0,r.jsx)(s.li,{children:"Deception (people may trust robot too much)"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Case study"}),": Sophia (Hanson Robotics) generates controversy for appearing too human."]}),"\n",(0,r.jsx)(s.h3,{id:"question-2-liability",children:"Question 2: Liability"}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Who is liable when a robot causes harm?"})}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Options"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Manufacturer"}),": Robot had design flaw \u2192 company pays"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Operator"}),": User misused robot \u2192 user pays"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Robot itself"}),': Treat robot as legal entity (like corporations) \u2192 robot\'s "assets" pay']}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Current law"}),": Unclear. Most cases settled out of court."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Proposal"})," (EU): Robot liability directive (strict liability for manufacturers)."]}),"\n",(0,r.jsx)(s.h3,{id:"question-3-limits-on-capability",children:"Question 3: Limits on Capability"}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Should there be limits on robot capabilities?"})}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Example"}),": Ban autonomous weapons."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Arguments for limits"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Prevent misuse (military, surveillance)"}),"\n",(0,r.jsx)(s.li,{children:"Give society time to adapt (job displacement)"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Arguments against"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Innovation stifled"}),"\n",(0,r.jsx)(s.li,{children:"Other countries won't comply (arms race continues)"}),"\n",(0,r.jsx)(s.li,{children:"Defensive use justified"}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Your position"}),": Discuss with classmates."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"citations",children:"Citations"}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Asimov, I. (1950). ",(0,r.jsx)(s.em,{children:"I, Robot."})," Gnome Press."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Calo, R. (2015). ",(0,r.jsx)(s.em,{children:"Robotics and the Lessons of Cyberlaw."})," California Law Review, 103, 513-563."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Buolamwini, J., & Gebru, T. (2018). ",(0,r.jsx)(s.em,{children:"Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification."})," Conference on Fairness, Accountability, and Transparency (FAT*)."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["World Economic Forum. (2020). ",(0,r.jsx)(s.em,{children:"The Future of Jobs Report 2020."})," ",(0,r.jsx)(s.a,{href:"https://www.weforum.org/publications/the-future-of-jobs-report-2020/",children:"https://www.weforum.org/publications/the-future-of-jobs-report-2020/"})]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Campaign to Stop Killer Robots. (2024). ",(0,r.jsx)(s.em,{children:"Key Arguments."})," ",(0,r.jsx)(s.a,{href:"https://www.stopkillerrobots.org/",children:"https://www.stopkillerrobots.org/"})]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["ISO 10218-1:2011. ",(0,r.jsx)(s.em,{children:"Robots and robotic devices \u2014 Safety requirements for industrial robots \u2014 Part 1: Robots."})," International Organization for Standardization."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["ISO/TS 15066:2016. ",(0,r.jsx)(s.em,{children:"Robots and robotic devices \u2014 Collaborative robots."})," International Organization for Standardization."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["IEEE. (2021). ",(0,r.jsx)(s.em,{children:"IEEE 7000-2021: Model Process for Addressing Ethical Concerns During System Design."})," IEEE Standards Association."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["European Commission. (2024). ",(0,r.jsx)(s.em,{children:"EU AI Act."})," ",(0,r.jsx)(s.a,{href:"https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai",children:"https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai"})]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Sharkey, A., & Sharkey, N. (2012). ",(0,r.jsx)(s.em,{children:"Granny and the robots: Ethical issues in robot care for the elderly."})," Ethics and Information Technology, 14(1), 27-40."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Lin, P., Abney, K., & Bekey, G. A. (Eds.). (2014). ",(0,r.jsx)(s.em,{children:"Robot Ethics: The Ethical and Social Implications of Robotics."})," MIT Press."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Wallach, W., & Allen, C. (2008). ",(0,r.jsx)(s.em,{children:"Moral Machines: Teaching Robots Right from Wrong."})," Oxford University Press."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Bryson, J. J., Diamantis, M. E., & Grant, T. D. (2017). ",(0,r.jsx)(s.em,{children:"Of, for, and by the people: The legal lacuna of synthetic persons."})," Artificial Intelligence and Law, 25(3), 273-291."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Russell, S., Dewey, D., & Tegmark, M. (2015). ",(0,r.jsx)(s.em,{children:"Research Priorities for Robust and Beneficial Artificial Intelligence."})," AI Magazine, 36(4), 105-114."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:["Bostrom, N. (2014). ",(0,r.jsx)(s.em,{children:"Superintelligence: Paths, Dangers, Strategies."})," Oxford University Press."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"epilogue-the-path-forward",children:"Epilogue: The Path Forward"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Robotics is at an inflection point."})," The next decade will see humanoid robots transition from research labs to factories, homes, and streets."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Our responsibility"}),":"]}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Build safely"}),": Engineer systems that fail gracefully"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Build fairly"}),": Test on diverse populations, audit for bias"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Build transparently"}),": Publish failure modes, share data"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Build ethically"}),": Prioritize human well-being over efficiency"]}),"\n"]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"The future is not predetermined."})," Every design decision\u2014what sensors to use, what data to train on, what tasks to automate\u2014shapes the world we'll live in."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"You are part of this story."})," The robots you build today will define tomorrow."]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Congratulations on completing the Physical AI & Humanoid Robotics textbook!"})}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"Next steps"}),":"]}),"\n",(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsx)(s.li,{children:"Build a capstone project (Chapter 11)"}),"\n",(0,r.jsx)(s.li,{children:"Contribute to open-source robotics (Isaac ROS, MoveIt, Nav2)"}),"\n",(0,r.jsx)(s.li,{children:"Join a research lab or startup"}),"\n",(0,r.jsx)(s.li,{children:"Share your knowledge (teach, mentor, write)"}),"\n"]}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Stay curious. Stay humble. Build robots that help."})}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.p,{children:(0,r.jsxs)(s.em,{children:["This textbook is a living document. Found an error? Have a suggestion? Submit an issue or PR at ",(0,r.jsx)(s.a,{href:"https://github.com/Shumailaaijaz/physical-ai-textbook",children:"github.com/Shumailaaijaz/physical-ai-textbook"})]})})]})}function h(e={}){const{wrapper:s}={...(0,l.R)(),...e.components};return s?(0,r.jsx)(s,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>o,x:()=>t});var i=n(6540);const r={},l=i.createContext(r);function o(e){const s=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function t(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(l.Provider,{value:s},e.children)}}}]);